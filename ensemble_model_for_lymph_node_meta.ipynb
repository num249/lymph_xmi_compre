{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbef4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, cross_val_predict\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn import svm  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "# cores = mp.cpu_count()\n",
    "# pool = mp.Pool(processes=20)\n",
    "\n",
    "# min1=min(list(X_standard.shape))\n",
    "# a1=list(range(10,min1,10))\n",
    "# a1[-1]=min1\n",
    "# pcc_top1=pool.map(find_best_pca_lr,a1)  ##（SVM，LR）\n",
    "# pool.terminate()\n",
    "\n",
    "\n",
    "# a1=pd.DataFrame()\n",
    "# for i1 in pcc_top1:\n",
    "#     a1=pd.concat([a1,i1], axis=0)\n",
    "# a1.columns=['tr_TP', 'tr_TN', 'tr_FP', 'tr_FN', 'tr_Sen', 'tr_Spe', 'tr_Acc', 'tr_PPV', 'tr_NPV', 'tr_MCC', 'tr_AUC','TP',\n",
    "#        'TN', 'FP', 'FN', 'Sen', 'Spe', 'Acc', 'PPV', 'NPV', 'MCC', 'AUC','PCA']   \n",
    "\n",
    "# a1=a1.sort_values(['Acc','tr_Acc','PCA'], ascending=[False,False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a00ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_csv(input_path,i):\n",
    "\n",
    "    df_chunk=pd.read_csv(input_path,\n",
    "                         chunksize=10000,\n",
    "#                          sep='\\t'\n",
    "                        sep=i\n",
    "                        )\n",
    "    res_chunk=[]\n",
    "    for chunk in df_chunk:\n",
    "        res_chunk.append(chunk)\n",
    "    res_df=pd.concat(res_chunk)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d3ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measures_gridloo(label, score):\n",
    "    label = np.array(label)\n",
    "    score = np.array(score)\n",
    "    \n",
    "    N  = len(label)\n",
    "    TP = sum((label == 1) & (score == 1))\n",
    "    TN = sum((label == 0) & (score == 0))\n",
    "    FP = sum((label == 0) & (score == 1))\n",
    "    FN = sum((label == 1) & (score == 0))\n",
    "\n",
    "    # init all measures to nan\n",
    "    measures = {measure: float(\"nan\") for measure in (\"Sen\", \"Spe\", \"Acc\", \"PPV\", \"NPV\", \"MCC\",\"AUC\")}\n",
    "    \n",
    "    measures[\"TP\"] = TP\n",
    "    measures[\"TN\"] = TN\n",
    "    measures[\"FP\"] = FP\n",
    "    measures[\"FN\"] = FN\n",
    "    \n",
    "    S = (TP + FN) / N\n",
    "    P = (TP + FP) / N\n",
    "\n",
    "    if (TP + FN) > 0:\n",
    "        measures[\"Sen\"] = round(TP/(TP+FN), 4)\n",
    "\n",
    "    if (TN + FP) > 0:\n",
    "        measures[\"Spe\"] = round(TN/(TN+FP), 4)\n",
    "\n",
    "    if (TP + FP + FN + TN) > 0:\n",
    "        measures[\"Acc\"] = round((TP+TN)/(TP+FP+FN+TN), 4)\n",
    "\n",
    "    if (TP + FP) > 0:\n",
    "        measures[\"PPV\"] = round(TP/(TP+FP), 4)\n",
    "\n",
    "    if (TN + FN) > 0:\n",
    "        measures[\"NPV\"] = round(TN/(TN+FN), 4)\n",
    "\n",
    "    if (S*P*(1-S)*(1-P)) > 0:\n",
    "        measures[\"MCC\"] = round((TP/N - S*P)/(math.sqrt(S*P*(1-S)*(1-P))), 4)\n",
    "    \n",
    "    \n",
    "    measures[\"AUC\"]= roc_auc_score(label, score)\n",
    "    return pd.DataFrame([measures],\n",
    "                        columns=[\"TP\", \"TN\", \"FP\",\n",
    "                                 \"FN\", \"Sen\", \"Spe\", \"Acc\", \"PPV\", \"NPV\", \"MCC\",\"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d53b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVM\n",
    "def find_best_pca(i):\n",
    "    n_components=i\n",
    "    estimator = PCA(n_components=n_components,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    \n",
    "    scoring = {'AUC': 'roc_auc'}\n",
    "    cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "    gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "    parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "    \n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "    grid_search=GridSearchCV(estimator=SVC(random_state=10),param_grid=parameters,cv=cvx,scoring='accuracy')\n",
    "    grid_search.fit(pca_X_train, train_y)\n",
    "    \n",
    "    train_pre_y = cross_val_predict(grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "    test_pre_y = grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "    test_res1['PCA']=n_components\n",
    "    \n",
    "    res=pd.concat([train_res1,test_res1], axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4e5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_pca_lr(i):\n",
    "    n_components=i\n",
    "    estimator = PCA(n_components=n_components,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    \n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "\n",
    "    param_grid = {'penalty':['l2'],\n",
    "              \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],  \n",
    "              \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\"],\n",
    "#             \"C\":list(np.arange(0,0.1,0.005)),   \n",
    "#               \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\"]\n",
    "            }\n",
    "    LR_grid = LogisticRegression()\n",
    "    grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=9)\n",
    "    grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "\n",
    "    train_pre_y = cross_val_predict(grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "   \n",
    "\n",
    "    test_pre_y = grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "    test_res1['PCA']=n_components\n",
    "    \n",
    "    res=pd.concat([train_res1,test_res1], axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e5f27eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer='LUAD'\n",
    "path='D:\\\\lymph_meta_xmiseq\\\\tcga_data\\\\'\n",
    "# e1=\"./\"+cancer+\"_delta_pcc_wilcox.csv\"\n",
    "# delta_pcc=read_single_csv(e1,',')\n",
    "# delta_pcc=delta_pcc.drop(['Unnamed: 0','pair'],axis=1)\n",
    "# delta_pcc=delta_pcc.dropna(axis=0,how='any')\n",
    "\n",
    "# result=delta_pcc.T\n",
    "# train=result.iloc[:,0:-1].values.astype('float')\n",
    "# target=result.iloc[:,-1].values.astype('float')\n",
    "\n",
    "train=pd.read_csv(path+cancer+\"\\\\admat_final.csv\").iloc[:,2:].T.values\n",
    "target=pd.read_csv(path+cancer+\"\\\\gctm_label.csv\",index_col=0).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "986f9b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00874834, -0.00736022, -0.01710605, ...,  0.0059139 ,\n",
       "         0.00585509,  0.01760065],\n",
       "       [-0.06756009, -0.03635654, -0.06104614, ...,  0.00184041,\n",
       "         0.01073223, -0.00660949],\n",
       "       [ 0.05017487, -0.03385318, -0.05728117, ..., -0.01067972,\n",
       "         0.01398897,  0.01295414],\n",
       "       ...,\n",
       "       [-0.00012984,  0.00158047,  0.00504004, ...,  0.00526114,\n",
       "        -0.00421565, -0.0168382 ],\n",
       "       [-0.0120549 ,  0.0223974 , -0.02588812, ..., -0.03524445,\n",
       "         0.00812885,  0.01039054],\n",
       "       [ 0.00757404,  0.00548185,  0.02304116, ...,  0.00104388,\n",
       "         0.00138618, -0.0349668 ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a0046d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4d47e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=10\n",
    "                                                   )\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(train_X)\n",
    "X_standard = standardScaler.transform(train_X)\n",
    "X_standard_test = standardScaler.transform(test_X)\n",
    "\n",
    "n_components=0.95\n",
    "estimator = PCA(n_components=n_components,random_state=10)\n",
    "pca_X_train = estimator.fit_transform(X_standard)\n",
    "pca_X_test = estimator.transform(X_standard_test)\n",
    "cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4d3eaf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 2281)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "385399ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.45230769        nan 0.52369231 0.54769231\n",
      " 0.54769231 0.72153846 0.76123077 0.74523077        nan        nan\n",
      " 0.45230769        nan 0.50030769 0.75292308 0.75292308 0.75292308\n",
      " 0.79230769 0.75292308        nan        nan 0.45230769        nan\n",
      " 0.52369231 0.848      0.848      0.82430769 0.864      0.832\n",
      "        nan        nan 0.68246154        nan 0.75292308 0.888\n",
      " 0.888      0.87230769 0.88       0.88              nan        nan\n",
      " 0.92              nan 0.92       0.88061538 0.88061538 0.85661538\n",
      " 0.86461538 0.86461538        nan        nan 0.944             nan\n",
      " 0.936      0.84061538 0.84061538 0.86461538 0.86461538 0.87261538\n",
      "        nan        nan 0.944             nan 0.87261538 0.84861538\n",
      " 0.84861538 0.86461538 0.86461538 0.87261538        nan        nan\n",
      " 0.90430769        nan 0.87261538 0.85661538 0.85661538 0.84861538\n",
      " 0.86461538 0.87261538        nan        nan 0.80892308        nan\n",
      " 0.87261538 0.84861538 0.84861538 0.84061538 0.86461538 0.87261538]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=10, shuffle=True),\n",
       "             estimator=LogisticRegression(max_iter=1000), n_jobs=10,\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                               1000],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm\n",
    "scoring = {'AUC': 'roc_auc'}\n",
    "cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "\n",
    "svc_grid_search=GridSearchCV(estimator=SVC(random_state=10),param_grid=parameters,cv=cvx,scoring='accuracy')\n",
    "svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "#LR\n",
    "param_grid = {'penalty':['l1', 'l2'],\n",
    "              \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "#               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "            }\n",
    "LR_grid = LogisticRegression(max_iter=1000)\n",
    "LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=10)\n",
    "LR_grid_search.fit(pca_X_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c0fc0d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                LogisticRegression(C=1, max_iter=1000,\n",
       "                                                   penalty='l1',\n",
       "                                                   solver='liblinear')),\n",
       "                               ('svc',\n",
       "                                SVC(C=32, gamma=3.0517578125e-05,\n",
       "                                    random_state=10))],\n",
       "                   final_estimator=LinearSVC(C=5), n_jobs=10)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('lr', LR_grid_search.best_estimator_),\n",
    "    ('svc', svc_grid_search.best_estimator_),\n",
    "]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LinearSVC(C=5),n_jobs=10)\n",
    "clf.fit(pca_X_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "aa318404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                LogisticRegression(C=1, max_iter=1000,\n",
       "                                                   penalty='l1',\n",
       "                                                   solver='liblinear')),\n",
       "                               ('svc',\n",
       "                                SVC(C=32, gamma=3.0517578125e-05,\n",
       "                                    random_state=10))],\n",
       "                   final_estimator=LogisticRegression(C=100))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('lr', LR_grid_search.best_estimator_),\n",
    "    ('svc', svc_grid_search.best_estimator_),\n",
    "]\n",
    "\n",
    "param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                 LogisticRegression(C=0.1),LogisticRegression(C=1),LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                 LogisticRegression(C=1000)]}\n",
    "\n",
    "Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=10)\n",
    "Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "Stacking_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a1961530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "\n",
    "test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "test_res1=get_measures_gridloo(test_y,test_pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dfa32e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TP  TN  FP  FN     Sen     Spe     Acc     PPV     NPV     MCC       AUC\n",
      "0  64  50   7   5  0.9275  0.8772  0.9048  0.9014  0.9091  0.8076  0.902365\n",
      "   TP  TN  FP  FN  Sen  Spe  Acc  PPV  NPV  MCC  AUC\n",
      "0  30  24   0   0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_res1)\n",
    "print(test_res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ac3da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shpae:\n",
      "(195, 13022)\n",
      "range(10, 132, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.79777778\n",
      " 0.79777778 0.79778056 0.79778056 0.79778056        nan        nan\n",
      " 0.5               nan 0.5        0.80732387 0.80732387 0.80944027\n",
      " 0.80944027 0.80944027        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.80894737 0.80894737 0.81001392 0.80948482 0.80948482\n",
      "        nan        nan 0.80202172        nan 0.80202172 0.81582568\n",
      " 0.81582568 0.81529936 0.81529936 0.81477304        nan        nan\n",
      " 0.81265664        nan 0.81370927 0.8121359  0.8121359  0.81319131\n",
      " 0.8121359  0.812665          nan        nan 0.81477304        nan\n",
      " 0.81318853 0.8131941  0.8131941  0.8131941  0.812665   0.812665\n",
      "        nan        nan 0.8131941         nan 0.812665   0.8137232\n",
      " 0.8137232  0.8137232  0.8131941  0.812665          nan        nan\n",
      " 0.8131941         nan 0.812665   0.8137232  0.8137232  0.8137232\n",
      " 0.8131941  0.812665          nan        nan 0.8131941         nan\n",
      " 0.812665   0.8137232  0.8137232  0.8137232  0.8131941  0.812665  ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.80939293\n",
      " 0.80939293 0.80939293 0.80939293 0.80939293        nan        nan\n",
      " 0.5               nan 0.5        0.832665   0.832665   0.83161793\n",
      " 0.83161793 0.83161793        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.83691172 0.83691172 0.83637984 0.83637984 0.83637984\n",
      "        nan        nan 0.81314119        nan 0.81314119 0.85644946\n",
      " 0.85644946 0.85644946 0.85750487 0.85644946        nan        nan\n",
      " 0.84642439        nan 0.84695071 0.87281259 0.87281259 0.86912838\n",
      " 0.86595934 0.86226399        nan        nan 0.87335004        nan\n",
      " 0.86120579 0.87756057 0.87756057 0.8802005  0.86965748 0.86331941\n",
      "        nan        nan 0.87755778        nan 0.86331941 0.87755778\n",
      " 0.87755778 0.8780841  0.87018658 0.86331941        nan        nan\n",
      " 0.87755778        nan 0.86331941 0.87755778 0.87755778 0.87755778\n",
      " 0.87018658 0.86331941        nan        nan 0.87755778        nan\n",
      " 0.86331941 0.87755778 0.87755778 0.87755778 0.87018658 0.86331941]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81468672\n",
      " 0.81468672 0.8141604  0.8141604  0.8141604         nan        nan\n",
      " 0.5               nan 0.5        0.84112782 0.84112782 0.84218881\n",
      " 0.84218881 0.84218881        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.86174882 0.86174882 0.85964355 0.85964355 0.85964355\n",
      "        nan        nan 0.81208299        nan 0.81208299 0.88811473\n",
      " 0.88811473 0.88599276 0.88704818 0.88493734        nan        nan\n",
      " 0.8654386         nan 0.86385408 0.89019215 0.89019215 0.88864383\n",
      " 0.89180451 0.88599833        nan        nan 0.88915065        nan\n",
      " 0.88758563 0.88753551 0.88753551 0.89232804 0.89022556 0.88546923\n",
      "        nan        nan 0.88595656        nan 0.88494291 0.88542746\n",
      " 0.88489836 0.89176831 0.88917293 0.88494291        nan        nan\n",
      " 0.88436926        nan 0.88546923 0.88436926 0.88436926 0.88595377\n",
      " 0.8886494  0.88546923        nan        nan 0.88436926        nan\n",
      " 0.88494291 0.88436926 0.88436926 0.88436926 0.88864662 0.88546923]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81996658\n",
      " 0.81996658 0.81997215 0.81997215 0.81997215        nan        nan\n",
      " 0.5               nan 0.5        0.85328599 0.85328599 0.85381509\n",
      " 0.85381509 0.85381509        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88443331 0.88443331 0.88392091 0.88392091 0.88392091\n",
      "        nan        nan 0.81950153        nan 0.81897243 0.90602896\n",
      " 0.90602896 0.91183793 0.91236703 0.91236703        nan        nan\n",
      " 0.89128098        nan 0.89021442 0.89387914 0.89387914 0.90918129\n",
      " 0.90918964 0.91025063        nan        nan 0.90757728        nan\n",
      " 0.90919243 0.89598719 0.89598719 0.90811752 0.9112949  0.90866889\n",
      "        nan        nan 0.90810916        nan 0.91024784 0.89494013\n",
      " 0.89494013 0.90705931 0.91129212 0.90866889        nan        nan\n",
      " 0.90863548        nan 0.90866889 0.89546644 0.89546644 0.90811473\n",
      " 0.91129212 0.90866889        nan        nan 0.90547201        nan\n",
      " 0.90866889 0.89441381 0.89441381 0.91022278 0.91023949 0.90866889]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.82049568\n",
      " 0.82049568 0.81944305 0.81944305 0.81944305        nan        nan\n",
      " 0.5               nan 0.5        0.85327764 0.85327764 0.85169312\n",
      " 0.85169312 0.85221944        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88708716 0.88708716 0.88657477 0.88657199 0.88657199\n",
      "        nan        nan 0.80573656        nan 0.80573656 0.89076859\n",
      " 0.89076859 0.8912949  0.89288221 0.89235589        nan        nan\n",
      " 0.88495127        nan 0.88336118 0.88338067 0.88338067 0.87863548\n",
      " 0.8823169  0.88600111        nan        nan 0.87018379        nan\n",
      " 0.88653578 0.88970482 0.88970482 0.87758563 0.88336953 0.88652743\n",
      "        nan        nan 0.86491785        nan 0.88652743 0.88917572\n",
      " 0.88917572 0.87652186 0.88284043 0.88758563        nan        nan\n",
      " 0.87229184        nan 0.88705653 0.88390699 0.88390699 0.87494013\n",
      " 0.88389585 0.88758563        nan        nan 0.88019493        nan\n",
      " 0.88705653 0.88180173 0.88127541 0.87441103 0.88336953 0.88652743]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81890281\n",
      " 0.81890281 0.8189056  0.8189056  0.8189056         nan        nan\n",
      " 0.5               nan 0.5        0.84904205 0.84904205 0.85168198\n",
      " 0.85168198 0.85221108        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.89235867 0.89235867 0.89500696 0.89500696 0.89500696\n",
      "        nan        nan 0.80838207        nan 0.80785297 0.90976608\n",
      " 0.90976608 0.91242551 0.91347536 0.91347536        nan        nan\n",
      " 0.90240602        nan 0.90292398 0.90449735 0.90449735 0.89289613\n",
      " 0.90081314 0.90767196        nan        nan 0.89920356        nan\n",
      " 0.90872737 0.89500696 0.89500696 0.8807296  0.90344472 0.90767474\n",
      "        nan        nan 0.89443052        nan 0.90767474 0.89394598\n",
      " 0.89394598 0.8807296  0.90239209 0.90767474        nan        nan\n",
      " 0.88492063        nan 0.90767474 0.891824   0.891824   0.88019215\n",
      " 0.90238931 0.90767474        nan        nan 0.86219716        nan\n",
      " 0.90767474 0.8907658  0.88971317 0.87966583 0.90239209 0.90767474]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.8183765\n",
      " 0.8183765  0.8183765  0.8183765  0.8183765         nan        nan\n",
      " 0.5               nan 0.5        0.85062935 0.85062935 0.85116124\n",
      " 0.85116124 0.85168755        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88390977 0.88390977 0.88813422 0.88866332 0.88866332\n",
      "        nan        nan 0.80785297        nan 0.80679476 0.90397661\n",
      " 0.90397661 0.90399053 0.90557226 0.90451685        nan        nan\n",
      " 0.87653857        nan 0.88234754 0.89500139 0.89500139 0.88972988\n",
      " 0.89079087 0.89976608        nan        nan 0.87811473        nan\n",
      " 0.90188527 0.88971596 0.88971596 0.88340295 0.89184907 0.89924255\n",
      "        nan        nan 0.87496519        nan 0.89924534 0.88602896\n",
      " 0.88550265 0.87759955 0.89184907 0.89924255        nan        nan\n",
      " 0.87018379        nan 0.89871345 0.88549986 0.88602896 0.87654135\n",
      " 0.89290448 0.89765803        nan        nan 0.85009468        nan\n",
      " 0.89765803 0.88338903 0.88550265 0.87179337 0.89237817 0.89765803]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.82048454\n",
      " 0.82048454 0.81995823 0.81995823 0.81995823        nan        nan\n",
      " 0.5               nan 0.5        0.8511501  0.8511501  0.85590922\n",
      " 0.85538012 0.85538012        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.8955472  0.8955472  0.90029518 0.89976887 0.89976887\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.90927597\n",
      " 0.90927597 0.91246449 0.91246449 0.91141186        nan        nan\n",
      " 0.88976051        nan 0.89451406 0.89818435 0.89818435 0.89715957\n",
      " 0.90138123 0.90612921        nan        nan 0.89026455        nan\n",
      " 0.90770816 0.89292398 0.89292398 0.88818435 0.90243665 0.90665553\n",
      "        nan        nan 0.88184071        nan 0.90612643 0.88659705\n",
      " 0.88659705 0.88343637 0.90296575 0.90665553        nan        nan\n",
      " 0.86176831        nan 0.90665553 0.88396547 0.8850181  0.87869674\n",
      " 0.90296575 0.90665553        nan        nan 0.83483988        nan\n",
      " 0.90665553 0.88344194 0.88344194 0.87975494 0.90349485 0.90612643]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81784461\n",
      " 0.81784461 0.8178474  0.8178474  0.8178474         nan        nan\n",
      " 0.5               nan 0.5        0.8516792  0.8516792  0.85326371\n",
      " 0.85326371 0.85326371        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.89290727 0.89290727 0.8981927  0.8971345  0.8971345\n",
      "        nan        nan 0.80732387        nan 0.80679476 0.91352827\n",
      " 0.91352827 0.91564467 0.91564467 0.91617098        nan        nan\n",
      " 0.87658034        nan 0.88028126 0.90666388 0.90666388 0.90878307\n",
      " 0.91406572 0.91406015        nan        nan 0.88236981        nan\n",
      " 0.91299916 0.89928989 0.89928989 0.89875522 0.91406572 0.91353105\n",
      "        nan        nan 0.87289056        nan 0.91353105 0.89453356\n",
      " 0.89453356 0.89612086 0.91406572 0.91406015        nan        nan\n",
      " 0.86281537        nan 0.91353105 0.89137009 0.89084378 0.88769702\n",
      " 0.91353383 0.91406015        nan        nan 0.82426901        nan\n",
      " 0.91353105 0.88662211 0.89401281 0.88769424 0.91406294 0.91353105]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81731551\n",
      " 0.81731551 0.81784461 0.81784461 0.81784461        nan        nan\n",
      " 0.5               nan 0.5        0.85221108 0.85221108 0.85274018\n",
      " 0.85274018 0.85274018        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.89186578 0.89186578 0.89451128 0.89398218 0.89398218\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.91616541\n",
      " 0.91616541 0.91142022 0.9108939  0.91194653        nan        nan\n",
      " 0.88240323        nan 0.88556391 0.90667502 0.90667502 0.90455026\n",
      " 0.90350599 0.91036202        nan        nan 0.88819827        nan\n",
      " 0.9093066  0.90719577 0.90719577 0.90297132 0.90350599 0.9098357\n",
      "        nan        nan 0.87604288        nan 0.9087775  0.90666945\n",
      " 0.90666945 0.90457254 0.90350599 0.9098357         nan        nan\n",
      " 0.84537455        nan 0.9098357  0.90244222 0.90244222 0.89615706\n",
      " 0.9040323  0.9108939         nan        nan 0.82526873        nan\n",
      " 0.9103648  0.902445   0.90562796 0.89247006 0.90297689 0.91036202]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81783904\n",
      " 0.81783904 0.81784183 0.81784183 0.81784183        nan        nan\n",
      " 0.5               nan 0.5        0.8516792  0.8516792  0.85485102\n",
      " 0.85485102 0.8543247         nan        nan 0.78772765        nan\n",
      " 0.78772765 0.89608187 0.89608187 0.89873851 0.89873851 0.89873851\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.91351991\n",
      " 0.91351991 0.91247006 0.91246728 0.91299638        nan        nan\n",
      " 0.87817878        nan 0.88663047 0.90823726 0.90823726 0.90348649\n",
      " 0.90665274 0.90982735        nan        nan 0.86019493        nan\n",
      " 0.90455305 0.90612086 0.90612086 0.89978279 0.90665274 0.90982456\n",
      "        nan        nan 0.86178502        nan 0.90876915 0.90875522\n",
      " 0.90875522 0.89926483 0.90612364 0.90929546        nan        nan\n",
      " 0.85696463        nan 0.90929546 0.90770259 0.90770259 0.89344751\n",
      " 0.90612364 0.90982456        nan        nan 0.80358674        nan\n",
      " 0.90982456 0.90454191 0.90294625 0.89450014 0.90717906 0.90876636]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81837093\n",
      " 0.81837093 0.8173183  0.8173183  0.8173183         nan        nan\n",
      " 0.5               nan 0.5        0.85168755 0.85168755 0.85380117\n",
      " 0.85380117 0.85380117        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88816486 0.88816486 0.88974659 0.88974659 0.88922027\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.89449457\n",
      " 0.89502367 0.89713729 0.89713729 0.8971345         nan        nan\n",
      " 0.86601504        nan 0.86865776 0.88761348 0.88761348 0.88867446\n",
      " 0.89079087 0.89132554        nan        nan 0.85228627        nan\n",
      " 0.89186299 0.8828655  0.8828655  0.88392927 0.89079087 0.89185185\n",
      "        nan        nan 0.84858535        nan 0.89185185 0.88549986\n",
      " 0.88549986 0.87126706 0.89237538 0.89132554        nan        nan\n",
      " 0.81783904        nan 0.89132554 0.88338903 0.88444723 0.86493177\n",
      " 0.89184907 0.89185185        nan        nan 0.77718184        nan\n",
      " 0.89079644 0.88076023 0.88234754 0.86123642 0.89131997 0.89026734]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81836814\n",
      " 0.81836814 0.81784461 0.81784461 0.81784461        nan        nan\n",
      " 0.5               nan 0.5        0.8522083  0.8522083  0.85432749\n",
      " 0.85432749 0.85379838        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88499025 0.88499025 0.88711779 0.88711779 0.88711779\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.89238931\n",
      " 0.89238931 0.89239488 0.89239488 0.89239209        nan        nan\n",
      " 0.8591061         nan 0.87549986 0.88552214 0.88552214 0.8897633\n",
      " 0.89028683 0.89345586        nan        nan 0.86018658        nan\n",
      " 0.89028683 0.88235032 0.88235032 0.88553885 0.89028126 0.89292398\n",
      "        nan        nan 0.85120301        nan 0.89397939 0.87971039\n",
      " 0.87971039 0.87602896 0.88975494 0.89292676        nan        nan\n",
      " 0.83211083        nan 0.89292398 0.87812865 0.87760234 0.86018936\n",
      " 0.89028126 0.89239766        nan        nan 0.73969925        nan\n",
      " 0.89292398 0.87549708 0.87655528 0.85753829 0.88975216 0.89345308]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components:\n",
      "110\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################random seed loop#################\n",
    "train_scores=[]\n",
    "test_scores=[]\n",
    "loopn=1\n",
    "scoring='roc_auc'\n",
    "#np.random.seed(42)\n",
    "random_states=np.random.choice(range(101), loopn, replace=False)\n",
    "\n",
    "tmp_train=[]\n",
    "tmp_test=[]\n",
    "#print(random_states)\n",
    "for i in range(loopn):\n",
    "    train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=10\n",
    "                                                   )\n",
    "    print(\"train_x.shpae:\")\n",
    "    print(train_X.shape)\n",
    "\n",
    "    standardScaler = StandardScaler()\n",
    "    standardScaler.fit(train_X)\n",
    "    X_standard = standardScaler.transform(train_X)\n",
    "    X_standard_test = standardScaler.transform(test_X)\n",
    "    #calculate max n_components\n",
    "    estimator = PCA(n_components=0.95,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "\n",
    "    n_components=range(10,min(pca_X_train.shape),10)\n",
    "    print(n_components)\n",
    "    #n_components=[0.99,0.95,0.90,0.85]\n",
    "    best_pca_train_scores=[]\n",
    "    best_pca_test_scores=[]\n",
    "    for j in n_components:\n",
    "        estimator = PCA(n_components=j,random_state=10)\n",
    "        pca_X_train = estimator.fit_transform(X_standard)\n",
    "        pca_X_test = estimator.transform(X_standard_test)\n",
    "        cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "    \n",
    "        #scoring = {'AUC': 'roc_auc'}\n",
    "        cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "        gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "        parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "\n",
    "        svc_grid_search=GridSearchCV(estimator=SVC(random_state=10),\n",
    "                                     param_grid=parameters,cv=cvx,scoring=scoring)\n",
    "        svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "        param_grid = {'penalty':['l1', 'l2'],\n",
    "                      \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                      \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "    #               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                    }\n",
    "        LR_grid = LogisticRegression(max_iter=1000, random_state=10)\n",
    "        LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring=scoring,n_jobs=10)\n",
    "        LR_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "        estimators = [\n",
    "            ('lr', LR_grid_search.best_estimator_),\n",
    "            ('svc', svc_grid_search.best_estimator_),\n",
    "        ]\n",
    "        clf = StackingClassifier(estimators=estimators, final_estimator=LinearSVC(C=5, random_state=10),\n",
    "                                 n_jobs=10)\n",
    "        clf.fit(pca_X_train, train_y)\n",
    "\n",
    "        estimators = [\n",
    "            ('lr', LR_grid_search.best_estimator_),\n",
    "            ('svc', svc_grid_search.best_estimator_),\n",
    "        ]\n",
    "\n",
    "        param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),\n",
    "                                         LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                         LogisticRegression(C=0.1),LogisticRegression(C=1),\n",
    "                                         LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                         LogisticRegression(C=1000)]}\n",
    "\n",
    "        Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "        Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx,\n",
    "                                            scoring=scoring,n_jobs=10)\n",
    "        Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "        Stacking_grid_search.best_estimator_\n",
    "\n",
    "        train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "        train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "\n",
    "        test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "        test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "        \n",
    "        best_pca_train_scores.append(train_res1.loc[:,\"AUC\"])\n",
    "        best_pca_test_scores.append(test_res1.loc[:,\"AUC\"])\n",
    "    \n",
    "    train_scores.append(np.max(best_pca_train_scores))\n",
    "    test_scores.append(best_pca_test_scores[np.argmax(best_pca_train_scores)])\n",
    "    print(\"n_components:\")\n",
    "    print(n_components[np.argmax(best_pca_train_scores)])\n",
    "    \n",
    "    tmp_train.append(best_pca_train_scores)\n",
    "    tmp_test.append(best_pca_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "89e38686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "0.8376952300548755\n",
      "0.7829059829059828\n",
      "std\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0    0.754221\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.809941\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.805087\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.827406\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.797119\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.811102\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.795958\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.805667\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.826826\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.833421\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.837695\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.817697\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.822552\n",
       "Name: AUC, dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0    0.754221\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.809941\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.805087\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.827406\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.797119\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.811102\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.795958\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.805667\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.826826\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.833421\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.837695\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.817697\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.827986\n",
       "Name: AUC, dtype: float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0   \\\n",
       "0  0    0.754221\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.754221\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        1   \\\n",
       "0  0    0.809941\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.809941\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        2   \\\n",
       "0  0    0.805087\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.805087\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        3   \\\n",
       "0  0    0.827406\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.827406\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        4   \\\n",
       "0  0    0.797119\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.797119\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        5   \\\n",
       "0  0    0.811102\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.811102\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        6   \\\n",
       "0  0    0.795958\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.795958\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        7   \\\n",
       "0  0    0.805667\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.805667\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        8   \\\n",
       "0  0    0.826826\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.826826\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        9   \\\n",
       "0  0    0.833421\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.833421\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        10  \\\n",
       "0  0    0.837695\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.837695\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        11  \\\n",
       "0  0    0.817697\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.817697\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        12  \n",
       "0  0    0.822552\n",
       "Name: AUC, dtype: float64  \n",
       "1  0    0.827986\n",
       "Name: AUC, dtype: float64  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('mean')\n",
    "print(np.mean(train_scores))\n",
    "print(np.mean(test_scores))\n",
    "print(\"std\")\n",
    "print(np.std(train_scores))\n",
    "print(np.std(test_scores))\n",
    "pd.DataFrame(tmp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "03767256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9295183982683983]\n",
      "[0    0.940972\n",
      "Name: AUC, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "print(train_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360d174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0cc7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shpae:\n",
      "(255, 13613)\n",
      "range(10, 216, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.71655702\n",
      " 0.71655702 0.72301635 0.72301635 0.72301635        nan        nan\n",
      " 0.5               nan 0.5        0.73521066 0.73521066 0.72824849\n",
      " 0.7295953  0.72925859        nan        nan 0.5               nan\n",
      " 0.5        0.76243576 0.76243576 0.74438242 0.74604266 0.74240874\n",
      "        nan        nan 0.72419258        nan 0.72582957 0.80898791\n",
      " 0.80898791 0.75338805 0.75239345 0.75300483        nan        nan\n",
      " 0.76455675        nan 0.74571372 0.81916977 0.81916977 0.77649189\n",
      " 0.7533958  0.75070995        nan        nan 0.81654594        nan\n",
      " 0.74937865 0.82114345 0.82114345 0.81255981 0.75273791 0.75005206\n",
      "        nan        nan 0.82114345        nan 0.75005206 0.8214724\n",
      " 0.8214724  0.8211357  0.75240896 0.74972311        nan        nan\n",
      " 0.8214724         nan 0.74972311 0.82114345 0.82114345 0.8214724\n",
      " 0.75240896 0.74972311        nan        nan 0.8214724         nan\n",
      " 0.74972311 0.82114345 0.82114345 0.8214724  0.75240896 0.74972311]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.74301236\n",
      " 0.74301236 0.74912724 0.74912724 0.74912724        nan        nan\n",
      " 0.5               nan 0.5        0.77950669 0.77950669 0.77786195\n",
      " 0.77786195 0.77786195        nan        nan 0.5               nan\n",
      " 0.5        0.82354355 0.82354355 0.79549774 0.79582669 0.79549774\n",
      "        nan        nan 0.77021863        nan 0.76952973 0.83794746\n",
      " 0.83794746 0.81838118 0.81736333 0.80517677        nan        nan\n",
      " 0.8123981         nan 0.80708843 0.85539717 0.85539717 0.82710438\n",
      " 0.81935252 0.80616361        nan        nan 0.85114412        nan\n",
      " 0.8078161  0.85901559 0.85901559 0.84777379 0.81902357 0.80583466\n",
      "        nan        nan 0.85802875        nan 0.80583466 0.85868665\n",
      " 0.85868665 0.85705742 0.81903132 0.80583466        nan        nan\n",
      " 0.85868665        nan 0.80583466 0.85901559 0.85901559 0.85868665\n",
      " 0.81903132 0.80583466        nan        nan 0.85901559        nan\n",
      " 0.80583466 0.85901559 0.85901559 0.85901559 0.81903132 0.80583466]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.74796983\n",
      " 0.74796983 0.75476586 0.75476586 0.75476586        nan        nan\n",
      " 0.5               nan 0.5        0.79245968 0.79245968 0.79285066\n",
      " 0.79318736 0.79318736        nan        nan 0.5               nan\n",
      " 0.5        0.82582292 0.82582292 0.80225501 0.80258395 0.80225501\n",
      "        nan        nan 0.77285797        nan 0.77282695 0.83179049\n",
      " 0.83179049 0.80386098 0.80088495 0.79002193        nan        nan\n",
      " 0.80454213        nan 0.79369462 0.83208068 0.83208068 0.80679825\n",
      " 0.80319533 0.79002968        nan        nan 0.82780436        nan\n",
      " 0.79068758 0.83110159 0.83110159 0.81946106 0.80352428 0.79035863\n",
      "        nan        nan 0.83110159        nan 0.79002968 0.83108608\n",
      " 0.83108608 0.82977029 0.80352428 0.79035863        nan        nan\n",
      " 0.83108608        nan 0.79035863 0.83108608 0.83108608 0.83109383\n",
      " 0.80352428 0.79035863        nan        nan 0.83108608        nan\n",
      " 0.79035863 0.83108608 0.83108608 0.83108608 0.80352428 0.79035863]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.7552842\n",
      " 0.7552842  0.76205697 0.76205697 0.76205697        nan        nan\n",
      " 0.5               nan 0.5        0.79570264 0.79570264 0.7987407\n",
      " 0.7987407  0.7987407         nan        nan 0.5               nan\n",
      " 0.5        0.82837697 0.82837697 0.80776183 0.80874867 0.80907762\n",
      "        nan        nan 0.77087653        nan 0.77018762 0.81718501\n",
      " 0.81718501 0.79195685 0.79128345 0.79326489        nan        nan\n",
      " 0.78955343        nan 0.7919491  0.80988614 0.80988614 0.79871411\n",
      " 0.78567584 0.79126794        nan        nan 0.80992491        nan\n",
      " 0.78995215 0.80787369 0.80787369 0.80331938 0.78501019 0.79160464\n",
      "        nan        nan 0.8075525         nan 0.79160464 0.80489766\n",
      " 0.80489766 0.80430954 0.78501019 0.79160464        nan        nan\n",
      " 0.80555556        nan 0.79160464 0.80555556 0.80555556 0.80523436\n",
      " 0.78501019 0.79160464        nan        nan 0.80555556        nan\n",
      " 0.79160464 0.8058845  0.80555556 0.80555556 0.78501019 0.79160464]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76323321\n",
      " 0.76323321 0.76835349 0.76835349 0.76835349        nan        nan\n",
      " 0.5               nan 0.5        0.81424774 0.81424774 0.81956517\n",
      " 0.81957292 0.81957292        nan        nan 0.5               nan\n",
      " 0.5        0.87377614 0.87410509 0.85511142 0.85477472 0.85443802\n",
      "        nan        nan 0.77354687        nan 0.77486266 0.87085438\n",
      " 0.87085438 0.83447302 0.83610225 0.83871832        nan        nan\n",
      " 0.8204479         nan 0.83634592 0.86858276 0.86858276 0.82924087\n",
      " 0.83150474 0.8350999         nan        nan 0.83075381        nan\n",
      " 0.83410531 0.85213539 0.85213539 0.82742225 0.83183369 0.83444976\n",
      "        nan        nan 0.83835061        nan 0.83411306 0.83968191\n",
      " 0.83968191 0.83206185 0.83183369 0.83444976        nan        nan\n",
      " 0.83836612        nan 0.83444976 0.83770822 0.83770822 0.83506114\n",
      " 0.83183369 0.83444976        nan        nan 0.83705033        nan\n",
      " 0.83444976 0.83672138 0.83672138 0.83705033 0.83183369 0.83444976]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.7635544\n",
      " 0.7635544  0.76999823 0.76999823 0.76999823        nan        nan\n",
      " 0.5               nan 0.5        0.81758373 0.81758373 0.8186326\n",
      " 0.8186326  0.8186326         nan        nan 0.5               nan\n",
      " 0.5        0.87579634 0.87579634 0.8535132  0.85316875 0.8531765\n",
      "        nan        nan 0.79469254        nan 0.79500598 0.86934919\n",
      " 0.86934919 0.83427587 0.83621855 0.83914806        nan        nan\n",
      " 0.8234782         nan 0.83144272 0.82552166 0.82552166 0.8029716\n",
      " 0.82966286 0.83552189        nan        nan 0.78171739        nan\n",
      " 0.83485624 0.79547116 0.79580011 0.77468213 0.82833931 0.83552189\n",
      "        nan        nan 0.76737108        nan 0.83552189 0.77330764\n",
      " 0.77364434 0.75227051 0.82866826 0.83552189        nan        nan\n",
      " 0.76437179        nan 0.83552189 0.76867136 0.76867136 0.75414341\n",
      " 0.82866826 0.83552189        nan        nan 0.75776183        nan\n",
      " 0.83552189 0.76634547 0.76704213 0.75081517 0.82866826 0.83552189]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76323321\n",
      " 0.76323321 0.77232412 0.77232412 0.77232412        nan        nan\n",
      " 0.5               nan 0.5        0.81725478 0.81725478 0.82224327\n",
      " 0.82225102 0.82225102        nan        nan 0.5               nan\n",
      " 0.5        0.8864312  0.8864312  0.86373383 0.86537857 0.86570751\n",
      "        nan        nan 0.78444865        nan 0.78344631 0.87843567\n",
      " 0.87843567 0.84239102 0.84439571 0.84832757        nan        nan\n",
      " 0.82517721        nan 0.83739478 0.85659335 0.85659335 0.82256114\n",
      " 0.83714336 0.84339336        nan        nan 0.80754918        nan\n",
      " 0.84372231 0.81632554 0.81632554 0.78730507 0.83748006 0.84372231\n",
      "        nan        nan 0.77223884        nan 0.84372231 0.79316742\n",
      " 0.79316742 0.76836124 0.83682217 0.84372231        nan        nan\n",
      " 0.77769914        nan 0.84372231 0.78557062 0.78524167 0.76309809\n",
      " 0.83682217 0.84372231        nan        nan 0.78071394        nan\n",
      " 0.84372231 0.78293904 0.78359693 0.76309809 0.83682217 0.84372231]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76257531\n",
      " 0.76257531 0.76933258 0.76933258 0.76900363        nan        nan\n",
      " 0.5               nan 0.5        0.81529661 0.81529661 0.82160863\n",
      " 0.82095074 0.82095074        nan        nan 0.5               nan\n",
      " 0.5        0.8899876  0.8899876  0.86541733 0.86574628 0.86573853\n",
      "        nan        nan 0.77220007        nan 0.77217681 0.88929094\n",
      " 0.88929094 0.84341662 0.84605595 0.84802964        nan        nan\n",
      " 0.80966241        nan 0.84069976 0.86053296 0.86053296 0.80864456\n",
      " 0.8397827  0.84572701        nan        nan 0.79661638        nan\n",
      " 0.84507687 0.84025009 0.84025009 0.79055578 0.83945375 0.84540581\n",
      "        nan        nan 0.77347377        nan 0.84573476 0.8296695\n",
      " 0.8296695  0.78852007 0.8391248  0.84573476        nan        nan\n",
      " 0.78852782        nan 0.84606371 0.82606659 0.82606659 0.78854333\n",
      " 0.8391248  0.84573476        nan        nan 0.79701068        nan\n",
      " 0.84573476 0.82044347 0.82078017 0.78526936 0.8391248  0.84573476]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76223086\n",
      " 0.76223086 0.77066388 0.77066388 0.77066388        nan        nan\n",
      " 0.5               nan 0.5        0.81559454 0.81559454 0.82090422\n",
      " 0.82057527 0.81991738        nan        nan 0.5               nan\n",
      " 0.5        0.8837531  0.8837531  0.86371832 0.86371832 0.86338162\n",
      "        nan        nan 0.77120548        nan 0.77151892 0.88991782\n",
      " 0.88991782 0.84665183 0.84698077 0.85064571        nan        nan\n",
      " 0.82912458        nan 0.84040958 0.85457314 0.85457314 0.80204235\n",
      " 0.84499934 0.84932217        nan        nan 0.77967393        nan\n",
      " 0.84800638 0.82914341 0.82914341 0.77323011 0.84467039 0.84932217\n",
      "        nan        nan 0.76298622        nan 0.84899322 0.81756047\n",
      " 0.81756047 0.75868665 0.84467039 0.84932217        nan        nan\n",
      " 0.75430179        nan 0.84932217 0.8115929  0.8115929  0.75407363\n",
      " 0.84467039 0.84932217        nan        nan 0.77365541        nan\n",
      " 0.84932217 0.80792796 0.80727007 0.75142655 0.84467039 0.84932217]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76090732\n",
      " 0.76090732 0.76898813 0.76898813 0.76898813        nan        nan\n",
      " 0.5               nan 0.5        0.81496766 0.81496766 0.82091197\n",
      " 0.81992513 0.81992513        nan        nan 0.5               nan\n",
      " 0.5        0.88742579 0.88742579 0.86437622 0.86536306 0.86470517\n",
      "        nan        nan 0.77120548        nan 0.77184786 0.8863149\n",
      " 0.8863149  0.83444976 0.8430334  0.84635389        nan        nan\n",
      " 0.79972422        nan 0.82914784 0.84112507 0.84112507 0.78647329\n",
      " 0.83809144 0.8450381         nan        nan 0.77384149        nan\n",
      " 0.84438021 0.81915869 0.81915869 0.76589248 0.83743355 0.8450381\n",
      "        nan        nan 0.75097355        nan 0.8450381  0.81185207\n",
      " 0.81185207 0.76190634 0.83743355 0.8450381         nan        nan\n",
      " 0.74821792        nan 0.8450381  0.80622896 0.80622896 0.75562533\n",
      " 0.83743355 0.8450381         nan        nan 0.76569865        nan\n",
      " 0.8450381  0.80320641 0.80319865 0.75329944 0.83743355 0.8450381 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76054736\n",
      " 0.76054736 0.76864367 0.76864367 0.76864367        nan        nan\n",
      " 0.5               nan 0.5        0.81623693 0.81623693 0.82190657\n",
      " 0.82157762 0.82157762        nan        nan 0.5               nan\n",
      " 0.5        0.88864855 0.88864855 0.86960061 0.87026626 0.86960061\n",
      "        nan        nan 0.77252127        nan 0.77250576 0.88492158\n",
      " 0.88492158 0.83988681 0.85277778 0.85712387        nan        nan\n",
      " 0.81869462        nan 0.84094343 0.83765727 0.83765727 0.78707691\n",
      " 0.84751462 0.85414009        nan        nan 0.76726254        nan\n",
      " 0.8538344  0.81216551 0.81216551 0.76889177 0.84619883 0.85381114\n",
      "        nan        nan 0.74870968        nan 0.85348219 0.8058845\n",
      " 0.8058845  0.7605828  0.84619883 0.85348219        nan        nan\n",
      " 0.7489611         nan 0.85381114 0.80190612 0.80157718 0.75334596\n",
      " 0.84619883 0.85348219        nan        nan 0.75975434        nan\n",
      " 0.85348219 0.797951   0.79531942 0.74708045 0.84619883 0.85348219]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76021066\n",
      " 0.76021066 0.76831473 0.76831473 0.76831473        nan        nan\n",
      " 0.5               nan 0.5        0.81724703 0.81724703 0.82059853\n",
      " 0.82059853 0.82026958        nan        nan 0.5               nan\n",
      " 0.5        0.89131889 0.89131889 0.86997608 0.87162081 0.87095517\n",
      "        nan        nan 0.77219232        nan 0.77184786 0.89410885\n",
      " 0.89410885 0.84713915 0.85445353 0.8590898         nan        nan\n",
      " 0.81258418        nan 0.84095893 0.84293594 0.84293594 0.80325735\n",
      " 0.84554094 0.85612928        nan        nan 0.77284689        nan\n",
      " 0.85449229 0.82343501 0.82343501 0.77974703 0.84521199 0.85579257\n",
      "        nan        nan 0.75764553        nan 0.85580033 0.81850855\n",
      " 0.81850855 0.77083444 0.84521199 0.85579257        nan        nan\n",
      " 0.76586147        nan 0.85579257 0.81285442 0.81252547 0.76752171\n",
      " 0.84521199 0.85579257        nan        nan 0.77768031        nan\n",
      " 0.85579257 0.80922049 0.81154638 0.76224304 0.84521199 0.85579257]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76086855\n",
      " 0.76086855 0.76766458 0.76766458 0.76766458        nan        nan\n",
      " 0.5               nan 0.5        0.81326865 0.81326865 0.81533537\n",
      " 0.81533537 0.81500642        nan        nan 0.5               nan\n",
      " 0.5        0.8744883  0.8744883  0.85645822 0.85645822 0.85711612\n",
      "        nan        nan 0.77252127        nan 0.77217681 0.86703438\n",
      " 0.86703438 0.8191166  0.83202308 0.83933745        nan        nan\n",
      " 0.79497165        nan 0.82549065 0.83301325 0.83301325 0.78139952\n",
      " 0.82740231 0.83669037        nan        nan 0.75179758        nan\n",
      " 0.83802166 0.82339624 0.82339624 0.77174375 0.82740231 0.83635367\n",
      "        nan        nan 0.74485867        nan 0.83702707 0.81712298\n",
      " 0.81712298 0.76613614 0.82740231 0.83669037        nan        nan\n",
      " 0.74416201        nan 0.83669037 0.8134813  0.81381025 0.75358187\n",
      " 0.82740231 0.83669037        nan        nan 0.76794701        nan\n",
      " 0.83669037 0.8128079  0.8128079  0.75286971 0.82740231 0.83669037]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.75988946\n",
      " 0.75988946 0.76732788 0.76699894 0.76699894        nan        nan\n",
      " 0.5               nan 0.5        0.81162391 0.81162391 0.81630671\n",
      " 0.81597776 0.81597776        nan        nan 0.5               nan\n",
      " 0.5        0.87679869 0.87679869 0.85775075 0.85775075 0.85775075\n",
      "        nan        nan 0.77219232        nan 0.77184786 0.87301746\n",
      " 0.87301746 0.82083112 0.8307383  0.83897749        nan        nan\n",
      " 0.80180976        nan 0.83964314 0.85021155 0.85021155 0.79762648\n",
      " 0.8221314  0.83336988        nan        nan 0.73896863        nan\n",
      " 0.83800616 0.83331893 0.83331893 0.78799397 0.82048666 0.83237529\n",
      "        nan        nan 0.72599238        nan 0.83270424 0.82502547\n",
      " 0.82502547 0.78005272 0.82048666 0.83237529        nan        nan\n",
      " 0.73216485        nan 0.83237529 0.82034268 0.81935584 0.76948764\n",
      " 0.82048666 0.83237529        nan        nan 0.77095406        nan\n",
      " 0.83237529 0.81638756 0.81374823 0.7688375  0.82048666 0.83237529]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.75955276\n",
      " 0.75955276 0.76666999 0.76601209 0.76601209        nan        nan\n",
      " 0.5               nan 0.5        0.8139343  0.8139343  0.81564106\n",
      " 0.81530436 0.81497541        nan        nan 0.5               nan\n",
      " 0.5        0.87778553 0.87778553 0.85840865 0.86071903 0.86006114\n",
      "        nan        nan 0.77219232        nan 0.77184786 0.87375288\n",
      " 0.87375288 0.8340743  0.84298689 0.84494506        nan        nan\n",
      " 0.79795543        nan 0.83571903 0.83953017 0.83953017 0.79627968\n",
      " 0.8340743  0.84396598        nan        nan 0.73020667        nan\n",
      " 0.84663632 0.82884104 0.82884104 0.77866715 0.83440324 0.84396598\n",
      "        nan        nan 0.7075824         nan 0.84363703 0.82386031\n",
      " 0.82386031 0.7759658  0.83440324 0.84396598        nan        nan\n",
      " 0.7230241         nan 0.84429492 0.82220007 0.82252902 0.76540847\n",
      " 0.83440324 0.84396598        nan        nan 0.77506756        nan\n",
      " 0.84396598 0.82086102 0.81853513 0.76542398 0.83440324 0.84396598]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.75789252\n",
      " 0.75789252 0.7650175  0.7650175  0.7650175         nan        nan\n",
      " 0.5               nan 0.5        0.81027711 0.81027711 0.81429426\n",
      " 0.81396531 0.81330742        nan        nan 0.5               nan\n",
      " 0.5        0.88340089 0.88340089 0.86693802 0.86593567 0.86527002\n",
      "        nan        nan 0.77219232        nan 0.77184786 0.87669015\n",
      " 0.87669015 0.82645424 0.83669812 0.84690324        nan        nan\n",
      " 0.78633373        nan 0.82314926 0.83693736 0.83693736 0.78280835\n",
      " 0.83040936 0.84494506        nan        nan 0.73320596        nan\n",
      " 0.84593191 0.81249446 0.81249446 0.764271   0.83040936 0.84330033\n",
      "        nan        nan 0.71358874        nan 0.84428717 0.8048744\n",
      " 0.80454545 0.75760677 0.83008041 0.84330033        nan        nan\n",
      " 0.70137892        nan 0.84362928 0.79892234 0.79826444 0.74375997\n",
      " 0.83008041 0.84330033        nan        nan 0.73614323        nan\n",
      " 0.84330033 0.79563286 0.79666622 0.73884902 0.83008041 0.84330033]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.75921606\n",
      " 0.75921606 0.76799353 0.76799353 0.76799353        nan        nan\n",
      " 0.5               nan 0.5        0.81492889 0.81492889 0.8169491\n",
      " 0.81695685 0.81695685        nan        nan 0.5               nan\n",
      " 0.5        0.88572679 0.88572679 0.86862152 0.86927166 0.86860602\n",
      "        nan        nan 0.77219232        nan 0.77184786 0.89161683\n",
      " 0.89161683 0.85132687 0.85722466 0.85751484        nan        nan\n",
      " 0.82064505        nan 0.84523525 0.85911638 0.85911638 0.81155857\n",
      " 0.84965887 0.8562068         nan        nan 0.76349681        nan\n",
      " 0.85753035 0.84156588 0.84156588 0.79033537 0.84933767 0.8562068\n",
      "        nan        nan 0.74949495        nan 0.8562068  0.83463472\n",
      " 0.83430578 0.78495592 0.84933767 0.8562068         nan        nan\n",
      " 0.74666622        nan 0.8562068  0.82997519 0.8293173  0.77215798\n",
      " 0.84933767 0.8562068         nan        nan 0.76639531        nan\n",
      " 0.8562068  0.82568337 0.82637228 0.76194511 0.84933767 0.8562068 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.75790027\n",
      " 0.75790027 0.76469631 0.76469631 0.76469631        nan        nan\n",
      " 0.5               nan 0.5        0.80796673 0.80796673 0.81298622\n",
      " 0.81298622 0.81298622        nan        nan 0.5               nan\n",
      " 0.5        0.87616405 0.87616405 0.86104023 0.86335061 0.86235602\n",
      "        nan        nan 0.77219232        nan 0.77184786 0.88144272\n",
      " 0.88144272 0.83382288 0.84467814 0.85220517        nan        nan\n",
      " 0.77481282        nan 0.81921739 0.84960792 0.84960792 0.7941011\n",
      " 0.83939948 0.84727096        nan        nan 0.72986665        nan\n",
      " 0.84562622 0.83833843 0.83833843 0.78439106 0.83874934 0.84628411\n",
      "        nan        nan 0.70409246        nan 0.84628411 0.83039717\n",
      " 0.83006823 0.78501019 0.83874934 0.84628411        nan        nan\n",
      " 0.70470384        nan 0.84628411 0.82640329 0.82507974 0.76505626\n",
      " 0.83874934 0.84628411        nan        nan 0.72913455        nan\n",
      " 0.84628411 0.82339624 0.82574539 0.74528066 0.83874934 0.84628411]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.75723463\n",
      " 0.75723463 0.76601985 0.7656909  0.7656909         nan        nan\n",
      " 0.5               nan 0.5        0.80962697 0.80962697 0.81366738\n",
      " 0.81366738 0.81366738        nan        nan 0.5               nan\n",
      " 0.5        0.88015794 0.88015794 0.86371057 0.86566875 0.86501085\n",
      "        nan        nan 0.77219232        nan 0.77184786 0.88635367\n",
      " 0.88635367 0.84177189 0.84867978 0.85225944        nan        nan\n",
      " 0.77026958        nan 0.81891946 0.85985181 0.85952286 0.80540936\n",
      " 0.84573476 0.8499568         nan        nan 0.72525031        nan\n",
      " 0.8496201  0.84134547 0.84134547 0.79078837 0.84507687 0.8506147\n",
      "        nan        nan 0.71553252        nan 0.8499568  0.83377968\n",
      " 0.83377968 0.78352051 0.84540581 0.8499568         nan        nan\n",
      " 0.71262626        nan 0.85028575 0.82948011 0.82984007 0.75508373\n",
      " 0.84540581 0.8499568         nan        nan 0.75662768        nan\n",
      " 0.85028575 0.83052897 0.83061426 0.74946837 0.84540581 0.8499568 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.75690568\n",
      " 0.75690568 0.7656909  0.7656909  0.7656909         nan        nan\n",
      " 0.5               nan 0.5        0.80896132 0.80896132 0.81234383\n",
      " 0.81168594 0.81135699        nan        nan 0.5               nan\n",
      " 0.5        0.87950004 0.87950004 0.86503411 0.86436071 0.86370282\n",
      "        nan        nan 0.77219232        nan 0.77184786 0.88242956\n",
      " 0.88242956 0.84709707 0.85462409 0.85723241        nan        nan\n",
      " 0.78901183        nan 0.82185673 0.86516148 0.86516148 0.81934919\n",
      " 0.84905525 0.85361399        nan        nan 0.76486355        nan\n",
      " 0.85063796 0.85025031 0.85025031 0.80810296 0.84972089 0.8529561\n",
      "        nan        nan 0.7492247         nan 0.85262715 0.84403132\n",
      " 0.84403132 0.80109428 0.84972089 0.8529561         nan        nan\n",
      " 0.74037414        nan 0.8529561  0.83745237 0.83646553 0.78024654\n",
      " 0.84972089 0.8529561         nan        nan 0.73965754        nan\n",
      " 0.8529561  0.83684875 0.83557173 0.77364434 0.84972089 0.8529561 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=10\n",
    "                                                   )\n",
    "print(\"train_x.shpae:\")\n",
    "print(train_X.shape)\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(train_X)\n",
    "X_standard = standardScaler.transform(train_X)\n",
    "X_standard_test = standardScaler.transform(test_X)\n",
    "    #calculate max n_components\n",
    "estimator = PCA(n_components=0.99,random_state=10)\n",
    "pca_X_train = estimator.fit_transform(X_standard)\n",
    "\n",
    "n_components=range(10,min(pca_X_train.shape),10)\n",
    "print(n_components)\n",
    "    #n_components=[0.99,0.95,0.90,0.85]\n",
    "best_pca_train_scores=[]\n",
    "best_pca_test_scores=[]\n",
    "for j in n_components:\n",
    "    estimator = PCA(n_components=j,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "    \n",
    "        #scoring = {'AUC': 'roc_auc'}\n",
    "    cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "    gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "    parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "\n",
    "    svc_grid_search=GridSearchCV(estimator=SVC(random_state=10),\n",
    "                                 param_grid=parameters,cv=cvx,scoring=scoring)\n",
    "    svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "    param_grid = {'penalty':['l1', 'l2'],\n",
    "                  \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                  \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "    #               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                  }\n",
    "    LR_grid = LogisticRegression(max_iter=1000, random_state=10)\n",
    "    LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring=scoring,n_jobs=10)\n",
    "    LR_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "    estimators = [\n",
    "        ('lr', LR_grid_search.best_estimator_),\n",
    "        ('svc', svc_grid_search.best_estimator_),\n",
    "    ]\n",
    "    clf = StackingClassifier(estimators=estimators, final_estimator=LinearSVC(C=5, random_state=10),\n",
    "                             n_jobs=10)\n",
    "    clf.fit(pca_X_train, train_y)\n",
    "\n",
    "    estimators = [\n",
    "        ('lr', LR_grid_search.best_estimator_),\n",
    "        ('svc', svc_grid_search.best_estimator_),\n",
    "    ]\n",
    "\n",
    "    param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),\n",
    "                                    LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                    LogisticRegression(C=0.1),LogisticRegression(C=1),\n",
    "                                    LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                    LogisticRegression(C=1000)]}\n",
    "\n",
    "    Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "    Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx,\n",
    "                                        scoring=scoring,n_jobs=10)\n",
    "    Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "    Stacking_grid_search.best_estimator_\n",
    "\n",
    "    train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "\n",
    "    test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "        \n",
    "    best_pca_train_scores.append(train_res1.loc[:,\"AUC\"])\n",
    "    best_pca_test_scores.append(test_res1.loc[:,\"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3f235ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79737676754328\n",
      "0    0.773595\n",
      "Name: AUC, dtype: float64\n",
      "n_components:\n",
      "80\n",
      "[0    0.732655\n",
      "Name: AUC, dtype: float64, 0    0.740188\n",
      "Name: AUC, dtype: float64, 0    0.744615\n",
      "Name: AUC, dtype: float64, 0    0.737082\n",
      "Name: AUC, dtype: float64, 0    0.777422\n",
      "Name: AUC, dtype: float64, 0    0.772103\n",
      "Name: AUC, dtype: float64, 0    0.78806\n",
      "Name: AUC, dtype: float64, 0    0.797377\n",
      "Name: AUC, dtype: float64, 0    0.780527\n",
      "Name: AUC, dtype: float64, 0    0.781419\n",
      "Name: AUC, dtype: float64, 0    0.783633\n",
      "Name: AUC, dtype: float64, 0    0.787631\n",
      "Name: AUC, dtype: float64, 0    0.775208\n",
      "Name: AUC, dtype: float64]\n",
      "[0    0.778544\n",
      "Name: AUC, dtype: float64, 0    0.797985\n",
      "Name: AUC, dtype: float64, 0    0.7614\n",
      "Name: AUC, dtype: float64, 0    0.729763\n",
      "Name: AUC, dtype: float64, 0    0.749205\n",
      "Name: AUC, dtype: float64, 0    0.7614\n",
      "Name: AUC, dtype: float64, 0    0.754153\n",
      "Name: AUC, dtype: float64, 0    0.773595\n",
      "Name: AUC, dtype: float64, 0    0.800283\n",
      "Name: AUC, dtype: float64, 0    0.754153\n",
      "Name: AUC, dtype: float64, 0    0.734712\n",
      "Name: AUC, dtype: float64, 0    0.805232\n",
      "Name: AUC, dtype: float64, 0    0.754153\n",
      "Name: AUC, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "print(np.max(best_pca_train_scores))\n",
    "print(best_pca_test_scores[np.argmax(best_pca_train_scores)])\n",
    "print(\"n_components:\")\n",
    "print(n_components[np.argmax(best_pca_train_scores)])\n",
    "\n",
    "print(best_pca_train_scores)\n",
    "print(best_pca_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d8158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
