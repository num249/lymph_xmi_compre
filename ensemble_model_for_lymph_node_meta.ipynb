{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbef4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, cross_val_predict\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn import svm  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "# cores = mp.cpu_count()\n",
    "# pool = mp.Pool(processes=20)\n",
    "\n",
    "# min1=min(list(X_standard.shape))\n",
    "# a1=list(range(10,min1,10))\n",
    "# a1[-1]=min1\n",
    "# pcc_top1=pool.map(find_best_pca_lr,a1)  ##（SVM，LR）\n",
    "# pool.terminate()\n",
    "\n",
    "\n",
    "# a1=pd.DataFrame()\n",
    "# for i1 in pcc_top1:\n",
    "#     a1=pd.concat([a1,i1], axis=0)\n",
    "# a1.columns=['tr_TP', 'tr_TN', 'tr_FP', 'tr_FN', 'tr_Sen', 'tr_Spe', 'tr_Acc', 'tr_PPV', 'tr_NPV', 'tr_MCC', 'tr_AUC','TP',\n",
    "#        'TN', 'FP', 'FN', 'Sen', 'Spe', 'Acc', 'PPV', 'NPV', 'MCC', 'AUC','PCA']   \n",
    "\n",
    "# a1=a1.sort_values(['Acc','tr_Acc','PCA'], ascending=[False,False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a00ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_csv(input_path,i):\n",
    "\n",
    "    df_chunk=pd.read_csv(input_path,\n",
    "                         chunksize=10000,\n",
    "#                          sep='\\t'\n",
    "                        sep=i\n",
    "                        )\n",
    "    res_chunk=[]\n",
    "    for chunk in df_chunk:\n",
    "        res_chunk.append(chunk)\n",
    "    res_df=pd.concat(res_chunk)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d3ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measures_gridloo(label, score):\n",
    "    label = np.array(label)\n",
    "    score = np.array(score)\n",
    "    \n",
    "    N  = len(label)\n",
    "    TP = sum((label == 1) & (score == 1))\n",
    "    TN = sum((label == 0) & (score == 0))\n",
    "    FP = sum((label == 0) & (score == 1))\n",
    "    FN = sum((label == 1) & (score == 0))\n",
    "\n",
    "    # init all measures to nan\n",
    "    measures = {measure: float(\"nan\") for measure in (\"Sen\", \"Spe\", \"Acc\", \"PPV\", \"NPV\", \"MCC\",\"AUC\")}\n",
    "    \n",
    "    measures[\"TP\"] = TP\n",
    "    measures[\"TN\"] = TN\n",
    "    measures[\"FP\"] = FP\n",
    "    measures[\"FN\"] = FN\n",
    "    \n",
    "    S = (TP + FN) / N\n",
    "    P = (TP + FP) / N\n",
    "\n",
    "    if (TP + FN) > 0:\n",
    "        measures[\"Sen\"] = round(TP/(TP+FN), 4)\n",
    "\n",
    "    if (TN + FP) > 0:\n",
    "        measures[\"Spe\"] = round(TN/(TN+FP), 4)\n",
    "\n",
    "    if (TP + FP + FN + TN) > 0:\n",
    "        measures[\"Acc\"] = round((TP+TN)/(TP+FP+FN+TN), 4)\n",
    "\n",
    "    if (TP + FP) > 0:\n",
    "        measures[\"PPV\"] = round(TP/(TP+FP), 4)\n",
    "\n",
    "    if (TN + FN) > 0:\n",
    "        measures[\"NPV\"] = round(TN/(TN+FN), 4)\n",
    "\n",
    "    if (S*P*(1-S)*(1-P)) > 0:\n",
    "        measures[\"MCC\"] = round((TP/N - S*P)/(math.sqrt(S*P*(1-S)*(1-P))), 4)\n",
    "    \n",
    "    \n",
    "    measures[\"AUC\"]= roc_auc_score(label, score)\n",
    "    return pd.DataFrame([measures],\n",
    "                        columns=[\"TP\", \"TN\", \"FP\",\n",
    "                                 \"FN\", \"Sen\", \"Spe\", \"Acc\", \"PPV\", \"NPV\", \"MCC\",\"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d53b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVM\n",
    "def find_best_pca(i):\n",
    "    n_components=i\n",
    "    estimator = PCA(n_components=n_components,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    \n",
    "    scoring = {'AUC': 'roc_auc'}\n",
    "    cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "    gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "    parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "    \n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "    grid_search=GridSearchCV(estimator=SVC(random_state=10),param_grid=parameters,cv=cvx,scoring='accuracy')\n",
    "    grid_search.fit(pca_X_train, train_y)\n",
    "    \n",
    "    train_pre_y = cross_val_predict(grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "    test_pre_y = grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "    test_res1['PCA']=n_components\n",
    "    \n",
    "    res=pd.concat([train_res1,test_res1], axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4e5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_pca_lr(i):\n",
    "    n_components=i\n",
    "    estimator = PCA(n_components=n_components,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    \n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "\n",
    "    param_grid = {'penalty':['l2'],\n",
    "              \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],  \n",
    "              \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\"],\n",
    "#             \"C\":list(np.arange(0,0.1,0.005)),   \n",
    "#               \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\"]\n",
    "            }\n",
    "    LR_grid = LogisticRegression()\n",
    "    grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=9)\n",
    "    grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "\n",
    "    train_pre_y = cross_val_predict(grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "   \n",
    "\n",
    "    test_pre_y = grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "    test_res1['PCA']=n_components\n",
    "    \n",
    "    res=pd.concat([train_res1,test_res1], axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e5f27eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer='BRCA'\n",
    "path='D:\\\\lymph_meta_xmiseq\\\\tcga_data\\\\'\n",
    "# e1=\"./\"+cancer+\"_delta_pcc_wilcox.csv\"\n",
    "# delta_pcc=read_single_csv(e1,',')\n",
    "# delta_pcc=delta_pcc.drop(['Unnamed: 0','pair'],axis=1)\n",
    "# delta_pcc=delta_pcc.dropna(axis=0,how='any')\n",
    "\n",
    "# result=delta_pcc.T\n",
    "# train=result.iloc[:,0:-1].values.astype('float')\n",
    "# target=result.iloc[:,-1].values.astype('float')\n",
    "\n",
    "train=pd.read_csv(path+cancer+\"\\\\admat_final.csv\").iloc[:,2:].T.values\n",
    "target=pd.read_csv(path+cancer+\"\\\\gctm_label.csv\",index_col=0).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "986f9b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00874834, -0.00736022, -0.01710605, ...,  0.0059139 ,\n",
       "         0.00585509,  0.01760065],\n",
       "       [-0.06756009, -0.03635654, -0.06104614, ...,  0.00184041,\n",
       "         0.01073223, -0.00660949],\n",
       "       [ 0.05017487, -0.03385318, -0.05728117, ..., -0.01067972,\n",
       "         0.01398897,  0.01295414],\n",
       "       ...,\n",
       "       [-0.00012984,  0.00158047,  0.00504004, ...,  0.00526114,\n",
       "        -0.00421565, -0.0168382 ],\n",
       "       [-0.0120549 ,  0.0223974 , -0.02588812, ..., -0.03524445,\n",
       "         0.00812885,  0.01039054],\n",
       "       [ 0.00757404,  0.00548185,  0.02304116, ...,  0.00104388,\n",
       "         0.00138618, -0.0349668 ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a0046d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4d47e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=10\n",
    "                                                   )\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(train_X)\n",
    "X_standard = standardScaler.transform(train_X)\n",
    "X_standard_test = standardScaler.transform(test_X)\n",
    "\n",
    "n_components=0.95\n",
    "estimator = PCA(n_components=n_components,random_state=10)\n",
    "pca_X_train = estimator.fit_transform(X_standard)\n",
    "pca_X_test = estimator.transform(X_standard_test)\n",
    "cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4d3eaf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 2281)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "385399ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.45230769        nan 0.52369231 0.54769231\n",
      " 0.54769231 0.72153846 0.76123077 0.74523077        nan        nan\n",
      " 0.45230769        nan 0.50030769 0.75292308 0.75292308 0.75292308\n",
      " 0.79230769 0.75292308        nan        nan 0.45230769        nan\n",
      " 0.52369231 0.848      0.848      0.82430769 0.864      0.832\n",
      "        nan        nan 0.68246154        nan 0.75292308 0.888\n",
      " 0.888      0.87230769 0.88       0.88              nan        nan\n",
      " 0.92              nan 0.92       0.88061538 0.88061538 0.85661538\n",
      " 0.86461538 0.86461538        nan        nan 0.944             nan\n",
      " 0.936      0.84061538 0.84061538 0.86461538 0.86461538 0.87261538\n",
      "        nan        nan 0.944             nan 0.87261538 0.84861538\n",
      " 0.84861538 0.86461538 0.86461538 0.87261538        nan        nan\n",
      " 0.90430769        nan 0.87261538 0.85661538 0.85661538 0.84861538\n",
      " 0.86461538 0.87261538        nan        nan 0.80892308        nan\n",
      " 0.87261538 0.84861538 0.84861538 0.84061538 0.86461538 0.87261538]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=10, shuffle=True),\n",
       "             estimator=LogisticRegression(max_iter=1000), n_jobs=10,\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                               1000],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm\n",
    "scoring = {'AUC': 'roc_auc'}\n",
    "cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "\n",
    "svc_grid_search=GridSearchCV(estimator=SVC(random_state=10),param_grid=parameters,cv=cvx,scoring='accuracy')\n",
    "svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "#LR\n",
    "param_grid = {'penalty':['l1', 'l2'],\n",
    "              \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "#               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "            }\n",
    "LR_grid = LogisticRegression(max_iter=1000)\n",
    "LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=10)\n",
    "LR_grid_search.fit(pca_X_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c0fc0d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                LogisticRegression(C=1, max_iter=1000,\n",
       "                                                   penalty='l1',\n",
       "                                                   solver='liblinear')),\n",
       "                               ('svc',\n",
       "                                SVC(C=32, gamma=3.0517578125e-05,\n",
       "                                    random_state=10))],\n",
       "                   final_estimator=LinearSVC(C=5), n_jobs=10)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('lr', LR_grid_search.best_estimator_),\n",
    "    ('svc', svc_grid_search.best_estimator_),\n",
    "]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LinearSVC(C=5),n_jobs=10)\n",
    "clf.fit(pca_X_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "aa318404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                LogisticRegression(C=1, max_iter=1000,\n",
       "                                                   penalty='l1',\n",
       "                                                   solver='liblinear')),\n",
       "                               ('svc',\n",
       "                                SVC(C=32, gamma=3.0517578125e-05,\n",
       "                                    random_state=10))],\n",
       "                   final_estimator=LogisticRegression(C=100))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('lr', LR_grid_search.best_estimator_),\n",
    "    ('svc', svc_grid_search.best_estimator_),\n",
    "]\n",
    "\n",
    "param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                 LogisticRegression(C=0.1),LogisticRegression(C=1),LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                 LogisticRegression(C=1000)]}\n",
    "\n",
    "Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=10)\n",
    "Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "Stacking_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a1961530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "\n",
    "test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "test_res1=get_measures_gridloo(test_y,test_pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dfa32e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TP  TN  FP  FN     Sen     Spe     Acc     PPV     NPV     MCC       AUC\n",
      "0  64  50   7   5  0.9275  0.8772  0.9048  0.9014  0.9091  0.8076  0.902365\n",
      "   TP  TN  FP  FN  Sen  Spe  Acc  PPV  NPV  MCC  AUC\n",
      "0  30  24   0   0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_res1)\n",
    "print(test_res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5ac3da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shpae:\n",
      "(233, 3992)\n",
      "range(10, 208, 10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################random seed loop#################\n",
    "train_scores=[]\n",
    "test_scores=[]\n",
    "loopn=20\n",
    "scoring='roc_auc'\n",
    "np.random.seed(42)\n",
    "random_states=np.random.choice(range(101), loopn, replace=False)\n",
    "\n",
    "tmp_train=[]\n",
    "tmp_test=[]\n",
    "#print(random_states)\n",
    "for i in range(loopn):\n",
    "    train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=random_states[i]\n",
    "                                                   )\n",
    "    print(\"train_x.shpae:\")\n",
    "    print(train_X.shape)\n",
    "\n",
    "    standardScaler = StandardScaler()\n",
    "    standardScaler.fit(train_X)\n",
    "    X_standard = standardScaler.transform(train_X)\n",
    "    X_standard_test = standardScaler.transform(test_X)\n",
    "    #calculate max n_components\n",
    "    estimator = PCA(n_components=0.99,random_state=random_states[i])\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "\n",
    "    n_components=range(10,min(pca_X_train.shape),10)\n",
    "    print(n_components)\n",
    "    #n_components=[0.99,0.95,0.90,0.85]\n",
    "    best_pca_train_scores=[]\n",
    "    best_pca_test_scores=[]\n",
    "    for j in n_components:\n",
    "        estimator = PCA(n_components=j,random_state=random_states[i])\n",
    "        pca_X_train = estimator.fit_transform(X_standard)\n",
    "        pca_X_test = estimator.transform(X_standard_test)\n",
    "        cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_states[i]) \n",
    "    \n",
    "        #scoring = {'AUC': 'roc_auc'}\n",
    "        cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "        gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "        parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "\n",
    "        svc_grid_search=GridSearchCV(estimator=SVC(random_state=random_states[i]),\n",
    "                                     param_grid=parameters,cv=cvx,scoring=scoring)\n",
    "        svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "        param_grid = {'penalty':['l1', 'l2'],\n",
    "                      \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                      \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "    #               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                    }\n",
    "        LR_grid = LogisticRegression(max_iter=1000, random_state=random_states[i])\n",
    "        LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring=scoring,n_jobs=10)\n",
    "        LR_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "        estimators = [\n",
    "            ('lr', LR_grid_search.best_estimator_),\n",
    "            ('svc', svc_grid_search.best_estimator_),\n",
    "        ]\n",
    "        clf = StackingClassifier(estimators=estimators, \n",
    "                                 final_estimator=LinearSVC(C=5, random_state=random_states[i]),n_jobs=10)\n",
    "        clf.fit(pca_X_train, train_y)\n",
    "\n",
    "        estimators = [\n",
    "            ('lr', LR_grid_search.best_estimator_),\n",
    "            ('svc', svc_grid_search.best_estimator_),\n",
    "        ]\n",
    "\n",
    "        param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),\n",
    "                                         LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                         LogisticRegression(C=0.1),LogisticRegression(C=1),\n",
    "                                         LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                         LogisticRegression(C=1000)]}\n",
    "\n",
    "        Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "        Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx,\n",
    "                                            scoring=scoring,n_jobs=10)\n",
    "        Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "        Stacking_grid_search.best_estimator_\n",
    "\n",
    "        train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "        train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "\n",
    "        test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "        test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "        \n",
    "        best_pca_train_scores.append(train_res1.loc[:,\"AUC\"])\n",
    "        best_pca_test_scores.append(test_res1.loc[:,\"AUC\"])\n",
    "    \n",
    "    train_scores.append(np.max(best_pca_train_scores))\n",
    "    test_scores.append(best_pca_test_scores[np.argmax(best_pca_train_scores)])\n",
    "    print(\"n_components:\")\n",
    "    print(n_components[np.argmax(best_pca_train_scores)])\n",
    "    \n",
    "    tmp_train.append(best_pca_train_scores)\n",
    "    tmp_test.append(best_pca_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "89e38686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "0.7493835404327798\n",
      "0.7397321428571428\n",
      "std\n",
      "0.012532381791542108\n",
      "0.022023953907401497\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0    0.777194\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.76217\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.770453\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.774934\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.767129\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.75584\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.737066\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.752729\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.75136\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.724993\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.712495\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.726096\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.709064\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.730737\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.727732\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.737013\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.733848\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0    0.743342\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.748142\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.738808\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.737226\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.73543\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.743289\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.758899\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.719501\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.719767\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.716762\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.703785\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.707003\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.705367\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.713066\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.703838\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.702203\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0    0.732585\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.746826\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.72615\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.749777\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.743395\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.758952\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.737385\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.730843\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.738755\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.715233\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.733795\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.727679\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.730737\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0    0.724621\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.699517\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.707375\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.738701\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.729261\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.721403\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.725937\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.722879\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.705474\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.70542\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.692656\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.689651\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.67573\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0    0.743182\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.741493\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.5\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.759005\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.743022\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.7464\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.744818\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.746294\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.729155\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.735643\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.712746\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.708851\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.707216\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.699198\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.711962\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.705474\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0    0.57817\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.568251\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.747823\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.727306\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.724301\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.731893\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.716337\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.732159\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.711856\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.728835\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.740177\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.721296\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.730684\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.73696\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.73063\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.739964\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0    0.739964\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.5\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.708638\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.71054\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.727626\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.723145\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.710593\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.722825\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.701046\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.713651\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.722613\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.711696\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.707322\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.722825\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.715021\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.713332\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.724408\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.707269\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0    0.737013\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.738648\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.741547\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.729101\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.74265\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.737172\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.729155\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.716762\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.710487\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.718398\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.715127\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.705953\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.702735\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.716762\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0    0.735377\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.718025\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.745921\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.750508\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.747663\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.761797\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.750668\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.763326\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.756944\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.746134\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.733848\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.722932\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.721243\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.724461\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.722879\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0    0.74039\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.729101\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.733795\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.749405\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.736853\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.728782\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.745031\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.745761\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.738116\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.711803\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.710646\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.702788\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.704583\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0    0.737226\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.747769\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.758473\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.75241\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.747876\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.732319\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.744818\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.754045\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.746187\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.721563\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.722719\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.717866\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.716496\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.715021\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.721137\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.721296\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.71655\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0    0.729048\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.727466\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.724727\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.740961\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.738169\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.738595\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.730737\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.729208\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.722506\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.719661\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.733476\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.728888\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.730417\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.72599\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0    0.724514\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.719821\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.729155\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.732106\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.736587\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.724088\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.725564\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.700833\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.696193\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.708585\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.69118\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.686486\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.69118\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.684957\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.697403\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.697615\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0    0.732798\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.727892\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.554383\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.735377\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.733955\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.713598\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.724301\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.727519\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.708478\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.712069\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.718238\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.730577\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.731893\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.714967\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.729101\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0    0.699943\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.710114\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.688175\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.69614\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.725884\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.728942\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.727519\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.702841\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.719714\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.702309\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.703678\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.700567\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.695767\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0    0.738648\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.5\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.685277\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.699517\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.724674\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.710753\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.707216\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.729155\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.712122\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.726416\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.722985\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.716709\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.718185\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.713438\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0    0.734327\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.734008\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.730843\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.710699\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.729261\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.719874\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.721509\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.752623\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.736853\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.719874\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.715074\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.5\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.713545\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.715127\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.723038\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.727838\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.726043\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.733742\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.727572\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.730577\n",
       "Name: AUC, dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0    0.758899\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.746134\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.758845\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.76217\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.760428\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.757316\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.750881\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.757263\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.71655\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.728729\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.703998\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.702522\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.705367\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0    0.745031\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.746187\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.743129\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.501582\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.741919\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.748195\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.740443\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.748035\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.726309\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.746347\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.694717\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.704211\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.694717\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.703998\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.693294\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.696193\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.702575\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.701099\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0    0.732692\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.732479\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.727838\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.716816\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.73095\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.726256\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.717082\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.72014\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.723251\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.716922\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>...</td>\n",
       "      <td>0    0.722825\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.713491\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.728835\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.722772\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.730471\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0   \\\n",
       "0   0    0.777194\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.743342\n",
       "Name: AUC, dtype: float64   \n",
       "2   0    0.732585\n",
       "Name: AUC, dtype: float64   \n",
       "3   0    0.724621\n",
       "Name: AUC, dtype: float64   \n",
       "4   0    0.743182\n",
       "Name: AUC, dtype: float64   \n",
       "5    0    0.57817\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.739964\n",
       "Name: AUC, dtype: float64   \n",
       "7   0    0.737013\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.735377\n",
       "Name: AUC, dtype: float64   \n",
       "9    0    0.74039\n",
       "Name: AUC, dtype: float64   \n",
       "10  0    0.737226\n",
       "Name: AUC, dtype: float64   \n",
       "11  0    0.729048\n",
       "Name: AUC, dtype: float64   \n",
       "12  0    0.724514\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.732798\n",
       "Name: AUC, dtype: float64   \n",
       "14  0    0.699943\n",
       "Name: AUC, dtype: float64   \n",
       "15  0    0.738648\n",
       "Name: AUC, dtype: float64   \n",
       "16  0    0.734327\n",
       "Name: AUC, dtype: float64   \n",
       "17  0    0.758899\n",
       "Name: AUC, dtype: float64   \n",
       "18  0    0.745031\n",
       "Name: AUC, dtype: float64   \n",
       "19  0    0.732692\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         1   \\\n",
       "0    0    0.76217\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.748142\n",
       "Name: AUC, dtype: float64   \n",
       "2   0    0.746826\n",
       "Name: AUC, dtype: float64   \n",
       "3   0    0.699517\n",
       "Name: AUC, dtype: float64   \n",
       "4   0    0.741493\n",
       "Name: AUC, dtype: float64   \n",
       "5   0    0.568251\n",
       "Name: AUC, dtype: float64   \n",
       "6        0    0.5\n",
       "Name: AUC, dtype: float64   \n",
       "7   0    0.738648\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.718025\n",
       "Name: AUC, dtype: float64   \n",
       "9   0    0.729101\n",
       "Name: AUC, dtype: float64   \n",
       "10  0    0.747769\n",
       "Name: AUC, dtype: float64   \n",
       "11  0    0.727466\n",
       "Name: AUC, dtype: float64   \n",
       "12  0    0.719821\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.727892\n",
       "Name: AUC, dtype: float64   \n",
       "14  0    0.710114\n",
       "Name: AUC, dtype: float64   \n",
       "15       0    0.5\n",
       "Name: AUC, dtype: float64   \n",
       "16  0    0.734008\n",
       "Name: AUC, dtype: float64   \n",
       "17  0    0.746134\n",
       "Name: AUC, dtype: float64   \n",
       "18  0    0.746187\n",
       "Name: AUC, dtype: float64   \n",
       "19  0    0.732479\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         2   \\\n",
       "0   0    0.770453\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.738808\n",
       "Name: AUC, dtype: float64   \n",
       "2    0    0.72615\n",
       "Name: AUC, dtype: float64   \n",
       "3   0    0.707375\n",
       "Name: AUC, dtype: float64   \n",
       "4        0    0.5\n",
       "Name: AUC, dtype: float64   \n",
       "5   0    0.747823\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.708638\n",
       "Name: AUC, dtype: float64   \n",
       "7   0    0.741547\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.745921\n",
       "Name: AUC, dtype: float64   \n",
       "9   0    0.733795\n",
       "Name: AUC, dtype: float64   \n",
       "10  0    0.758473\n",
       "Name: AUC, dtype: float64   \n",
       "11  0    0.724727\n",
       "Name: AUC, dtype: float64   \n",
       "12  0    0.729155\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.554383\n",
       "Name: AUC, dtype: float64   \n",
       "14  0    0.688175\n",
       "Name: AUC, dtype: float64   \n",
       "15  0    0.685277\n",
       "Name: AUC, dtype: float64   \n",
       "16  0    0.730843\n",
       "Name: AUC, dtype: float64   \n",
       "17  0    0.758845\n",
       "Name: AUC, dtype: float64   \n",
       "18  0    0.743129\n",
       "Name: AUC, dtype: float64   \n",
       "19  0    0.727838\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         3   \\\n",
       "0   0    0.774934\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.737226\n",
       "Name: AUC, dtype: float64   \n",
       "2   0    0.749777\n",
       "Name: AUC, dtype: float64   \n",
       "3   0    0.738701\n",
       "Name: AUC, dtype: float64   \n",
       "4   0    0.759005\n",
       "Name: AUC, dtype: float64   \n",
       "5   0    0.727306\n",
       "Name: AUC, dtype: float64   \n",
       "6    0    0.71054\n",
       "Name: AUC, dtype: float64   \n",
       "7   0    0.729101\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.750508\n",
       "Name: AUC, dtype: float64   \n",
       "9   0    0.749405\n",
       "Name: AUC, dtype: float64   \n",
       "10   0    0.75241\n",
       "Name: AUC, dtype: float64   \n",
       "11  0    0.740961\n",
       "Name: AUC, dtype: float64   \n",
       "12  0    0.732106\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.735377\n",
       "Name: AUC, dtype: float64   \n",
       "14   0    0.69614\n",
       "Name: AUC, dtype: float64   \n",
       "15  0    0.699517\n",
       "Name: AUC, dtype: float64   \n",
       "16  0    0.710699\n",
       "Name: AUC, dtype: float64   \n",
       "17   0    0.76217\n",
       "Name: AUC, dtype: float64   \n",
       "18  0    0.501582\n",
       "Name: AUC, dtype: float64   \n",
       "19  0    0.716816\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         4   \\\n",
       "0   0    0.767129\n",
       "Name: AUC, dtype: float64   \n",
       "1    0    0.73543\n",
       "Name: AUC, dtype: float64   \n",
       "2   0    0.743395\n",
       "Name: AUC, dtype: float64   \n",
       "3   0    0.729261\n",
       "Name: AUC, dtype: float64   \n",
       "4   0    0.743022\n",
       "Name: AUC, dtype: float64   \n",
       "5   0    0.724301\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.727626\n",
       "Name: AUC, dtype: float64   \n",
       "7    0    0.74265\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.747663\n",
       "Name: AUC, dtype: float64   \n",
       "9   0    0.736853\n",
       "Name: AUC, dtype: float64   \n",
       "10  0    0.747876\n",
       "Name: AUC, dtype: float64   \n",
       "11  0    0.738169\n",
       "Name: AUC, dtype: float64   \n",
       "12  0    0.736587\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.733955\n",
       "Name: AUC, dtype: float64   \n",
       "14  0    0.725884\n",
       "Name: AUC, dtype: float64   \n",
       "15  0    0.724674\n",
       "Name: AUC, dtype: float64   \n",
       "16  0    0.729261\n",
       "Name: AUC, dtype: float64   \n",
       "17  0    0.760428\n",
       "Name: AUC, dtype: float64   \n",
       "18  0    0.741919\n",
       "Name: AUC, dtype: float64   \n",
       "19   0    0.73095\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         5   \\\n",
       "0    0    0.75584\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.743289\n",
       "Name: AUC, dtype: float64   \n",
       "2   0    0.758952\n",
       "Name: AUC, dtype: float64   \n",
       "3   0    0.721403\n",
       "Name: AUC, dtype: float64   \n",
       "4     0    0.7464\n",
       "Name: AUC, dtype: float64   \n",
       "5   0    0.731893\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.723145\n",
       "Name: AUC, dtype: float64   \n",
       "7   0    0.737172\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.761797\n",
       "Name: AUC, dtype: float64   \n",
       "9   0    0.728782\n",
       "Name: AUC, dtype: float64   \n",
       "10  0    0.732319\n",
       "Name: AUC, dtype: float64   \n",
       "11  0    0.738595\n",
       "Name: AUC, dtype: float64   \n",
       "12  0    0.724088\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.713598\n",
       "Name: AUC, dtype: float64   \n",
       "14  0    0.728942\n",
       "Name: AUC, dtype: float64   \n",
       "15  0    0.710753\n",
       "Name: AUC, dtype: float64   \n",
       "16  0    0.719874\n",
       "Name: AUC, dtype: float64   \n",
       "17  0    0.757316\n",
       "Name: AUC, dtype: float64   \n",
       "18  0    0.748195\n",
       "Name: AUC, dtype: float64   \n",
       "19  0    0.726256\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         6   \\\n",
       "0   0    0.737066\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.758899\n",
       "Name: AUC, dtype: float64   \n",
       "2   0    0.737385\n",
       "Name: AUC, dtype: float64   \n",
       "3   0    0.725937\n",
       "Name: AUC, dtype: float64   \n",
       "4   0    0.744818\n",
       "Name: AUC, dtype: float64   \n",
       "5   0    0.716337\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.710593\n",
       "Name: AUC, dtype: float64   \n",
       "7   0    0.729155\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.750668\n",
       "Name: AUC, dtype: float64   \n",
       "9   0    0.745031\n",
       "Name: AUC, dtype: float64   \n",
       "10  0    0.744818\n",
       "Name: AUC, dtype: float64   \n",
       "11  0    0.730737\n",
       "Name: AUC, dtype: float64   \n",
       "12  0    0.725564\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.724301\n",
       "Name: AUC, dtype: float64   \n",
       "14  0    0.727519\n",
       "Name: AUC, dtype: float64   \n",
       "15  0    0.707216\n",
       "Name: AUC, dtype: float64   \n",
       "16  0    0.721509\n",
       "Name: AUC, dtype: float64   \n",
       "17  0    0.750881\n",
       "Name: AUC, dtype: float64   \n",
       "18  0    0.740443\n",
       "Name: AUC, dtype: float64   \n",
       "19  0    0.717082\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         7   \\\n",
       "0   0    0.752729\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.719501\n",
       "Name: AUC, dtype: float64   \n",
       "2   0    0.730843\n",
       "Name: AUC, dtype: float64   \n",
       "3   0    0.722879\n",
       "Name: AUC, dtype: float64   \n",
       "4   0    0.746294\n",
       "Name: AUC, dtype: float64   \n",
       "5   0    0.732159\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.722825\n",
       "Name: AUC, dtype: float64   \n",
       "7   0    0.716762\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.763326\n",
       "Name: AUC, dtype: float64   \n",
       "9   0    0.745761\n",
       "Name: AUC, dtype: float64   \n",
       "10  0    0.754045\n",
       "Name: AUC, dtype: float64   \n",
       "11  0    0.729208\n",
       "Name: AUC, dtype: float64   \n",
       "12  0    0.700833\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.727519\n",
       "Name: AUC, dtype: float64   \n",
       "14  0    0.702841\n",
       "Name: AUC, dtype: float64   \n",
       "15  0    0.729155\n",
       "Name: AUC, dtype: float64   \n",
       "16  0    0.752623\n",
       "Name: AUC, dtype: float64   \n",
       "17  0    0.757263\n",
       "Name: AUC, dtype: float64   \n",
       "18  0    0.748035\n",
       "Name: AUC, dtype: float64   \n",
       "19   0    0.72014\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         8   \\\n",
       "0    0    0.75136\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.719767\n",
       "Name: AUC, dtype: float64   \n",
       "2   0    0.738755\n",
       "Name: AUC, dtype: float64   \n",
       "3   0    0.705474\n",
       "Name: AUC, dtype: float64   \n",
       "4   0    0.729155\n",
       "Name: AUC, dtype: float64   \n",
       "5   0    0.711856\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.701046\n",
       "Name: AUC, dtype: float64   \n",
       "7   0    0.710487\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.756944\n",
       "Name: AUC, dtype: float64   \n",
       "9   0    0.738116\n",
       "Name: AUC, dtype: float64   \n",
       "10  0    0.746187\n",
       "Name: AUC, dtype: float64   \n",
       "11  0    0.722506\n",
       "Name: AUC, dtype: float64   \n",
       "12  0    0.696193\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.708478\n",
       "Name: AUC, dtype: float64   \n",
       "14  0    0.719714\n",
       "Name: AUC, dtype: float64   \n",
       "15  0    0.712122\n",
       "Name: AUC, dtype: float64   \n",
       "16  0    0.736853\n",
       "Name: AUC, dtype: float64   \n",
       "17   0    0.71655\n",
       "Name: AUC, dtype: float64   \n",
       "18  0    0.726309\n",
       "Name: AUC, dtype: float64   \n",
       "19  0    0.723251\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         9   ...  \\\n",
       "0   0    0.724993\n",
       "Name: AUC, dtype: float64  ...   \n",
       "1   0    0.716762\n",
       "Name: AUC, dtype: float64  ...   \n",
       "2   0    0.715233\n",
       "Name: AUC, dtype: float64  ...   \n",
       "3    0    0.70542\n",
       "Name: AUC, dtype: float64  ...   \n",
       "4   0    0.735643\n",
       "Name: AUC, dtype: float64  ...   \n",
       "5   0    0.728835\n",
       "Name: AUC, dtype: float64  ...   \n",
       "6   0    0.713651\n",
       "Name: AUC, dtype: float64  ...   \n",
       "7   0    0.718398\n",
       "Name: AUC, dtype: float64  ...   \n",
       "8   0    0.746134\n",
       "Name: AUC, dtype: float64  ...   \n",
       "9   0    0.711803\n",
       "Name: AUC, dtype: float64  ...   \n",
       "10  0    0.721563\n",
       "Name: AUC, dtype: float64  ...   \n",
       "11  0    0.719661\n",
       "Name: AUC, dtype: float64  ...   \n",
       "12  0    0.708585\n",
       "Name: AUC, dtype: float64  ...   \n",
       "13  0    0.712069\n",
       "Name: AUC, dtype: float64  ...   \n",
       "14  0    0.702309\n",
       "Name: AUC, dtype: float64  ...   \n",
       "15  0    0.726416\n",
       "Name: AUC, dtype: float64  ...   \n",
       "16  0    0.719874\n",
       "Name: AUC, dtype: float64  ...   \n",
       "17  0    0.728729\n",
       "Name: AUC, dtype: float64  ...   \n",
       "18  0    0.746347\n",
       "Name: AUC, dtype: float64  ...   \n",
       "19  0    0.716922\n",
       "Name: AUC, dtype: float64  ...   \n",
       "\n",
       "                                         41  \\\n",
       "0   0    0.712495\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.703785\n",
       "Name: AUC, dtype: float64   \n",
       "2   0    0.733795\n",
       "Name: AUC, dtype: float64   \n",
       "3   0    0.692656\n",
       "Name: AUC, dtype: float64   \n",
       "4   0    0.712746\n",
       "Name: AUC, dtype: float64   \n",
       "5   0    0.740177\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.722613\n",
       "Name: AUC, dtype: float64   \n",
       "7   0    0.715127\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.733848\n",
       "Name: AUC, dtype: float64   \n",
       "9   0    0.710646\n",
       "Name: AUC, dtype: float64   \n",
       "10  0    0.722719\n",
       "Name: AUC, dtype: float64   \n",
       "11  0    0.733476\n",
       "Name: AUC, dtype: float64   \n",
       "12   0    0.69118\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.718238\n",
       "Name: AUC, dtype: float64   \n",
       "14  0    0.703678\n",
       "Name: AUC, dtype: float64   \n",
       "15  0    0.722985\n",
       "Name: AUC, dtype: float64   \n",
       "16  0    0.715074\n",
       "Name: AUC, dtype: float64   \n",
       "17  0    0.703998\n",
       "Name: AUC, dtype: float64   \n",
       "18  0    0.694717\n",
       "Name: AUC, dtype: float64   \n",
       "19  0    0.722825\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         42  \\\n",
       "0   0    0.726096\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.707003\n",
       "Name: AUC, dtype: float64   \n",
       "2   0    0.727679\n",
       "Name: AUC, dtype: float64   \n",
       "3   0    0.689651\n",
       "Name: AUC, dtype: float64   \n",
       "4   0    0.708851\n",
       "Name: AUC, dtype: float64   \n",
       "5   0    0.721296\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.711696\n",
       "Name: AUC, dtype: float64   \n",
       "7   0    0.705953\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.722932\n",
       "Name: AUC, dtype: float64   \n",
       "9   0    0.702788\n",
       "Name: AUC, dtype: float64   \n",
       "10  0    0.717866\n",
       "Name: AUC, dtype: float64   \n",
       "11  0    0.728888\n",
       "Name: AUC, dtype: float64   \n",
       "12  0    0.686486\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.730577\n",
       "Name: AUC, dtype: float64   \n",
       "14  0    0.700567\n",
       "Name: AUC, dtype: float64   \n",
       "15  0    0.716709\n",
       "Name: AUC, dtype: float64   \n",
       "16       0    0.5\n",
       "Name: AUC, dtype: float64   \n",
       "17  0    0.702522\n",
       "Name: AUC, dtype: float64   \n",
       "18  0    0.704211\n",
       "Name: AUC, dtype: float64   \n",
       "19  0    0.713491\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         43  \\\n",
       "0   0    0.709064\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.705367\n",
       "Name: AUC, dtype: float64   \n",
       "2   0    0.730737\n",
       "Name: AUC, dtype: float64   \n",
       "3    0    0.67573\n",
       "Name: AUC, dtype: float64   \n",
       "4   0    0.707216\n",
       "Name: AUC, dtype: float64   \n",
       "5   0    0.730684\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.707322\n",
       "Name: AUC, dtype: float64   \n",
       "7   0    0.702735\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.721243\n",
       "Name: AUC, dtype: float64   \n",
       "9   0    0.704583\n",
       "Name: AUC, dtype: float64   \n",
       "10  0    0.716496\n",
       "Name: AUC, dtype: float64   \n",
       "11  0    0.730417\n",
       "Name: AUC, dtype: float64   \n",
       "12   0    0.69118\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.731893\n",
       "Name: AUC, dtype: float64   \n",
       "14  0    0.695767\n",
       "Name: AUC, dtype: float64   \n",
       "15  0    0.718185\n",
       "Name: AUC, dtype: float64   \n",
       "16  0    0.713545\n",
       "Name: AUC, dtype: float64   \n",
       "17  0    0.705367\n",
       "Name: AUC, dtype: float64   \n",
       "18  0    0.694717\n",
       "Name: AUC, dtype: float64   \n",
       "19  0    0.728835\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         44  \\\n",
       "0   0    0.730737\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.713066\n",
       "Name: AUC, dtype: float64   \n",
       "2                                      None   \n",
       "3                                      None   \n",
       "4   0    0.699198\n",
       "Name: AUC, dtype: float64   \n",
       "5    0    0.73696\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.722825\n",
       "Name: AUC, dtype: float64   \n",
       "7   0    0.716762\n",
       "Name: AUC, dtype: float64   \n",
       "8   0    0.724461\n",
       "Name: AUC, dtype: float64   \n",
       "9                                      None   \n",
       "10  0    0.715021\n",
       "Name: AUC, dtype: float64   \n",
       "11   0    0.72599\n",
       "Name: AUC, dtype: float64   \n",
       "12  0    0.684957\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.714967\n",
       "Name: AUC, dtype: float64   \n",
       "14                                     None   \n",
       "15  0    0.713438\n",
       "Name: AUC, dtype: float64   \n",
       "16  0    0.715127\n",
       "Name: AUC, dtype: float64   \n",
       "17                                     None   \n",
       "18  0    0.703998\n",
       "Name: AUC, dtype: float64   \n",
       "19  0    0.722772\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         45  \\\n",
       "0   0    0.727732\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.703838\n",
       "Name: AUC, dtype: float64   \n",
       "2                                      None   \n",
       "3                                      None   \n",
       "4   0    0.711962\n",
       "Name: AUC, dtype: float64   \n",
       "5    0    0.73063\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.715021\n",
       "Name: AUC, dtype: float64   \n",
       "7                                      None   \n",
       "8   0    0.722879\n",
       "Name: AUC, dtype: float64   \n",
       "9                                      None   \n",
       "10  0    0.721137\n",
       "Name: AUC, dtype: float64   \n",
       "11                                     None   \n",
       "12  0    0.697403\n",
       "Name: AUC, dtype: float64   \n",
       "13  0    0.729101\n",
       "Name: AUC, dtype: float64   \n",
       "14                                     None   \n",
       "15                                     None   \n",
       "16  0    0.723038\n",
       "Name: AUC, dtype: float64   \n",
       "17                                     None   \n",
       "18  0    0.693294\n",
       "Name: AUC, dtype: float64   \n",
       "19  0    0.730471\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                         46  \\\n",
       "0   0    0.737013\n",
       "Name: AUC, dtype: float64   \n",
       "1   0    0.702203\n",
       "Name: AUC, dtype: float64   \n",
       "2                                      None   \n",
       "3                                      None   \n",
       "4   0    0.705474\n",
       "Name: AUC, dtype: float64   \n",
       "5   0    0.739964\n",
       "Name: AUC, dtype: float64   \n",
       "6   0    0.713332\n",
       "Name: AUC, dtype: float64   \n",
       "7                                      None   \n",
       "8                                      None   \n",
       "9                                      None   \n",
       "10  0    0.721296\n",
       "Name: AUC, dtype: float64   \n",
       "11                                     None   \n",
       "12  0    0.697615\n",
       "Name: AUC, dtype: float64   \n",
       "13                                     None   \n",
       "14                                     None   \n",
       "15                                     None   \n",
       "16  0    0.727838\n",
       "Name: AUC, dtype: float64   \n",
       "17                                     None   \n",
       "18  0    0.696193\n",
       "Name: AUC, dtype: float64   \n",
       "19                                     None   \n",
       "\n",
       "                                         47  \\\n",
       "0   0    0.733848\n",
       "Name: AUC, dtype: float64   \n",
       "1                                      None   \n",
       "2                                      None   \n",
       "3                                      None   \n",
       "4                                      None   \n",
       "5                                      None   \n",
       "6   0    0.724408\n",
       "Name: AUC, dtype: float64   \n",
       "7                                      None   \n",
       "8                                      None   \n",
       "9                                      None   \n",
       "10   0    0.71655\n",
       "Name: AUC, dtype: float64   \n",
       "11                                     None   \n",
       "12                                     None   \n",
       "13                                     None   \n",
       "14                                     None   \n",
       "15                                     None   \n",
       "16  0    0.726043\n",
       "Name: AUC, dtype: float64   \n",
       "17                                     None   \n",
       "18  0    0.702575\n",
       "Name: AUC, dtype: float64   \n",
       "19                                     None   \n",
       "\n",
       "                                         48  \\\n",
       "0                                      None   \n",
       "1                                      None   \n",
       "2                                      None   \n",
       "3                                      None   \n",
       "4                                      None   \n",
       "5                                      None   \n",
       "6   0    0.707269\n",
       "Name: AUC, dtype: float64   \n",
       "7                                      None   \n",
       "8                                      None   \n",
       "9                                      None   \n",
       "10                                     None   \n",
       "11                                     None   \n",
       "12                                     None   \n",
       "13                                     None   \n",
       "14                                     None   \n",
       "15                                     None   \n",
       "16  0    0.733742\n",
       "Name: AUC, dtype: float64   \n",
       "17                                     None   \n",
       "18  0    0.701099\n",
       "Name: AUC, dtype: float64   \n",
       "19                                     None   \n",
       "\n",
       "                                         49  \\\n",
       "0                                      None   \n",
       "1                                      None   \n",
       "2                                      None   \n",
       "3                                      None   \n",
       "4                                      None   \n",
       "5                                      None   \n",
       "6                                      None   \n",
       "7                                      None   \n",
       "8                                      None   \n",
       "9                                      None   \n",
       "10                                     None   \n",
       "11                                     None   \n",
       "12                                     None   \n",
       "13                                     None   \n",
       "14                                     None   \n",
       "15                                     None   \n",
       "16  0    0.727572\n",
       "Name: AUC, dtype: float64   \n",
       "17                                     None   \n",
       "18                                     None   \n",
       "19                                     None   \n",
       "\n",
       "                                         50  \n",
       "0                                      None  \n",
       "1                                      None  \n",
       "2                                      None  \n",
       "3                                      None  \n",
       "4                                      None  \n",
       "5                                      None  \n",
       "6                                      None  \n",
       "7                                      None  \n",
       "8                                      None  \n",
       "9                                      None  \n",
       "10                                     None  \n",
       "11                                     None  \n",
       "12                                     None  \n",
       "13                                     None  \n",
       "14                                     None  \n",
       "15                                     None  \n",
       "16  0    0.730577\n",
       "Name: AUC, dtype: float64  \n",
       "17                                     None  \n",
       "18                                     None  \n",
       "19                                     None  \n",
       "\n",
       "[20 rows x 51 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('mean')\n",
    "print(np.mean(train_scores))\n",
    "print(np.mean(test_scores))\n",
    "print(\"std\")\n",
    "print(np.std(train_scores))\n",
    "print(np.std(test_scores))\n",
    "pd.DataFrame(tmp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "03767256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9295183982683983]\n",
      "[0    0.940972\n",
      "Name: AUC, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "print(train_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360d174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2e2d299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shpae:\n",
      "(630, 4958)\n",
      "range(10, 459, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72752591\n",
      " 0.72752591 0.72722357 0.72722357 0.72727396        nan        nan\n",
      " 0.5               nan 0.5        0.7279292  0.7279292  0.72183167\n",
      " 0.72208364 0.72203325        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.76784054 0.76784054 0.7294922  0.73946975 0.73427939\n",
      "        nan        nan 0.72651724        nan 0.73221161 0.80780132\n",
      " 0.80780132 0.75398314 0.74395514 0.73674903        nan        nan\n",
      " 0.79611033        nan 0.73684961 0.81747656 0.81747656 0.79812631\n",
      " 0.74435829 0.73695063        nan        nan 0.81656957        nan\n",
      " 0.73659787 0.8178797  0.8178797  0.81475547 0.74425751 0.73715221\n",
      "        nan        nan 0.81803089        nan 0.73710182 0.81808128\n",
      " 0.81808128 0.81787972 0.7443079  0.73715221        nan        nan\n",
      " 0.81813167        nan 0.73715221 0.81818208 0.81818208 0.81823246\n",
      " 0.7443079  0.73715221        nan        nan 0.81808128        nan\n",
      " 0.73715221 0.81818208 0.81818208 0.81818208 0.7443079  0.73715221]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.75287267\n",
      " 0.75287267 0.75287268 0.75287268 0.75287268        nan        nan\n",
      " 0.5               nan 0.5        0.7573074  0.7573074  0.75413265\n",
      " 0.75418304 0.75423343        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.78406659 0.78406659 0.76098637 0.76481624 0.76174222\n",
      "        nan        nan 0.73498306        nan 0.73961922 0.80467756\n",
      " 0.80467756 0.7627508  0.7578628  0.7580643         nan        nan\n",
      " 0.79480072        nan 0.75660268 0.81319377 0.81319377 0.79495173\n",
      " 0.75544392 0.75619974        nan        nan 0.81263942        nan\n",
      " 0.75574617 0.81384886 0.81384886 0.81188364 0.75504081 0.75614933\n",
      "        nan        nan 0.81379846        nan 0.75604855 0.81394964\n",
      " 0.81394964 0.81369768 0.7549904  0.75609894        nan        nan\n",
      " 0.81400003        nan 0.75609894 0.81400005 0.81400005 0.81405042\n",
      " 0.7549904  0.75609894        nan        nan 0.81405042        nan\n",
      " 0.75604855 0.81400005 0.81400005 0.81405045 0.7549904  0.75604855]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.75640007\n",
      " 0.75640007 0.75665203 0.75665203 0.75665203        nan        nan\n",
      " 0.5               nan 0.5        0.76138907 0.76138907 0.75886942\n",
      " 0.75876864 0.75856708        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.78769462 0.78769462 0.76990573 0.77403812 0.77030893\n",
      "        nan        nan 0.73543652        nan 0.73971999 0.80744879\n",
      " 0.80744879 0.77146819 0.76647933 0.76652972        nan        nan\n",
      " 0.79560656        nan 0.76264944 0.81742619 0.8174766  0.79661411\n",
      " 0.76204492 0.76360697        nan        nan 0.81707341        nan\n",
      " 0.76456441 0.81646869 0.81646869 0.81520885 0.7614906  0.76325423\n",
      "        nan        nan 0.81651906        nan 0.7634054  0.8163175\n",
      " 0.8163175  0.81626709 0.76154099 0.76325423        nan        nan\n",
      " 0.81646869        nan 0.76325423 0.81631751 0.81631751 0.81641828\n",
      " 0.76154099 0.76325423        nan        nan 0.8163679         nan\n",
      " 0.76325423 0.81631751 0.81626712 0.81631751 0.76154099 0.76325423]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.75609776\n",
      " 0.75609776 0.75564418 0.75564418 0.75564418        nan        nan\n",
      " 0.5               nan 0.5        0.76012912 0.76012912 0.75690393\n",
      " 0.75720629 0.75695435        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.78678712 0.78678712 0.76587365 0.77000592 0.76602484\n",
      "        nan        nan 0.73573887        nan 0.74012311 0.8151581\n",
      " 0.81505732 0.77076156 0.76355546 0.76174127        nan        nan\n",
      " 0.8060373         nan 0.76007832 0.82800772 0.82805811 0.79827611\n",
      " 0.75922185 0.76078393        nan        nan 0.82594111        nan\n",
      " 0.76159015 0.8239753  0.8239753  0.82337144 0.75886911 0.76043117\n",
      "        nan        nan 0.82337056        nan 0.76053195 0.82352171\n",
      " 0.8235721  0.82276594 0.75876833 0.76043117        nan        nan\n",
      " 0.82347133        nan 0.76048156 0.82347129 0.82347129 0.82342093\n",
      " 0.75876833 0.76043117        nan        nan 0.82352171        nan\n",
      " 0.76043117 0.82347128 0.82352168 0.82352171 0.75876833 0.76043117]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76209444\n",
      " 0.76209444 0.76204409 0.76204409 0.76204409        nan        nan\n",
      " 0.5               nan 0.5        0.77121555 0.77121555 0.76854468\n",
      " 0.7684943  0.76829271        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.8061377  0.8061377  0.78829843 0.79142277 0.7886512\n",
      "        nan        nan 0.74264289        nan 0.74606968 0.83168629\n",
      " 0.83168629 0.78885167 0.7887512  0.78890278        nan        nan\n",
      " 0.81954163        nan 0.78784466 0.84216741 0.8422178  0.80225553\n",
      " 0.78582832 0.78844918        nan        nan 0.83939599        nan\n",
      " 0.78799568 0.84085717 0.84085717 0.83284451 0.7856267  0.78834842\n",
      "        nan        nan 0.8400508         nan 0.78834841 0.83979879\n",
      " 0.83984918 0.83939577 0.78552591 0.7884492         nan        nan\n",
      " 0.83969799        nan 0.78834842 0.83984918 0.83984918 0.83969799\n",
      " 0.78552591 0.7884492         nan        nan 0.83969799        nan\n",
      " 0.78839881 0.83984918 0.83984918 0.8397484  0.78552591 0.7884492 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76133861\n",
      " 0.76133861 0.76128823 0.76128823 0.76128823        nan        nan\n",
      " 0.5               nan 0.5        0.76950226 0.76950226 0.76662985\n",
      " 0.76678102 0.76647867        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80150157 0.80150157 0.78114256 0.78461974 0.78154573\n",
      "        nan        nan 0.73730126        nan 0.74108075 0.82624397\n",
      " 0.82634475 0.77292754 0.77323034 0.77569984        nan        nan\n",
      " 0.81364593        nan 0.77952972 0.83702717 0.83707756 0.78965738\n",
      " 0.76919882 0.77529669        nan        nan 0.83697641        nan\n",
      " 0.77408728 0.83793373 0.83798413 0.8236723  0.76859416 0.77504473\n",
      "        nan        nan 0.83637139        nan 0.7752463  0.83622021\n",
      " 0.83622021 0.83616995 0.76854375 0.77499434        nan        nan\n",
      " 0.83622021        nan 0.77499434 0.83627061 0.83622022 0.83601862\n",
      " 0.76849336 0.77499434        nan        nan 0.83611942        nan\n",
      " 0.77499434 0.836321   0.836321   0.83622021 0.76849336 0.77499434]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76048189\n",
      " 0.76048189 0.76063309 0.76063309 0.7605827         nan        nan\n",
      " 0.5               nan 0.5        0.76673063 0.76673063 0.76340471\n",
      " 0.76320314 0.76310235        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80074537 0.80074537 0.77882427 0.78346044 0.77973141\n",
      "        nan        nan 0.73543667        nan 0.73946808 0.8241778\n",
      " 0.8241778  0.77549743 0.77564911 0.77776589        nan        nan\n",
      " 0.81208369        nan 0.77857213 0.8382372  0.8382372  0.78930467\n",
      " 0.77348201 0.77741313        nan        nan 0.8361209         nan\n",
      " 0.77796749 0.83889256 0.83889256 0.82478192 0.77317964 0.77711079\n",
      "        nan        nan 0.83808631        nan 0.77706039 0.83828786\n",
      " 0.83833826 0.83576818 0.77317964 0.7770604         nan        nan\n",
      " 0.83783433        nan 0.77701001 0.83788472 0.83783433 0.83773355\n",
      " 0.77317964 0.7770604         nan        nan 0.83793511        nan\n",
      " 0.7770604  0.83788471 0.83793511 0.8379855  0.77317964 0.7770604 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76002835\n",
      " 0.76002835 0.75977641 0.7598268  0.75987719        nan        nan\n",
      " 0.5               nan 0.5        0.76637778 0.76637778 0.76209437\n",
      " 0.76214479 0.76199361        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.7980747  0.7980747  0.77615342 0.77988248 0.77726207\n",
      "        nan        nan 0.73468066        nan 0.73926649 0.81339317\n",
      " 0.81339317 0.76461244 0.76622523 0.77091203        nan        nan\n",
      " 0.8031139         nan 0.77207165 0.81873463 0.81868424 0.76667876\n",
      " 0.76264722 0.76950097        nan        nan 0.81868413        nan\n",
      " 0.76965223 0.81334212 0.81334212 0.7999883  0.76219367 0.76945058\n",
      "        nan        nan 0.81203169        nan 0.76960175 0.8118301\n",
      " 0.8118301  0.81001608 0.76214328 0.76945058        nan        nan\n",
      " 0.8119813         nan 0.76945058 0.81177974 0.81183013 0.81147733\n",
      " 0.76214328 0.76950097        nan        nan 0.81177973        nan\n",
      " 0.76945058 0.81177974 0.81177974 0.81172935 0.76214328 0.76950097]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76012913\n",
      " 0.76012913 0.7597764  0.7597764  0.7597764         nan        nan\n",
      " 0.5               nan 0.5        0.76748645 0.76743606 0.76390847\n",
      " 0.7637069  0.76360612        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.79585711 0.79585711 0.77554852 0.77968071 0.77756428\n",
      "        nan        nan 0.7355879         nan 0.73891374 0.81319169\n",
      " 0.8131413  0.75670108 0.76360486 0.76904757        nan        nan\n",
      " 0.80719536        nan 0.77519578 0.8158115  0.8158115  0.75589492\n",
      " 0.75922068 0.76783814        nan        nan 0.8137448         nan\n",
      " 0.76884602 0.80936026 0.80936026 0.79373896 0.75881754 0.76758618\n",
      "        nan        nan 0.80729413        nan 0.76793894 0.80658862\n",
      " 0.80653823 0.80396817 0.75871676 0.76758618        nan        nan\n",
      " 0.80633665        nan 0.76763657 0.80613506 0.80613506 0.80623588\n",
      " 0.75871676 0.76758618        nan        nan 0.80618546        nan\n",
      " 0.76758618 0.80603427 0.80603427 0.80603427 0.75871676 0.76758618]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76088505\n",
      " 0.76088505 0.76088504 0.76088505 0.76088505        nan        nan\n",
      " 0.5               nan 0.5        0.76834321 0.76834321 0.76431177\n",
      " 0.76436215 0.76426136        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.79817539 0.79817539 0.77665712 0.78099094 0.77741307\n",
      "        nan        nan 0.73503348        nan 0.7390649  0.81173068\n",
      " 0.81168029 0.76758596 0.77025673 0.77509453        nan        nan\n",
      " 0.79656229        nan 0.77781565 0.80628768 0.80623729 0.76224438\n",
      " 0.76496554 0.7725245         nan        nan 0.80316292        nan\n",
      " 0.77373394 0.80029041 0.80029041 0.78658345 0.76456242 0.77232294\n",
      "        nan        nan 0.79913125        nan 0.77262528 0.79918164\n",
      " 0.79908084 0.79686347 0.76441123 0.77227255        nan        nan\n",
      " 0.79882888        nan 0.77217177 0.79882884 0.79882884 0.79837535\n",
      " 0.76436084 0.77227255        nan        nan 0.79887926        nan\n",
      " 0.77227255 0.79877844 0.79882884 0.79872805 0.76436084 0.77227255]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76138898\n",
      " 0.76138898 0.76118745 0.76118745 0.76118745        nan        nan\n",
      " 0.5               nan 0.5        0.76834317 0.76839356 0.76416053\n",
      " 0.76411013 0.76400935        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.79888083 0.79893122 0.77685865 0.78089017 0.77766501\n",
      "        nan        nan 0.73634384        nan 0.74067769 0.80245835\n",
      " 0.80245835 0.75307281 0.76617476 0.77373395        nan        nan\n",
      " 0.80497761        nan 0.77675767 0.79696505 0.79691466 0.74768059\n",
      " 0.75896875 0.77212133        nan        nan 0.79550299        nan\n",
      " 0.77232294 0.78809517 0.78814557 0.77050811 0.75841443 0.77161743\n",
      "        nan        nan 0.78708726        nan 0.77176857 0.78653288\n",
      " 0.78648249 0.78229991 0.75831365 0.77151664        nan        nan\n",
      " 0.78597848        nan 0.77151664 0.78567611 0.78567611 0.78582731\n",
      " 0.75831365 0.77151664        nan        nan 0.78587767        nan\n",
      " 0.77151664 0.78572652 0.78567611 0.78577689 0.75831365 0.77151664]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76229616\n",
      " 0.76229616 0.76204419 0.76199378 0.76199378        nan        nan\n",
      " 0.5               nan 0.5        0.77076215 0.77076215 0.76652906\n",
      " 0.76647868 0.76642828        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80104775 0.80104775 0.77988243 0.78330922 0.77998328\n",
      "        nan        nan 0.73583989        nan 0.73966975 0.79893132\n",
      " 0.79893132 0.76083379 0.76723341 0.77544772        nan        nan\n",
      " 0.79036436        nan 0.77685873 0.79318594 0.79318594 0.74929451\n",
      " 0.76199263 0.77494374        nan        nan 0.7874411         nan\n",
      " 0.77494378 0.78351007 0.78351007 0.76607501 0.76118635 0.77464137\n",
      "        nan        nan 0.78013328        nan 0.77474215 0.77917572\n",
      " 0.77917572 0.77781555 0.76108556 0.77459097        nan        nan\n",
      " 0.7783189         nan 0.77464136 0.7783189  0.7783189  0.77872218\n",
      " 0.76118634 0.77459097        nan        nan 0.77821812        nan\n",
      " 0.77459097 0.77811732 0.77811732 0.77816772 0.76118634 0.77459097]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76113713\n",
      " 0.76113713 0.76123791 0.76118752 0.76113713        nan        nan\n",
      " 0.5               nan 0.5        0.76950229 0.76950229 0.7651685\n",
      " 0.76537006 0.76521889        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.79535362 0.79535362 0.77670784 0.77978183 0.77811885\n",
      "        nan        nan 0.73594069        nan 0.73966978 0.79323695\n",
      " 0.79323695 0.75272038 0.76531853 0.77111383        nan        nan\n",
      " 0.79187586        nan 0.78033586 0.77791671 0.77786632 0.72964021\n",
      " 0.76088391 0.76955161        nan        nan 0.77322978        nan\n",
      " 0.77166808 0.7640076  0.76395721 0.74163314 0.76058157 0.76940042\n",
      "        nan        nan 0.75982481        nan 0.76950121 0.75891765\n",
      " 0.75881687 0.75443275 0.76043038 0.76935003        nan        nan\n",
      " 0.75821204        nan 0.76935003 0.75821203 0.75816164 0.75745617\n",
      " 0.76043038 0.76935003        nan        nan 0.75811124        nan\n",
      " 0.76935003 0.75816163 0.75816163 0.75806082 0.76043038 0.76935003]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76179217\n",
      " 0.76179217 0.76148976 0.76143937 0.76148976        nan        nan\n",
      " 0.5               nan 0.5        0.76793995 0.76793995 0.76456369\n",
      " 0.76466447 0.76441252        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.79626062 0.79626062 0.77600231 0.77988264 0.7771614\n",
      "        nan        nan 0.73589027        nan 0.73961937 0.78376228\n",
      " 0.78376228 0.74128114 0.75634863 0.76819108        nan        nan\n",
      " 0.78547548        nan 0.77469175 0.78068742 0.7807378  0.72016603\n",
      " 0.75004958 0.76637691        nan        nan 0.78517232        nan\n",
      " 0.76723357 0.78154389 0.78159428 0.7469237  0.74929364 0.7661753\n",
      "        nan        nan 0.77751233        nan 0.7662761  0.77675646\n",
      " 0.77680685 0.77201944 0.74919286 0.76612491        nan        nan\n",
      " 0.77635338        nan 0.7661753  0.77625259 0.77630298 0.7754966\n",
      " 0.74919286 0.76612491        nan        nan 0.77620222        nan\n",
      " 0.76612491 0.77645421 0.77645421 0.7764038  0.74919286 0.76612491]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76023005\n",
      " 0.76023005 0.75992768 0.75997807 0.75997807        nan        nan\n",
      " 0.5               nan 0.5        0.76693226 0.76693226 0.76315279\n",
      " 0.76320318 0.76320318        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.79172543 0.79172543 0.77141677 0.77484355 0.773231\n",
      "        nan        nan 0.73609188        nan 0.73997216 0.78441832\n",
      " 0.78436791 0.74027352 0.75604637 0.76506705        nan        nan\n",
      " 0.77534727        nan 0.77045919 0.76849339 0.768443   0.7132626\n",
      " 0.74979782 0.76395833        nan        nan 0.76395785        nan\n",
      " 0.76476468 0.76168971 0.76168971 0.72601139 0.74899152 0.76360562\n",
      "        nan        nan 0.75236669        nan 0.76350483 0.74979672\n",
      " 0.74979672 0.74848628 0.74884034 0.76360562        nan        nan\n",
      " 0.74762978        nan 0.76360562 0.74757935 0.74752896 0.74768017\n",
      " 0.74878995 0.76360562        nan        nan 0.74707542        nan\n",
      " 0.76360562 0.74717621 0.74717621 0.74727699 0.74878995 0.76360562]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76118741\n",
      " 0.76118741 0.76088508 0.76093547 0.76088508        nan        nan\n",
      " 0.5               nan 0.5        0.76884725 0.76884725 0.76481575\n",
      " 0.76481575 0.76476535        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.79852819 0.79852819 0.77499458 0.77867333 0.77620405\n",
      "        nan        nan 0.73599109        nan 0.73997216 0.79651236\n",
      " 0.79651236 0.74889052 0.76209337 0.76970286        nan        nan\n",
      " 0.79449569        nan 0.77645546 0.78058676 0.78058676 0.72832925\n",
      " 0.75513917 0.76874542        nan        nan 0.77872132        nan\n",
      " 0.77015641 0.76874338 0.76874338 0.74641875 0.75463527 0.76859421\n",
      "        nan        nan 0.75533856        nan 0.768695   0.75281896\n",
      " 0.75291974 0.75281834 0.75453449 0.7686446         nan        nan\n",
      " 0.74304206        nan 0.76859421 0.74394921 0.74394923 0.74707401\n",
      " 0.75453449 0.7686446         nan        nan 0.74052212        nan\n",
      " 0.7686446  0.74047169 0.74047169 0.74193334 0.75453449 0.7686446 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76148974\n",
      " 0.76148974 0.76123777 0.76123777 0.76123777        nan        nan\n",
      " 0.5               nan 0.5        0.76869577 0.76869577 0.76592417\n",
      " 0.76587379 0.76557143        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.79983835 0.79978795 0.77781643 0.78094082 0.77983216\n",
      "        nan        nan 0.73604148        nan 0.73977058 0.7929343\n",
      " 0.7929343  0.75125896 0.76269823 0.77272662        nan        nan\n",
      " 0.79177502        nan 0.78194838 0.77237242 0.77237242 0.72419755\n",
      " 0.75927151 0.77131556        nan        nan 0.76571995        nan\n",
      " 0.77297855 0.74823261 0.74823261 0.7220791  0.75896917 0.77121478\n",
      "        nan        nan 0.72540269        nan 0.77141635 0.72217771\n",
      " 0.72207692 0.72298531 0.7588684  0.77121478        nan        nan\n",
      " 0.7136611         nan 0.77121478 0.71376193 0.71381233 0.71441702\n",
      " 0.7588684  0.77121478        nan        nan 0.71214934        nan\n",
      " 0.77121478 0.71330861 0.71340942 0.71250203 0.7588684  0.77121478]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76254799\n",
      " 0.76254799 0.76234642 0.76239681 0.76229603        nan        nan\n",
      " 0.5               nan 0.5        0.77025799 0.7702076  0.76688158\n",
      " 0.76668    0.76678081        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80311415 0.80306376 0.78109217 0.78451889 0.7830071\n",
      "        nan        nan 0.73609188        nan 0.73992177 0.79308617\n",
      " 0.79308617 0.75125973 0.76950165 0.77766534        nan        nan\n",
      " 0.79590752        nan 0.78310771 0.76184108 0.76184108 0.71603463\n",
      " 0.76305155 0.7764559         nan        nan 0.75312227        nan\n",
      " 0.77837081 0.73311591 0.73306551 0.69819456 0.76204368 0.77590156\n",
      "        nan        nan 0.7105892         nan 0.77620394 0.71391538\n",
      " 0.71396577 0.69965448 0.76214447 0.77590156        nan        nan\n",
      " 0.69647873        nan 0.77590156 0.7000572  0.70000679 0.70262714\n",
      " 0.76219486 0.77590156        nan        nan 0.69451335        nan\n",
      " 0.77590156 0.69627767 0.69773935 0.69310242 0.76219486 0.77590156]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76108669\n",
      " 0.76108669 0.76078432 0.76083471 0.76078432        nan        nan\n",
      " 0.5               nan 0.5        0.76839371 0.76834332 0.76471491\n",
      " 0.7647149  0.76466451        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.79454751 0.79454751 0.7755492  0.77811926 0.7768594\n",
      "        nan        nan 0.73604148        nan 0.73966978 0.7840652\n",
      " 0.7840652  0.74601864 0.76058197 0.7695524         nan        nan\n",
      " 0.78502312        nan 0.77766525 0.75826306 0.75826306 0.71295995\n",
      " 0.75564345 0.76819172        nan        nan 0.75750686        nan\n",
      " 0.76935066 0.7355352  0.7355352  0.69557385 0.75478676 0.76788939\n",
      "        nan        nan 0.70524832        nan 0.76799013 0.70670981\n",
      " 0.70681059 0.69824432 0.75468598 0.76793978        nan        nan\n",
      " 0.6919444         nan 0.76793979 0.69637861 0.69637861 0.68882044\n",
      " 0.75468598 0.76793978        nan        nan 0.68579632        nan\n",
      " 0.76793978 0.69315307 0.69280033 0.685645   0.75468598 0.76793978]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76229603\n",
      " 0.76229603 0.76219524 0.76219524 0.76214485        nan        nan\n",
      " 0.5               nan 0.5        0.76935099 0.76935099 0.76567232\n",
      " 0.76557154 0.76547076        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80412194 0.80412194 0.78310766 0.78613126 0.78492187\n",
      "        nan        nan 0.73599108        nan 0.73972017 0.79505091\n",
      " 0.79505091 0.75720571 0.77151729 0.77867316        nan        nan\n",
      " 0.79872907        nan 0.78698798 0.76960183 0.76955144 0.7247019\n",
      " 0.76708266 0.77706056        nan        nan 0.76113482        nan\n",
      " 0.77826992 0.7386093  0.7386093  0.70489652 0.76632677 0.77701015\n",
      "        nan        nan 0.70489636        nan 0.77711097 0.70812113\n",
      " 0.70817152 0.70136795 0.76637716 0.77701015        nan        nan\n",
      " 0.69229816        nan 0.77695976 0.69945365 0.69945365 0.68322619\n",
      " 0.76642755 0.77701015        nan        nan 0.68625035        nan\n",
      " 0.77701015 0.69683317 0.69688357 0.67889229 0.76637715 0.77701015]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76269923\n",
      " 0.76269923 0.76264882 0.76264882 0.76269921        nan        nan\n",
      " 0.5               nan 0.5        0.76980449 0.76980449 0.76627693\n",
      " 0.76632731 0.76642807        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80281155 0.80281155 0.78411542 0.78698784 0.78512334\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.79358883\n",
      " 0.79358883 0.75115776 0.76803933 0.77776554        nan        nan\n",
      " 0.79106905        nan 0.77993261 0.76289881 0.76289881 0.70595477\n",
      " 0.76194189 0.775901          nan        nan 0.75075352        nan\n",
      " 0.7767073  0.72706919 0.72706919 0.67647372 0.76118601 0.77564904\n",
      "        nan        nan 0.69517071        nan 0.77569944 0.69345711\n",
      " 0.69345711 0.66316976 0.76113561 0.77564904        nan        nan\n",
      " 0.67647514        nan 0.77559865 0.68584782 0.68584782 0.64366822\n",
      " 0.76113561 0.77564904        nan        nan 0.64704419        nan\n",
      " 0.77559865 0.68549508 0.68514233 0.63923365 0.76113561 0.77564904]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76375745\n",
      " 0.76375745 0.76360631 0.76355592 0.7636567         nan        nan\n",
      " 0.5               nan 0.5        0.77187081 0.77187081 0.76804086\n",
      " 0.7677889  0.76758735        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80644012 0.80644012 0.78708893 0.79071732 0.78915513\n",
      "        nan        nan 0.73609188        nan 0.73982097 0.79610922\n",
      " 0.79610922 0.7563992  0.77353291 0.78068888        nan        nan\n",
      " 0.79686516        nan 0.78865112 0.75927116 0.75927116 0.71124706\n",
      " 0.76894714 0.7790763         nan        nan 0.74400175        nan\n",
      " 0.78109205 0.71850287 0.71850286 0.67466125 0.76879597 0.77867317\n",
      "        nan        nan 0.68085993        nan 0.77872357 0.6848413\n",
      " 0.68494208 0.6574779  0.76879596 0.77862278        nan        nan\n",
      " 0.66654773        nan 0.77857239 0.68055799 0.68055801 0.64805476\n",
      " 0.76879596 0.77862278        nan        nan 0.64689508        nan\n",
      " 0.77862278 0.67823995 0.6783407  0.64669419 0.76879596 0.77862278]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76269919\n",
      " 0.76269919 0.76254802 0.76259841 0.76259841        nan        nan\n",
      " 0.5               nan 0.5        0.7697542  0.7697542  0.76673052\n",
      " 0.76678093 0.76652898        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80432364 0.80427324 0.78426693 0.78809685 0.78512373\n",
      "        nan        nan 0.73609188        nan 0.73977057 0.79590764\n",
      " 0.79590764 0.758818   0.77192029 0.77973134        nan        nan\n",
      " 0.79918292        nan 0.7858291  0.76909807 0.76904768 0.72354307\n",
      " 0.7666792  0.77897547        nan        nan 0.75826384        nan\n",
      " 0.77947937 0.7370488  0.73709919 0.69829691 0.76592329 0.77862272\n",
      "        nan        nan 0.7169427         nan 0.77867311 0.72117576\n",
      " 0.72122615 0.68630399 0.7659233  0.77852194        nan        nan\n",
      " 0.69764208        nan 0.77862272 0.71905921 0.7191096  0.68176899\n",
      " 0.7659233  0.77852194        nan        nan 0.68222181        nan\n",
      " 0.77852194 0.71563257 0.71588452 0.68005571 0.7659233  0.77852194]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76269924\n",
      " 0.76269924 0.76264886 0.76264886 0.76264886        nan        nan\n",
      " 0.5               nan 0.5        0.77051014 0.77051014 0.7671842\n",
      " 0.76733538 0.76713382        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80371865 0.80371865 0.78517405 0.7876937  0.7860308\n",
      "        nan        nan 0.73609188        nan 0.73977057 0.79434517\n",
      " 0.79434517 0.75755805 0.77166838 0.77988266        nan        nan\n",
      " 0.79812488        nan 0.78784478 0.76169014 0.76169014 0.72364356\n",
      " 0.76829198 0.77842125        nan        nan 0.74133175        nan\n",
      " 0.78003392 0.73160507 0.73160507 0.69658156 0.76793924 0.7781189\n",
      "        nan        nan 0.71477383        nan 0.77857244 0.72077031\n",
      " 0.7208207  0.68292493 0.76798963 0.77816929        nan        nan\n",
      " 0.70393897        nan 0.77816929 0.71804889 0.71804889 0.67884298\n",
      " 0.76798963 0.77816929        nan        nan 0.67894393        nan\n",
      " 0.77816929 0.71688987 0.71694027 0.67854053 0.76798963 0.77816929]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76491655\n",
      " 0.76491655 0.7645638  0.76461419 0.76461419        nan        nan\n",
      " 0.5               nan 0.5        0.77353363 0.77353363 0.76990539\n",
      " 0.76980459 0.76975422        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.81052188 0.81052188 0.79333769 0.79676442 0.79379131\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.80769973\n",
      " 0.80769973 0.77393601 0.78638329 0.79096911        nan        nan\n",
      " 0.79787302        nan 0.79147302 0.76899798 0.76899798 0.7321609\n",
      " 0.78330931 0.7898101         nan        nan 0.75796193        nan\n",
      " 0.79106993 0.73004477 0.73009516 0.69366084 0.78275497 0.78945733\n",
      "        nan        nan 0.72082274        nan 0.78940698 0.71331457\n",
      " 0.71331457 0.68171737 0.78285575 0.78945733        nan        nan\n",
      " 0.7052005         nan 0.78940694 0.70434479 0.70439519 0.6794495\n",
      " 0.78285575 0.78945733        nan        nan 0.66715422        nan\n",
      " 0.78945733 0.70041424 0.70061584 0.67597287 0.78285575 0.78945733]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76280004\n",
      " 0.76280004 0.76264886 0.76264886 0.76269925        nan        nan\n",
      " 0.5               nan 0.5        0.77161876 0.77161876 0.76783924\n",
      " 0.76814158 0.76794002        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80588577 0.80588577 0.78708898 0.79117083 0.78855035\n",
      "        nan        nan 0.73609188        nan 0.73982097 0.79091896\n",
      " 0.79091896 0.75539144 0.77474235 0.7829064         nan        nan\n",
      " 0.79862795        nan 0.78794544 0.74899201 0.74899201 0.70464634\n",
      " 0.76975347 0.78078993        nan        nan 0.73886228        nan\n",
      " 0.78341027 0.71507704 0.71502665 0.6739063  0.76924955 0.78068916\n",
      "        nan        nan 0.69310609        nan 0.78089073 0.69240036\n",
      " 0.69240038 0.659494   0.76914877 0.78068916        nan        nan\n",
      " 0.68156551        nan 0.78063876 0.68720963 0.68710884 0.65495865\n",
      " 0.76914877 0.78068916        nan        nan 0.64901218        nan\n",
      " 0.78068916 0.68554661 0.6854458  0.65047374 0.76914877 0.78068916]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76501725\n",
      " 0.76501725 0.76501728 0.76501728 0.76501728        nan        nan\n",
      " 0.5               nan 0.5        0.7735841  0.7735841  0.77005648\n",
      " 0.77020767 0.77000612        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.81092511 0.81092511 0.79333769 0.79575659 0.79313611\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.8032652\n",
      " 0.8032652  0.76577254 0.78356117 0.78975975        nan        nan\n",
      " 0.79610867        nan 0.79222891 0.7589195  0.7589195  0.71522894\n",
      " 0.77847154 0.78900389        nan        nan 0.73241315        nan\n",
      " 0.79001177 0.72319157 0.72324196 0.68030723 0.77801802 0.78860073\n",
      "        nan        nan 0.70016148        nan 0.78900391 0.71029107\n",
      " 0.71024068 0.67113533 0.77786684 0.78865113        nan        nan\n",
      " 0.67420898        nan 0.78865113 0.70711637 0.70701557 0.66947217\n",
      " 0.77786684 0.78865113        nan        nan 0.66261879        nan\n",
      " 0.78865113 0.70565491 0.70545335 0.66811147 0.77786684 0.78865113]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76380788\n",
      " 0.76380788 0.76370712 0.76370712 0.76370712        nan        nan\n",
      " 0.5               nan 0.5        0.77045968 0.77045968 0.76758732\n",
      " 0.76753693 0.76733534        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80618826 0.80618826 0.78693805 0.79046542 0.78875216\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.79374139\n",
      " 0.79374139 0.75584586 0.77585141 0.78255392        nan        nan\n",
      " 0.77867437        nan 0.7834609  0.75352853 0.75352853 0.71800188\n",
      " 0.77091305 0.78149565        nan        nan 0.72964256        nan\n",
      " 0.78275547 0.72233544 0.72233544 0.68630484 0.76990521 0.7810421\n",
      "        nan        nan 0.70620891        nan 0.78124369 0.71160152\n",
      " 0.71165192 0.6756717  0.7699052  0.7810421         nan        nan\n",
      " 0.67184158        nan 0.7810421  0.7071666  0.70741856 0.67108581\n",
      " 0.7699052  0.7810421         nan        nan 0.66171204        nan\n",
      " 0.7810421  0.70464684 0.70494918 0.66786047 0.7699052  0.7810421 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76365684\n",
      " 0.76365684 0.76365682 0.76365682 0.76365682        nan        nan\n",
      " 0.5               nan 0.5        0.77101407 0.77101407 0.76799048\n",
      " 0.76819203 0.76804085        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80553323 0.80553323 0.78406558 0.78779462 0.7853254\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.78572927\n",
      " 0.78572927 0.7485393  0.76995572 0.78008468        nan        nan\n",
      " 0.79802428        nan 0.79187631 0.75060556 0.75060556 0.7106441\n",
      " 0.76511803 0.77811935        nan        nan 0.73599157        nan\n",
      " 0.78043749 0.71578355 0.71578355 0.67869433 0.76476531 0.77771619\n",
      "        nan        nan 0.70515125        nan 0.77786736 0.70263078\n",
      " 0.70263078 0.66584344 0.76476531 0.77776658        nan        nan\n",
      " 0.67531638        nan 0.77781697 0.69819614 0.69829692 0.66105587\n",
      " 0.76476531 0.77776658        nan        nan 0.65586523        nan\n",
      " 0.77776658 0.6957268  0.6959788  0.65919152 0.76476531 0.77776658]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76340481\n",
      " 0.76340481 0.76320325 0.76315285 0.76315285        nan        nan\n",
      " 0.5               nan 0.5        0.77131651 0.77131651 0.7681921\n",
      " 0.76819211 0.76809132        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80558367 0.80558367 0.78638366 0.78870168 0.78688757\n",
      "        nan        nan 0.73609188        nan 0.73982097 0.79157479\n",
      " 0.79157479 0.75428392 0.7729792  0.78210029        nan        nan\n",
      " 0.77731315        nan 0.78628265 0.75695512 0.75695512 0.71517977\n",
      " 0.76799041 0.78124362        nan        nan 0.7396194         nan\n",
      " 0.78300731 0.72807988 0.72807988 0.68544728 0.76718411 0.78104206\n",
      "        nan        nan 0.72001633        nan 0.78119326 0.7137178\n",
      " 0.71366741 0.67546915 0.76723451 0.78109245        nan        nan\n",
      " 0.70242746        nan 0.78109245 0.70656196 0.70661236 0.66937151\n",
      " 0.76723451 0.78109245        nan        nan 0.65057503        nan\n",
      " 0.78109245 0.70444553 0.70449592 0.66367685 0.76723451 0.78109245]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76380794\n",
      " 0.76380794 0.76365679 0.76365679 0.76365679        nan        nan\n",
      " 0.5               nan 0.5        0.77151799 0.77151799 0.76829282\n",
      " 0.76814166 0.76799048        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80568433 0.80568433 0.78794572 0.78960878 0.78764341\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.79626109\n",
      " 0.79626109 0.76305198 0.77731283 0.78330975        nan        nan\n",
      " 0.78729079        nan 0.78809674 0.75675327 0.75675327 0.71941209\n",
      " 0.77348299 0.78199956        nan        nan 0.73256418        nan\n",
      " 0.78461989 0.72868391 0.72868391 0.69285449 0.77247511 0.78174759\n",
      "        nan        nan 0.71240643        nan 0.78235231 0.71432172\n",
      " 0.71427131 0.67909668 0.77247511 0.78194916        nan        nan\n",
      " 0.67662687        nan 0.78194916 0.70812336 0.70827456 0.67415808\n",
      " 0.77247511 0.78194916        nan        nan 0.66271843        nan\n",
      " 0.78194916 0.7056541  0.706662   0.66871548 0.77247511 0.78194916]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76416077\n",
      " 0.76416077 0.76380802 0.76370724 0.76370724        nan        nan\n",
      " 0.5               nan 0.5        0.77131653 0.77131653 0.76763783\n",
      " 0.76778901 0.76743627        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80543261 0.80543261 0.78598078 0.78875238 0.7869382\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.78840082\n",
      " 0.78840082 0.75247041 0.7719719  0.78189911        nan        nan\n",
      " 0.78346115        nan 0.78527473 0.74637318 0.74637318 0.7010703\n",
      " 0.76663018 0.78079048        nan        nan 0.7291393         nan\n",
      " 0.78189904 0.71558286 0.71563325 0.67345445 0.76562236 0.78084091\n",
      "        nan        nan 0.70343819        nan 0.78104244 0.70374051\n",
      " 0.70374051 0.66705431 0.76557197 0.78094169        nan        nan\n",
      " 0.66302292        nan 0.78084089 0.70101939 0.70106978 0.66231736\n",
      " 0.76552158 0.78094169        nan        nan 0.64074958        nan\n",
      " 0.78094169 0.69915476 0.69920513 0.65511132 0.76552158 0.78094169]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76411026\n",
      " 0.76411026 0.76365677 0.76365677 0.76370716        nan        nan\n",
      " 0.5               nan 0.5        0.77187068 0.77187068 0.76809123\n",
      " 0.76788965 0.76773846        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80633929 0.80633929 0.78789536 0.79107008 0.78829846\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.79429569\n",
      " 0.79429569 0.76053248 0.77711131 0.78608127        nan        nan\n",
      " 0.78945755        nan 0.7901124  0.75811356 0.75811356 0.71538071\n",
      " 0.77257601 0.78446867        nan        nan 0.73140474        nan\n",
      " 0.78567809 0.72969181 0.72969181 0.68484232 0.77232406 0.7843175\n",
      "        nan        nan 0.70605738        nan 0.78431749 0.7163376\n",
      " 0.7163376  0.67546897 0.77232407 0.78436789        nan        nan\n",
      " 0.67823961        nan 0.78441828 0.7118525  0.71170133 0.67173984\n",
      " 0.77232407 0.78436789        nan        nan 0.65349767        nan\n",
      " 0.78436789 0.71023982 0.71008859 0.66246763 0.77232407 0.78436789]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76471494\n",
      " 0.76476534 0.7645134  0.7645134  0.7645134         nan        nan\n",
      " 0.5               nan 0.5        0.7725762  0.7725762  0.76884715\n",
      " 0.76879675 0.76864554        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80850621 0.80850621 0.78890315 0.7920275  0.79011255\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.80004017\n",
      " 0.79998978 0.76733495 0.78300695 0.78885275        nan        nan\n",
      " 0.78613143        nan 0.78855035 0.75791116 0.75791116 0.71961273\n",
      " 0.77665758 0.78804643        nan        nan 0.73195888        nan\n",
      " 0.78789526 0.73598953 0.73598953 0.69451617 0.77615366 0.78789524\n",
      "        nan        nan 0.70540127        nan 0.78824797 0.73064752\n",
      " 0.73064752 0.68615054 0.77610327 0.78789524        nan        nan\n",
      " 0.68080836        nan 0.78794563 0.72777506 0.72767429 0.68342933\n",
      " 0.77610327 0.78789524        nan        nan 0.66387642        nan\n",
      " 0.78789524 0.72611202 0.72671678 0.67909563 0.77610327 0.78789524]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76385831\n",
      " 0.76385831 0.76365675 0.76365675 0.76365675        nan        nan\n",
      " 0.5               nan 0.5        0.77192112 0.77197151 0.76819201\n",
      " 0.76804082 0.76778888        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.8067425  0.8067425  0.78749218 0.7917755  0.78870159\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.79973801\n",
      " 0.79973801 0.76350556 0.77932853 0.78623235        nan        nan\n",
      " 0.7816468         nan 0.78497246 0.76501768 0.76506808 0.72112549\n",
      " 0.77368463 0.78461979        nan        nan 0.73311828        nan\n",
      " 0.78577886 0.73785553 0.73785553 0.69880109 0.77328149 0.78467018\n",
      "        nan        nan 0.71114582        nan 0.78401508 0.72883542\n",
      " 0.72883542 0.69260269 0.7732311  0.78461979        nan        nan\n",
      " 0.67652553        nan 0.7845694  0.72324178 0.72334256 0.68902462\n",
      " 0.77318071 0.78461979        nan        nan 0.66624686        nan\n",
      " 0.78461979 0.720319   0.72036935 0.68267503 0.77318071 0.78461979]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76446301\n",
      " 0.76446301 0.76431182 0.76431182 0.76436221        nan        nan\n",
      " 0.5               nan 0.5        0.77207228 0.77207228 0.768696\n",
      " 0.76854484 0.76844405        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.8102197  0.8102197  0.79162452 0.79464805 0.79207802\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.80956501\n",
      " 0.80951462 0.77605357 0.78870173 0.79328752        nan        nan\n",
      " 0.77222331        nan 0.78537556 0.77232524 0.77232524 0.73604217\n",
      " 0.78330975 0.79248126        nan        nan 0.733421          nan\n",
      " 0.79238043 0.74733045 0.74728005 0.70343809 0.78280583 0.79263243\n",
      "        nan        nan 0.71401916        nan 0.7927836  0.73649606\n",
      " 0.73654647 0.69426649 0.78270505 0.79248125        nan        nan\n",
      " 0.67430961        nan 0.79263243 0.73065055 0.73049936 0.688421\n",
      " 0.78270505 0.79248125        nan        nan 0.65828539        nan\n",
      " 0.79248125 0.72677021 0.72787886 0.6848938  0.78270505 0.79248125]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76431185\n",
      " 0.76431185 0.76431185 0.76426146 0.76431185        nan        nan\n",
      " 0.5               nan 0.5        0.77222344 0.77222344 0.76824242\n",
      " 0.76814164 0.76804086        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80890938 0.80890938 0.7885504  0.79248104 0.7903141\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.80513009\n",
      " 0.8050797  0.77323107 0.78396456 0.78996155        nan        nan\n",
      " 0.78769393        nan 0.78764315 0.77363468 0.77363468 0.73589007\n",
      " 0.77963094 0.78910484        nan        nan 0.74692633        nan\n",
      " 0.79041503 0.75241876 0.75241876 0.71527897 0.77877426 0.78875209\n",
      "        nan        nan 0.71235541        nan 0.78905444 0.74359976\n",
      " 0.74349896 0.70741763 0.77867348 0.78880248        nan        nan\n",
      " 0.68846926        nan 0.78895367 0.7382076  0.73830838 0.69663366\n",
      " 0.77867348 0.78875209        nan        nan 0.67052958        nan\n",
      " 0.78880248 0.73437763 0.73447844 0.68927644 0.77867348 0.78875209]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76380784\n",
      " 0.76380784 0.76355589 0.76355589 0.76355589        nan        nan\n",
      " 0.5               nan 0.5        0.77232425 0.77232425 0.76854474\n",
      " 0.76869591 0.76834318        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80860695 0.80860695 0.79036453 0.79379121 0.79107006\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.80830493\n",
      " 0.80830493 0.77358376 0.78461974 0.7893567         nan        nan\n",
      " 0.78381339        nan 0.78668578 0.78245406 0.78240367 0.74284494\n",
      " 0.78058827 0.78839927        nan        nan 0.76022991        nan\n",
      " 0.78975997 0.77126692 0.77126692 0.72858343 0.7798828  0.78809688\n",
      "        nan        nan 0.72822969        nan 0.78844965 0.76295186\n",
      " 0.76295186 0.72374547 0.7798324  0.78809688        nan        nan\n",
      " 0.70449512        nan 0.78804649 0.75982738 0.75982737 0.7201676\n",
      " 0.7798324  0.78804649        nan        nan 0.68489219        nan\n",
      " 0.78804649 0.75796282 0.75786201 0.71160087 0.7798324  0.78804649]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76421103\n",
      " 0.76421103 0.76405985 0.76400946 0.76405985        nan        nan\n",
      " 0.5               nan 0.5        0.77176991 0.77176991 0.7680408\n",
      " 0.76809119 0.76794003        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80835502 0.80835502 0.79031407 0.79384161 0.7910196\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.81042126\n",
      " 0.81042126 0.77524664 0.7871393  0.78996134        nan        nan\n",
      " 0.78552696        nan 0.78703847 0.78658596 0.78658596 0.74732967\n",
      " 0.78300717 0.78885282        nan        nan 0.75579525        nan\n",
      " 0.79021335 0.77454196 0.77454196 0.73427774 0.78260403 0.78900402\n",
      "        nan        nan 0.7295911         nan 0.78870164 0.77076229\n",
      " 0.77076231 0.73175784 0.78255364 0.78900402        nan        nan\n",
      " 0.71124792        nan 0.78900401 0.76814182 0.76829299 0.72742405\n",
      " 0.78255364 0.78900402        nan        nan 0.70313463        nan\n",
      " 0.78900402 0.76582364 0.76607563 0.72681974 0.78255364 0.78900402]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76491651\n",
      " 0.76491651 0.76466456 0.76466456 0.76466456        nan        nan\n",
      " 0.5               nan 0.5        0.77262653 0.77262653 0.7694519\n",
      " 0.76930073 0.76904875        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.81032034 0.81032034 0.79217871 0.79575658 0.79248102\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.81037091\n",
      " 0.81037091 0.77917717 0.78940688 0.79026364        nan        nan\n",
      " 0.79016288        nan 0.78653441 0.78184904 0.78184904 0.74329831\n",
      " 0.78613137 0.78860072        nan        nan 0.7470279         nan\n",
      " 0.79051567 0.76607556 0.76607556 0.72636554 0.78547623 0.78875189\n",
      "        nan        nan 0.7301964         nan 0.78875189 0.75912084\n",
      " 0.75912084 0.71971345 0.78532505 0.7887015         nan        nan\n",
      " 0.69481915        nan 0.7887015  0.75493821 0.7548878  0.71381749\n",
      " 0.78532505 0.7887015         nan        nan 0.67949991        nan\n",
      " 0.78875189 0.75277115 0.75277115 0.70938339 0.78532505 0.7887015 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76506772\n",
      " 0.76506772 0.76486616 0.76486616 0.76486616        nan        nan\n",
      " 0.5               nan 0.5        0.77242504 0.77242504 0.76889751\n",
      " 0.76874636 0.76864557        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.81047163 0.81047163 0.79091887 0.79444637 0.79227944\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.81022024\n",
      " 0.81022024 0.77791807 0.78799612 0.79142278        nan        nan\n",
      " 0.78860091        nan 0.7879958  0.78230341 0.78225302 0.74249275\n",
      " 0.7834608  0.79016305        nan        nan 0.75070667        nan\n",
      " 0.79177556 0.76612731 0.7661777  0.72949107 0.78280572 0.79011266\n",
      "        nan        nan 0.72349416        nan 0.79041501 0.76219658\n",
      " 0.76219658 0.72440132 0.78280572 0.79011266        nan        nan\n",
      " 0.70207753        nan 0.79021346 0.75987841 0.76002962 0.7222848\n",
      " 0.78280572 0.79011266        nan        nan 0.69033522        nan\n",
      " 0.79011266 0.75851778 0.7591729  0.71397042 0.78275533 0.79011266]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76526928\n",
      " 0.76526928 0.76481573 0.76481572 0.76486612        nan        nan\n",
      " 0.5               nan 0.5        0.77202182 0.77202182 0.76869595\n",
      " 0.76879675 0.76869596        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.81117698 0.81117698 0.79343848 0.79621007 0.79358966\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.815914\n",
      " 0.815914   0.78472042 0.7930351  0.79409356        nan        nan\n",
      " 0.78633316        nan 0.78713922 0.79197775 0.79197775 0.75740789\n",
      " 0.78885258 0.79288404        nan        nan 0.75458518        nan\n",
      " 0.79384162 0.7758515  0.7758515  0.73956818 0.78834869 0.79298481\n",
      "        nan        nan 0.73074861        nan 0.79308563 0.76854398\n",
      " 0.76854399 0.73447809 0.78834868 0.7929344         nan        nan\n",
      " 0.71638572        nan 0.79303521 0.76511718 0.76536914 0.72878352\n",
      " 0.78834868 0.7929344         nan        nan 0.69144049        nan\n",
      " 0.7929344  0.76224458 0.76269817 0.7174953  0.78834868 0.7929344 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76506767\n",
      " 0.76506767 0.76456375 0.76456375 0.76461414        nan        nan\n",
      " 0.5               nan 0.5        0.77242503 0.77237464 0.76839361\n",
      " 0.76879675 0.76874637        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.81087472 0.81087472 0.79177554 0.7942952  0.79232987\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.81732516\n",
      " 0.81732516 0.78446864 0.79046532 0.7929346         nan        nan\n",
      " 0.77993338        nan 0.7850227  0.79379214 0.79374173 0.7547872\n",
      " 0.78658501 0.79227951        nan        nan 0.74355089        nan\n",
      " 0.79263224 0.77529725 0.77529725 0.73815711 0.78608106 0.79207794\n",
      "        nan        nan 0.72087353        nan 0.79202753 0.76894756\n",
      " 0.76894756 0.73241208 0.78618185 0.79212833        nan        nan\n",
      " 0.69633183        nan 0.79207794 0.7655206  0.76536942 0.72233326\n",
      " 0.78613146 0.79212833        nan        nan 0.68211856        nan\n",
      " 0.79212833 0.7625472  0.76274875 0.71311115 0.78613146 0.79212833]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76375743\n",
      " 0.76375743 0.76355588 0.76355588 0.76355588        nan        nan\n",
      " 0.5               nan 0.5        0.77030851 0.77030851 0.76703301\n",
      " 0.76713379 0.767033          nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80538177 0.80538177 0.7865348  0.79031426 0.78759301\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.79943596\n",
      " 0.79943596 0.76350561 0.77917742 0.78542611        nan        nan\n",
      " 0.77852217        nan 0.78723995 0.76355705 0.76355705 0.72243596\n",
      " 0.77459172 0.78406552        nan        nan 0.73629313        nan\n",
      " 0.78718986 0.74914407 0.74909368 0.71089559 0.77403742 0.78371274\n",
      "        nan        nan 0.71114649        nan 0.78416629 0.74329824\n",
      " 0.74339903 0.70651108 0.77393664 0.78376313        nan        nan\n",
      " 0.68509251        nan 0.78376313 0.74022421 0.74002264 0.6962813\n",
      " 0.77393664 0.78376313        nan        nan 0.66362541        nan\n",
      " 0.78376313 0.73800683 0.73785562 0.68579922 0.77393664 0.78376313]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.76471492\n",
      " 0.76476531 0.76476533 0.76476533 0.76476533        nan        nan\n",
      " 0.5               nan 0.5        0.77232429 0.77232429 0.76839361\n",
      " 0.76839361 0.76804085        nan        nan 0.77937848        nan\n",
      " 0.77937848 0.80976619 0.80976619 0.79253152 0.79515201 0.79243075\n",
      "        nan        nan 0.73609188        nan 0.73987138 0.81450371\n",
      " 0.81440293 0.78109287 0.78935689 0.79071749        nan        nan\n",
      " 0.78114262        nan 0.78683692 0.78920713 0.78920713 0.7537806\n",
      " 0.78497277 0.79046549        nan        nan 0.74032526        nan\n",
      " 0.79096939 0.77570172 0.77570172 0.74163554 0.7843177  0.79026394\n",
      "        nan        nan 0.71492531        nan 0.79026392 0.77041025\n",
      " 0.77030945 0.73589049 0.78436809 0.79021355        nan        nan\n",
      " 0.69466767        nan 0.79026394 0.76652987 0.76658026 0.72712222\n",
      " 0.78436809 0.79021355        nan        nan 0.68846964        nan\n",
      " 0.79021355 0.76476609 0.7652196  0.71926092 0.78436809 0.79021355]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "random_stat=10\n",
    "train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=random_stat\n",
    "                                                   )\n",
    "print(\"train_x.shpae:\")\n",
    "print(train_X.shape)\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(train_X)\n",
    "X_standard = standardScaler.transform(train_X)\n",
    "X_standard_test = standardScaler.transform(test_X)\n",
    "    #calculate max n_components\n",
    "estimator = PCA(n_components=0.99,random_state=random_stat)\n",
    "pca_X_train = estimator.fit_transform(X_standard)\n",
    "\n",
    "n_components=range(10,min(pca_X_train.shape),10)\n",
    "print(n_components)\n",
    "    #n_components=[0.99,0.95,0.90,0.85]\n",
    "best_pca_train_scores=[]\n",
    "best_pca_test_scores=[]\n",
    "for j in n_components:\n",
    "    estimator = PCA(n_components=j,random_state=random_stat)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_stat) \n",
    "    \n",
    "        #scoring = {'AUC': 'roc_auc'}\n",
    "    cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "    gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "    parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "\n",
    "    svc_grid_search=GridSearchCV(estimator=SVC(random_state=random_stat),\n",
    "                                 param_grid=parameters,cv=cvx,scoring=scoring)\n",
    "    svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "    param_grid = {'penalty':['l1', 'l2'],\n",
    "                  \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                  \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "    #               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                  }\n",
    "    LR_grid = LogisticRegression(max_iter=1000, random_state=random_stat)\n",
    "    LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring=scoring,n_jobs=10)\n",
    "    LR_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "    estimators = [\n",
    "        ('lr', LR_grid_search.best_estimator_),\n",
    "        ('svc', svc_grid_search.best_estimator_),\n",
    "    ]\n",
    "    clf = StackingClassifier(estimators=estimators, \n",
    "                             final_estimator=LinearSVC(C=5, random_state=random_stat),n_jobs=10)\n",
    "    clf.fit(pca_X_train, train_y)\n",
    "\n",
    "    estimators = [\n",
    "        ('lr', LR_grid_search.best_estimator_),\n",
    "        ('svc', svc_grid_search.best_estimator_),\n",
    "    ]\n",
    "\n",
    "    param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),\n",
    "                                    LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                    LogisticRegression(C=0.1),LogisticRegression(C=1),\n",
    "                                    LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                    LogisticRegression(C=1000)]}\n",
    "\n",
    "    Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "    Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx,\n",
    "                                        scoring=scoring,n_jobs=10)\n",
    "    Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "    Stacking_grid_search.best_estimator_\n",
    "\n",
    "    train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "\n",
    "    test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "        \n",
    "    best_pca_train_scores.append(train_res1.loc[:,\"AUC\"])\n",
    "    best_pca_test_scores.append(test_res1.loc[:,\"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5618cb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755472466338789\n",
      "0    0.77037\n",
      "Name: AUC, dtype: float64\n",
      "n_components:\n",
      "40\n",
      "[0    0.720632\n",
      "Name: AUC, dtype: float64, 0    0.543195\n",
      "Name: AUC, dtype: float64, 0    0.752378\n",
      "Name: AUC, dtype: float64, 0    0.755472\n",
      "Name: AUC, dtype: float64, 0    0.752308\n",
      "Name: AUC, dtype: float64, 0    0.750786\n",
      "Name: AUC, dtype: float64, 0    0.725379\n",
      "Name: AUC, dtype: float64, 0    0.733331\n",
      "Name: AUC, dtype: float64, 0    0.720652\n",
      "Name: AUC, dtype: float64, 0    0.71901\n",
      "Name: AUC, dtype: float64, 0    0.711179\n",
      "Name: AUC, dtype: float64, 0    0.711189\n",
      "Name: AUC, dtype: float64, 0    0.727032\n",
      "Name: AUC, dtype: float64, 0    0.738148\n",
      "Name: AUC, dtype: float64, 0    0.71907\n",
      "Name: AUC, dtype: float64, 0    0.71911\n",
      "Name: AUC, dtype: float64, 0    0.707984\n",
      "Name: AUC, dtype: float64, 0    0.717528\n",
      "Name: AUC, dtype: float64, 0    0.731758\n",
      "Name: AUC, dtype: float64, 0    0.720622\n",
      "Name: AUC, dtype: float64, 0    0.71906\n",
      "Name: AUC, dtype: float64, 0    0.730156\n",
      "Name: AUC, dtype: float64, 0    0.738067\n",
      "Name: AUC, dtype: float64, 0    0.722315\n",
      "Name: AUC, dtype: float64, 0    0.722184\n",
      "Name: AUC, dtype: float64, 0    0.741232\n",
      "Name: AUC, dtype: float64, 0    0.71901\n",
      "Name: AUC, dtype: float64, 0    0.734893\n",
      "Name: AUC, dtype: float64, 0    0.738088\n",
      "Name: AUC, dtype: float64, 0    0.726981\n",
      "Name: AUC, dtype: float64, 0    0.742865\n",
      "Name: AUC, dtype: float64, 0    0.733381\n",
      "Name: AUC, dtype: float64, 0    0.733381\n",
      "Name: AUC, dtype: float64, 0    0.736536\n",
      "Name: AUC, dtype: float64, 0    0.728574\n",
      "Name: AUC, dtype: float64, 0    0.715926\n",
      "Name: AUC, dtype: float64, 0    0.734983\n",
      "Name: AUC, dtype: float64, 0    0.723837\n",
      "Name: AUC, dtype: float64, 0    0.738118\n",
      "Name: AUC, dtype: float64, 0    0.730156\n",
      "Name: AUC, dtype: float64, 0    0.728594\n",
      "Name: AUC, dtype: float64, 0    0.738118\n",
      "Name: AUC, dtype: float64, 0    0.738108\n",
      "Name: AUC, dtype: float64, 0    0.733351\n",
      "Name: AUC, dtype: float64]\n",
      "[0    0.755556\n",
      "Name: AUC, dtype: float64, 0    0.525926\n",
      "Name: AUC, dtype: float64, 0    0.774074\n",
      "Name: AUC, dtype: float64, 0    0.77037\n",
      "Name: AUC, dtype: float64, 0    0.796296\n",
      "Name: AUC, dtype: float64, 0    0.774074\n",
      "Name: AUC, dtype: float64, 0    0.811111\n",
      "Name: AUC, dtype: float64, 0    0.777778\n",
      "Name: AUC, dtype: float64, 0    0.762963\n",
      "Name: AUC, dtype: float64, 0    0.766667\n",
      "Name: AUC, dtype: float64, 0    0.744444\n",
      "Name: AUC, dtype: float64, 0    0.718519\n",
      "Name: AUC, dtype: float64, 0    0.733333\n",
      "Name: AUC, dtype: float64, 0    0.744444\n",
      "Name: AUC, dtype: float64, 0    0.722222\n",
      "Name: AUC, dtype: float64, 0    0.72963\n",
      "Name: AUC, dtype: float64, 0    0.748148\n",
      "Name: AUC, dtype: float64, 0    0.748148\n",
      "Name: AUC, dtype: float64, 0    0.72963\n",
      "Name: AUC, dtype: float64, 0    0.733333\n",
      "Name: AUC, dtype: float64, 0    0.744444\n",
      "Name: AUC, dtype: float64, 0    0.748148\n",
      "Name: AUC, dtype: float64, 0    0.748148\n",
      "Name: AUC, dtype: float64, 0    0.733333\n",
      "Name: AUC, dtype: float64, 0    0.744444\n",
      "Name: AUC, dtype: float64, 0    0.744444\n",
      "Name: AUC, dtype: float64, 0    0.751852\n",
      "Name: AUC, dtype: float64, 0    0.751852\n",
      "Name: AUC, dtype: float64, 0    0.744444\n",
      "Name: AUC, dtype: float64, 0    0.774074\n",
      "Name: AUC, dtype: float64, 0    0.759259\n",
      "Name: AUC, dtype: float64, 0    0.762963\n",
      "Name: AUC, dtype: float64, 0    0.751852\n",
      "Name: AUC, dtype: float64, 0    0.751852\n",
      "Name: AUC, dtype: float64, 0    0.755556\n",
      "Name: AUC, dtype: float64, 0    0.755556\n",
      "Name: AUC, dtype: float64, 0    0.751852\n",
      "Name: AUC, dtype: float64, 0    0.755556\n",
      "Name: AUC, dtype: float64, 0    0.744444\n",
      "Name: AUC, dtype: float64, 0    0.744444\n",
      "Name: AUC, dtype: float64, 0    0.733333\n",
      "Name: AUC, dtype: float64, 0    0.737037\n",
      "Name: AUC, dtype: float64, 0    0.740741\n",
      "Name: AUC, dtype: float64, 0    0.725926\n",
      "Name: AUC, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "print(np.max(best_pca_train_scores))\n",
    "print(best_pca_test_scores[np.argmax(best_pca_train_scores)])\n",
    "print(\"n_components:\")\n",
    "print(n_components[np.argmax(best_pca_train_scores)])\n",
    "\n",
    "print(best_pca_train_scores)\n",
    "print(best_pca_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03346a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
