{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbef4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, cross_val_predict\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn import svm  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "# cores = mp.cpu_count()\n",
    "# pool = mp.Pool(processes=20)\n",
    "\n",
    "# min1=min(list(X_standard.shape))\n",
    "# a1=list(range(10,min1,10))\n",
    "# a1[-1]=min1\n",
    "# pcc_top1=pool.map(find_best_pca_lr,a1)  ##（SVM，LR）\n",
    "# pool.terminate()\n",
    "\n",
    "\n",
    "# a1=pd.DataFrame()\n",
    "# for i1 in pcc_top1:\n",
    "#     a1=pd.concat([a1,i1], axis=0)\n",
    "# a1.columns=['tr_TP', 'tr_TN', 'tr_FP', 'tr_FN', 'tr_Sen', 'tr_Spe', 'tr_Acc', 'tr_PPV', 'tr_NPV', 'tr_MCC', 'tr_AUC','TP',\n",
    "#        'TN', 'FP', 'FN', 'Sen', 'Spe', 'Acc', 'PPV', 'NPV', 'MCC', 'AUC','PCA']   \n",
    "\n",
    "# a1=a1.sort_values(['Acc','tr_Acc','PCA'], ascending=[False,False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a00ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_csv(input_path,i):\n",
    "\n",
    "    df_chunk=pd.read_csv(input_path,\n",
    "                         chunksize=10000,\n",
    "#                          sep='\\t'\n",
    "                        sep=i\n",
    "                        )\n",
    "    res_chunk=[]\n",
    "    for chunk in df_chunk:\n",
    "        res_chunk.append(chunk)\n",
    "    res_df=pd.concat(res_chunk)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d3ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measures_gridloo(label, score):\n",
    "    label = np.array(label)\n",
    "    score = np.array(score)\n",
    "    \n",
    "    N  = len(label)\n",
    "    TP = sum((label == 1) & (score == 1))\n",
    "    TN = sum((label == 0) & (score == 0))\n",
    "    FP = sum((label == 0) & (score == 1))\n",
    "    FN = sum((label == 1) & (score == 0))\n",
    "\n",
    "    # init all measures to nan\n",
    "    measures = {measure: float(\"nan\") for measure in (\"Sen\", \"Spe\", \"Acc\", \"PPV\", \"NPV\", \"MCC\",\"AUC\")}\n",
    "    \n",
    "    measures[\"TP\"] = TP\n",
    "    measures[\"TN\"] = TN\n",
    "    measures[\"FP\"] = FP\n",
    "    measures[\"FN\"] = FN\n",
    "    \n",
    "    S = (TP + FN) / N\n",
    "    P = (TP + FP) / N\n",
    "\n",
    "    if (TP + FN) > 0:\n",
    "        measures[\"Sen\"] = round(TP/(TP+FN), 4)\n",
    "\n",
    "    if (TN + FP) > 0:\n",
    "        measures[\"Spe\"] = round(TN/(TN+FP), 4)\n",
    "\n",
    "    if (TP + FP + FN + TN) > 0:\n",
    "        measures[\"Acc\"] = round((TP+TN)/(TP+FP+FN+TN), 4)\n",
    "\n",
    "    if (TP + FP) > 0:\n",
    "        measures[\"PPV\"] = round(TP/(TP+FP), 4)\n",
    "\n",
    "    if (TN + FN) > 0:\n",
    "        measures[\"NPV\"] = round(TN/(TN+FN), 4)\n",
    "\n",
    "    if (S*P*(1-S)*(1-P)) > 0:\n",
    "        measures[\"MCC\"] = round((TP/N - S*P)/(math.sqrt(S*P*(1-S)*(1-P))), 4)\n",
    "    \n",
    "    \n",
    "    measures[\"AUC\"]= roc_auc_score(label, score)\n",
    "    return pd.DataFrame([measures],\n",
    "                        columns=[\"TP\", \"TN\", \"FP\",\n",
    "                                 \"FN\", \"Sen\", \"Spe\", \"Acc\", \"PPV\", \"NPV\", \"MCC\",\"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d53b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVM\n",
    "def find_best_pca(i):\n",
    "    n_components=i\n",
    "    estimator = PCA(n_components=n_components,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    \n",
    "    scoring = {'AUC': 'roc_auc'}\n",
    "    cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "    gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "    parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "    \n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "    grid_search=GridSearchCV(estimator=SVC(random_state=10),param_grid=parameters,cv=cvx,scoring='accuracy')\n",
    "    grid_search.fit(pca_X_train, train_y)\n",
    "    \n",
    "    train_pre_y = cross_val_predict(grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "    test_pre_y = grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "    test_res1['PCA']=n_components\n",
    "    \n",
    "    res=pd.concat([train_res1,test_res1], axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4e5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_pca_lr(i):\n",
    "    n_components=i\n",
    "    estimator = PCA(n_components=n_components,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    \n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "\n",
    "    param_grid = {'penalty':['l2'],\n",
    "              \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],  \n",
    "              \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\"],\n",
    "#             \"C\":list(np.arange(0,0.1,0.005)),   \n",
    "#               \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\"]\n",
    "            }\n",
    "    LR_grid = LogisticRegression()\n",
    "    grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=9)\n",
    "    grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "\n",
    "    train_pre_y = cross_val_predict(grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "   \n",
    "\n",
    "    test_pre_y = grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "    test_res1['PCA']=n_components\n",
    "    \n",
    "    res=pd.concat([train_res1,test_res1], axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5f27eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer='BRCA'\n",
    "path='D:\\\\lymph_meta_xmiseq\\\\tcga_data\\\\'\n",
    "# e1=\"./\"+cancer+\"_delta_pcc_wilcox.csv\"\n",
    "# delta_pcc=read_single_csv(e1,',')\n",
    "# delta_pcc=delta_pcc.drop(['Unnamed: 0','pair'],axis=1)\n",
    "# delta_pcc=delta_pcc.dropna(axis=0,how='any')\n",
    "\n",
    "# result=delta_pcc.T\n",
    "# train=result.iloc[:,0:-1].values.astype('float')\n",
    "# target=result.iloc[:,-1].values.astype('float')\n",
    "\n",
    "train=pd.read_csv(path+cancer+\"\\\\admat_final.csv\").iloc[:,2:].T.values\n",
    "target=pd.read_csv(path+cancer+\"\\\\gctm_label.csv\",index_col=0).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "986f9b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00874834, -0.00736022, -0.01710605, ...,  0.0059139 ,\n",
       "         0.00585509,  0.01760065],\n",
       "       [-0.06756009, -0.03635654, -0.06104614, ...,  0.00184041,\n",
       "         0.01073223, -0.00660949],\n",
       "       [ 0.05017487, -0.03385318, -0.05728117, ..., -0.01067972,\n",
       "         0.01398897,  0.01295414],\n",
       "       ...,\n",
       "       [-0.00012984,  0.00158047,  0.00504004, ...,  0.00526114,\n",
       "        -0.00421565, -0.0168382 ],\n",
       "       [-0.0120549 ,  0.0223974 , -0.02588812, ..., -0.03524445,\n",
       "         0.00812885,  0.01039054],\n",
       "       [ 0.00757404,  0.00548185,  0.02304116, ...,  0.00104388,\n",
       "         0.00138618, -0.0349668 ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a0046d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4d47e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=10\n",
    "                                                   )\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(train_X)\n",
    "X_standard = standardScaler.transform(train_X)\n",
    "X_standard_test = standardScaler.transform(test_X)\n",
    "\n",
    "n_components=0.95\n",
    "estimator = PCA(n_components=n_components,random_state=10)\n",
    "pca_X_train = estimator.fit_transform(X_standard)\n",
    "pca_X_test = estimator.transform(X_standard_test)\n",
    "cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4d3eaf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 2281)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "385399ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.45230769        nan 0.52369231 0.54769231\n",
      " 0.54769231 0.72153846 0.76123077 0.74523077        nan        nan\n",
      " 0.45230769        nan 0.50030769 0.75292308 0.75292308 0.75292308\n",
      " 0.79230769 0.75292308        nan        nan 0.45230769        nan\n",
      " 0.52369231 0.848      0.848      0.82430769 0.864      0.832\n",
      "        nan        nan 0.68246154        nan 0.75292308 0.888\n",
      " 0.888      0.87230769 0.88       0.88              nan        nan\n",
      " 0.92              nan 0.92       0.88061538 0.88061538 0.85661538\n",
      " 0.86461538 0.86461538        nan        nan 0.944             nan\n",
      " 0.936      0.84061538 0.84061538 0.86461538 0.86461538 0.87261538\n",
      "        nan        nan 0.944             nan 0.87261538 0.84861538\n",
      " 0.84861538 0.86461538 0.86461538 0.87261538        nan        nan\n",
      " 0.90430769        nan 0.87261538 0.85661538 0.85661538 0.84861538\n",
      " 0.86461538 0.87261538        nan        nan 0.80892308        nan\n",
      " 0.87261538 0.84861538 0.84861538 0.84061538 0.86461538 0.87261538]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=10, shuffle=True),\n",
       "             estimator=LogisticRegression(max_iter=1000), n_jobs=10,\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                               1000],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm\n",
    "scoring = {'AUC': 'roc_auc'}\n",
    "cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "\n",
    "svc_grid_search=GridSearchCV(estimator=SVC(random_state=10),param_grid=parameters,cv=cvx,scoring='accuracy')\n",
    "svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "#LR\n",
    "param_grid = {'penalty':['l1', 'l2'],\n",
    "              \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "#               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "            }\n",
    "LR_grid = LogisticRegression(max_iter=1000)\n",
    "LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=10)\n",
    "LR_grid_search.fit(pca_X_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c0fc0d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                LogisticRegression(C=1, max_iter=1000,\n",
       "                                                   penalty='l1',\n",
       "                                                   solver='liblinear')),\n",
       "                               ('svc',\n",
       "                                SVC(C=32, gamma=3.0517578125e-05,\n",
       "                                    random_state=10))],\n",
       "                   final_estimator=LinearSVC(C=5), n_jobs=10)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('lr', LR_grid_search.best_estimator_),\n",
    "    ('svc', svc_grid_search.best_estimator_),\n",
    "]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LinearSVC(C=5),n_jobs=10)\n",
    "clf.fit(pca_X_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "aa318404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                LogisticRegression(C=1, max_iter=1000,\n",
       "                                                   penalty='l1',\n",
       "                                                   solver='liblinear')),\n",
       "                               ('svc',\n",
       "                                SVC(C=32, gamma=3.0517578125e-05,\n",
       "                                    random_state=10))],\n",
       "                   final_estimator=LogisticRegression(C=100))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('lr', LR_grid_search.best_estimator_),\n",
    "    ('svc', svc_grid_search.best_estimator_),\n",
    "]\n",
    "\n",
    "param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                 LogisticRegression(C=0.1),LogisticRegression(C=1),LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                 LogisticRegression(C=1000)]}\n",
    "\n",
    "Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=10)\n",
    "Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "Stacking_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a1961530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "\n",
    "test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "test_res1=get_measures_gridloo(test_y,test_pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dfa32e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TP  TN  FP  FN     Sen     Spe     Acc     PPV     NPV     MCC       AUC\n",
      "0  64  50   7   5  0.9275  0.8772  0.9048  0.9014  0.9091  0.8076  0.902365\n",
      "   TP  TN  FP  FN  Sen  Spe  Acc  PPV  NPV  MCC  AUC\n",
      "0  30  24   0   0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_res1)\n",
    "print(test_res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ac3da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shpae:\n",
      "(195, 13022)\n",
      "range(10, 132, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.79777778\n",
      " 0.79777778 0.79778056 0.79778056 0.79778056        nan        nan\n",
      " 0.5               nan 0.5        0.80732387 0.80732387 0.80944027\n",
      " 0.80944027 0.80944027        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.80894737 0.80894737 0.81001392 0.80948482 0.80948482\n",
      "        nan        nan 0.80202172        nan 0.80202172 0.81582568\n",
      " 0.81582568 0.81529936 0.81529936 0.81477304        nan        nan\n",
      " 0.81265664        nan 0.81370927 0.8121359  0.8121359  0.81319131\n",
      " 0.8121359  0.812665          nan        nan 0.81477304        nan\n",
      " 0.81318853 0.8131941  0.8131941  0.8131941  0.812665   0.812665\n",
      "        nan        nan 0.8131941         nan 0.812665   0.8137232\n",
      " 0.8137232  0.8137232  0.8131941  0.812665          nan        nan\n",
      " 0.8131941         nan 0.812665   0.8137232  0.8137232  0.8137232\n",
      " 0.8131941  0.812665          nan        nan 0.8131941         nan\n",
      " 0.812665   0.8137232  0.8137232  0.8137232  0.8131941  0.812665  ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.80939293\n",
      " 0.80939293 0.80939293 0.80939293 0.80939293        nan        nan\n",
      " 0.5               nan 0.5        0.832665   0.832665   0.83161793\n",
      " 0.83161793 0.83161793        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.83691172 0.83691172 0.83637984 0.83637984 0.83637984\n",
      "        nan        nan 0.81314119        nan 0.81314119 0.85644946\n",
      " 0.85644946 0.85644946 0.85750487 0.85644946        nan        nan\n",
      " 0.84642439        nan 0.84695071 0.87281259 0.87281259 0.86912838\n",
      " 0.86595934 0.86226399        nan        nan 0.87335004        nan\n",
      " 0.86120579 0.87756057 0.87756057 0.8802005  0.86965748 0.86331941\n",
      "        nan        nan 0.87755778        nan 0.86331941 0.87755778\n",
      " 0.87755778 0.8780841  0.87018658 0.86331941        nan        nan\n",
      " 0.87755778        nan 0.86331941 0.87755778 0.87755778 0.87755778\n",
      " 0.87018658 0.86331941        nan        nan 0.87755778        nan\n",
      " 0.86331941 0.87755778 0.87755778 0.87755778 0.87018658 0.86331941]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81468672\n",
      " 0.81468672 0.8141604  0.8141604  0.8141604         nan        nan\n",
      " 0.5               nan 0.5        0.84112782 0.84112782 0.84218881\n",
      " 0.84218881 0.84218881        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.86174882 0.86174882 0.85964355 0.85964355 0.85964355\n",
      "        nan        nan 0.81208299        nan 0.81208299 0.88811473\n",
      " 0.88811473 0.88599276 0.88704818 0.88493734        nan        nan\n",
      " 0.8654386         nan 0.86385408 0.89019215 0.89019215 0.88864383\n",
      " 0.89180451 0.88599833        nan        nan 0.88915065        nan\n",
      " 0.88758563 0.88753551 0.88753551 0.89232804 0.89022556 0.88546923\n",
      "        nan        nan 0.88595656        nan 0.88494291 0.88542746\n",
      " 0.88489836 0.89176831 0.88917293 0.88494291        nan        nan\n",
      " 0.88436926        nan 0.88546923 0.88436926 0.88436926 0.88595377\n",
      " 0.8886494  0.88546923        nan        nan 0.88436926        nan\n",
      " 0.88494291 0.88436926 0.88436926 0.88436926 0.88864662 0.88546923]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81996658\n",
      " 0.81996658 0.81997215 0.81997215 0.81997215        nan        nan\n",
      " 0.5               nan 0.5        0.85328599 0.85328599 0.85381509\n",
      " 0.85381509 0.85381509        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88443331 0.88443331 0.88392091 0.88392091 0.88392091\n",
      "        nan        nan 0.81950153        nan 0.81897243 0.90602896\n",
      " 0.90602896 0.91183793 0.91236703 0.91236703        nan        nan\n",
      " 0.89128098        nan 0.89021442 0.89387914 0.89387914 0.90918129\n",
      " 0.90918964 0.91025063        nan        nan 0.90757728        nan\n",
      " 0.90919243 0.89598719 0.89598719 0.90811752 0.9112949  0.90866889\n",
      "        nan        nan 0.90810916        nan 0.91024784 0.89494013\n",
      " 0.89494013 0.90705931 0.91129212 0.90866889        nan        nan\n",
      " 0.90863548        nan 0.90866889 0.89546644 0.89546644 0.90811473\n",
      " 0.91129212 0.90866889        nan        nan 0.90547201        nan\n",
      " 0.90866889 0.89441381 0.89441381 0.91022278 0.91023949 0.90866889]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.82049568\n",
      " 0.82049568 0.81944305 0.81944305 0.81944305        nan        nan\n",
      " 0.5               nan 0.5        0.85327764 0.85327764 0.85169312\n",
      " 0.85169312 0.85221944        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88708716 0.88708716 0.88657477 0.88657199 0.88657199\n",
      "        nan        nan 0.80573656        nan 0.80573656 0.89076859\n",
      " 0.89076859 0.8912949  0.89288221 0.89235589        nan        nan\n",
      " 0.88495127        nan 0.88336118 0.88338067 0.88338067 0.87863548\n",
      " 0.8823169  0.88600111        nan        nan 0.87018379        nan\n",
      " 0.88653578 0.88970482 0.88970482 0.87758563 0.88336953 0.88652743\n",
      "        nan        nan 0.86491785        nan 0.88652743 0.88917572\n",
      " 0.88917572 0.87652186 0.88284043 0.88758563        nan        nan\n",
      " 0.87229184        nan 0.88705653 0.88390699 0.88390699 0.87494013\n",
      " 0.88389585 0.88758563        nan        nan 0.88019493        nan\n",
      " 0.88705653 0.88180173 0.88127541 0.87441103 0.88336953 0.88652743]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81890281\n",
      " 0.81890281 0.8189056  0.8189056  0.8189056         nan        nan\n",
      " 0.5               nan 0.5        0.84904205 0.84904205 0.85168198\n",
      " 0.85168198 0.85221108        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.89235867 0.89235867 0.89500696 0.89500696 0.89500696\n",
      "        nan        nan 0.80838207        nan 0.80785297 0.90976608\n",
      " 0.90976608 0.91242551 0.91347536 0.91347536        nan        nan\n",
      " 0.90240602        nan 0.90292398 0.90449735 0.90449735 0.89289613\n",
      " 0.90081314 0.90767196        nan        nan 0.89920356        nan\n",
      " 0.90872737 0.89500696 0.89500696 0.8807296  0.90344472 0.90767474\n",
      "        nan        nan 0.89443052        nan 0.90767474 0.89394598\n",
      " 0.89394598 0.8807296  0.90239209 0.90767474        nan        nan\n",
      " 0.88492063        nan 0.90767474 0.891824   0.891824   0.88019215\n",
      " 0.90238931 0.90767474        nan        nan 0.86219716        nan\n",
      " 0.90767474 0.8907658  0.88971317 0.87966583 0.90239209 0.90767474]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.8183765\n",
      " 0.8183765  0.8183765  0.8183765  0.8183765         nan        nan\n",
      " 0.5               nan 0.5        0.85062935 0.85062935 0.85116124\n",
      " 0.85116124 0.85168755        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88390977 0.88390977 0.88813422 0.88866332 0.88866332\n",
      "        nan        nan 0.80785297        nan 0.80679476 0.90397661\n",
      " 0.90397661 0.90399053 0.90557226 0.90451685        nan        nan\n",
      " 0.87653857        nan 0.88234754 0.89500139 0.89500139 0.88972988\n",
      " 0.89079087 0.89976608        nan        nan 0.87811473        nan\n",
      " 0.90188527 0.88971596 0.88971596 0.88340295 0.89184907 0.89924255\n",
      "        nan        nan 0.87496519        nan 0.89924534 0.88602896\n",
      " 0.88550265 0.87759955 0.89184907 0.89924255        nan        nan\n",
      " 0.87018379        nan 0.89871345 0.88549986 0.88602896 0.87654135\n",
      " 0.89290448 0.89765803        nan        nan 0.85009468        nan\n",
      " 0.89765803 0.88338903 0.88550265 0.87179337 0.89237817 0.89765803]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.82048454\n",
      " 0.82048454 0.81995823 0.81995823 0.81995823        nan        nan\n",
      " 0.5               nan 0.5        0.8511501  0.8511501  0.85590922\n",
      " 0.85538012 0.85538012        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.8955472  0.8955472  0.90029518 0.89976887 0.89976887\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.90927597\n",
      " 0.90927597 0.91246449 0.91246449 0.91141186        nan        nan\n",
      " 0.88976051        nan 0.89451406 0.89818435 0.89818435 0.89715957\n",
      " 0.90138123 0.90612921        nan        nan 0.89026455        nan\n",
      " 0.90770816 0.89292398 0.89292398 0.88818435 0.90243665 0.90665553\n",
      "        nan        nan 0.88184071        nan 0.90612643 0.88659705\n",
      " 0.88659705 0.88343637 0.90296575 0.90665553        nan        nan\n",
      " 0.86176831        nan 0.90665553 0.88396547 0.8850181  0.87869674\n",
      " 0.90296575 0.90665553        nan        nan 0.83483988        nan\n",
      " 0.90665553 0.88344194 0.88344194 0.87975494 0.90349485 0.90612643]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81784461\n",
      " 0.81784461 0.8178474  0.8178474  0.8178474         nan        nan\n",
      " 0.5               nan 0.5        0.8516792  0.8516792  0.85326371\n",
      " 0.85326371 0.85326371        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.89290727 0.89290727 0.8981927  0.8971345  0.8971345\n",
      "        nan        nan 0.80732387        nan 0.80679476 0.91352827\n",
      " 0.91352827 0.91564467 0.91564467 0.91617098        nan        nan\n",
      " 0.87658034        nan 0.88028126 0.90666388 0.90666388 0.90878307\n",
      " 0.91406572 0.91406015        nan        nan 0.88236981        nan\n",
      " 0.91299916 0.89928989 0.89928989 0.89875522 0.91406572 0.91353105\n",
      "        nan        nan 0.87289056        nan 0.91353105 0.89453356\n",
      " 0.89453356 0.89612086 0.91406572 0.91406015        nan        nan\n",
      " 0.86281537        nan 0.91353105 0.89137009 0.89084378 0.88769702\n",
      " 0.91353383 0.91406015        nan        nan 0.82426901        nan\n",
      " 0.91353105 0.88662211 0.89401281 0.88769424 0.91406294 0.91353105]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81731551\n",
      " 0.81731551 0.81784461 0.81784461 0.81784461        nan        nan\n",
      " 0.5               nan 0.5        0.85221108 0.85221108 0.85274018\n",
      " 0.85274018 0.85274018        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.89186578 0.89186578 0.89451128 0.89398218 0.89398218\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.91616541\n",
      " 0.91616541 0.91142022 0.9108939  0.91194653        nan        nan\n",
      " 0.88240323        nan 0.88556391 0.90667502 0.90667502 0.90455026\n",
      " 0.90350599 0.91036202        nan        nan 0.88819827        nan\n",
      " 0.9093066  0.90719577 0.90719577 0.90297132 0.90350599 0.9098357\n",
      "        nan        nan 0.87604288        nan 0.9087775  0.90666945\n",
      " 0.90666945 0.90457254 0.90350599 0.9098357         nan        nan\n",
      " 0.84537455        nan 0.9098357  0.90244222 0.90244222 0.89615706\n",
      " 0.9040323  0.9108939         nan        nan 0.82526873        nan\n",
      " 0.9103648  0.902445   0.90562796 0.89247006 0.90297689 0.91036202]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81783904\n",
      " 0.81783904 0.81784183 0.81784183 0.81784183        nan        nan\n",
      " 0.5               nan 0.5        0.8516792  0.8516792  0.85485102\n",
      " 0.85485102 0.8543247         nan        nan 0.78772765        nan\n",
      " 0.78772765 0.89608187 0.89608187 0.89873851 0.89873851 0.89873851\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.91351991\n",
      " 0.91351991 0.91247006 0.91246728 0.91299638        nan        nan\n",
      " 0.87817878        nan 0.88663047 0.90823726 0.90823726 0.90348649\n",
      " 0.90665274 0.90982735        nan        nan 0.86019493        nan\n",
      " 0.90455305 0.90612086 0.90612086 0.89978279 0.90665274 0.90982456\n",
      "        nan        nan 0.86178502        nan 0.90876915 0.90875522\n",
      " 0.90875522 0.89926483 0.90612364 0.90929546        nan        nan\n",
      " 0.85696463        nan 0.90929546 0.90770259 0.90770259 0.89344751\n",
      " 0.90612364 0.90982456        nan        nan 0.80358674        nan\n",
      " 0.90982456 0.90454191 0.90294625 0.89450014 0.90717906 0.90876636]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81837093\n",
      " 0.81837093 0.8173183  0.8173183  0.8173183         nan        nan\n",
      " 0.5               nan 0.5        0.85168755 0.85168755 0.85380117\n",
      " 0.85380117 0.85380117        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88816486 0.88816486 0.88974659 0.88974659 0.88922027\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.89449457\n",
      " 0.89502367 0.89713729 0.89713729 0.8971345         nan        nan\n",
      " 0.86601504        nan 0.86865776 0.88761348 0.88761348 0.88867446\n",
      " 0.89079087 0.89132554        nan        nan 0.85228627        nan\n",
      " 0.89186299 0.8828655  0.8828655  0.88392927 0.89079087 0.89185185\n",
      "        nan        nan 0.84858535        nan 0.89185185 0.88549986\n",
      " 0.88549986 0.87126706 0.89237538 0.89132554        nan        nan\n",
      " 0.81783904        nan 0.89132554 0.88338903 0.88444723 0.86493177\n",
      " 0.89184907 0.89185185        nan        nan 0.77718184        nan\n",
      " 0.89079644 0.88076023 0.88234754 0.86123642 0.89131997 0.89026734]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81836814\n",
      " 0.81836814 0.81784461 0.81784461 0.81784461        nan        nan\n",
      " 0.5               nan 0.5        0.8522083  0.8522083  0.85432749\n",
      " 0.85432749 0.85379838        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88499025 0.88499025 0.88711779 0.88711779 0.88711779\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.89238931\n",
      " 0.89238931 0.89239488 0.89239488 0.89239209        nan        nan\n",
      " 0.8591061         nan 0.87549986 0.88552214 0.88552214 0.8897633\n",
      " 0.89028683 0.89345586        nan        nan 0.86018658        nan\n",
      " 0.89028683 0.88235032 0.88235032 0.88553885 0.89028126 0.89292398\n",
      "        nan        nan 0.85120301        nan 0.89397939 0.87971039\n",
      " 0.87971039 0.87602896 0.88975494 0.89292676        nan        nan\n",
      " 0.83211083        nan 0.89292398 0.87812865 0.87760234 0.86018936\n",
      " 0.89028126 0.89239766        nan        nan 0.73969925        nan\n",
      " 0.89292398 0.87549708 0.87655528 0.85753829 0.88975216 0.89345308]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components:\n",
      "110\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################random seed loop#################\n",
    "train_scores=[]\n",
    "test_scores=[]\n",
    "loopn=1\n",
    "scoring='roc_auc'\n",
    "#np.random.seed(42)\n",
    "random_states=np.random.choice(range(101), loopn, replace=False)\n",
    "\n",
    "tmp_train=[]\n",
    "tmp_test=[]\n",
    "#print(random_states)\n",
    "for i in range(loopn):\n",
    "    train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=10\n",
    "                                                   )\n",
    "    print(\"train_x.shpae:\")\n",
    "    print(train_X.shape)\n",
    "\n",
    "    standardScaler = StandardScaler()\n",
    "    standardScaler.fit(train_X)\n",
    "    X_standard = standardScaler.transform(train_X)\n",
    "    X_standard_test = standardScaler.transform(test_X)\n",
    "    #calculate max n_components\n",
    "    estimator = PCA(n_components=0.95,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "\n",
    "    n_components=range(10,min(pca_X_train.shape),10)\n",
    "    print(n_components)\n",
    "    #n_components=[0.99,0.95,0.90,0.85]\n",
    "    best_pca_train_scores=[]\n",
    "    best_pca_test_scores=[]\n",
    "    for j in n_components:\n",
    "        estimator = PCA(n_components=j,random_state=10)\n",
    "        pca_X_train = estimator.fit_transform(X_standard)\n",
    "        pca_X_test = estimator.transform(X_standard_test)\n",
    "        cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "    \n",
    "        #scoring = {'AUC': 'roc_auc'}\n",
    "        cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "        gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "        parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "\n",
    "        svc_grid_search=GridSearchCV(estimator=SVC(random_state=10),\n",
    "                                     param_grid=parameters,cv=cvx,scoring=scoring)\n",
    "        svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "        param_grid = {'penalty':['l1', 'l2'],\n",
    "                      \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                      \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "    #               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                    }\n",
    "        LR_grid = LogisticRegression(max_iter=1000)\n",
    "        LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring=scoring,n_jobs=10)\n",
    "        LR_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "        estimators = [\n",
    "            ('lr', LR_grid_search.best_estimator_),\n",
    "            ('svc', svc_grid_search.best_estimator_),\n",
    "        ]\n",
    "        clf = StackingClassifier(estimators=estimators, final_estimator=LinearSVC(C=5),n_jobs=10)\n",
    "        clf.fit(pca_X_train, train_y)\n",
    "\n",
    "        estimators = [\n",
    "            ('lr', LR_grid_search.best_estimator_),\n",
    "            ('svc', svc_grid_search.best_estimator_),\n",
    "        ]\n",
    "\n",
    "        param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),\n",
    "                                         LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                         LogisticRegression(C=0.1),LogisticRegression(C=1),\n",
    "                                         LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                         LogisticRegression(C=1000)]}\n",
    "\n",
    "        Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "        Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx,\n",
    "                                            scoring=scoring,n_jobs=10)\n",
    "        Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "        Stacking_grid_search.best_estimator_\n",
    "\n",
    "        train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "        train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "\n",
    "        test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "        test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "        \n",
    "        best_pca_train_scores.append(train_res1.loc[:,\"AUC\"])\n",
    "        best_pca_test_scores.append(test_res1.loc[:,\"AUC\"])\n",
    "    \n",
    "    train_scores.append(np.max(best_pca_train_scores))\n",
    "    test_scores.append(best_pca_test_scores[np.argmax(best_pca_train_scores)])\n",
    "    print(\"n_components:\")\n",
    "    print(n_components[np.argmax(best_pca_train_scores)])\n",
    "    \n",
    "    tmp_train.append(best_pca_train_scores)\n",
    "    tmp_test.append(best_pca_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89e38686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "0.8376952300548755\n",
      "0.7829059829059828\n",
      "std\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0    0.754221\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.809941\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.805087\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.827406\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.797119\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.811102\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.795958\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.805667\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.826826\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.833421\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.837695\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.817697\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.822552\n",
       "Name: AUC, dtype: float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0   \\\n",
       "0  0    0.754221\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        1   \\\n",
       "0  0    0.809941\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        2   \\\n",
       "0  0    0.805087\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        3   \\\n",
       "0  0    0.827406\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        4   \\\n",
       "0  0    0.797119\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        5   \\\n",
       "0  0    0.811102\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        6   \\\n",
       "0  0    0.795958\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        7   \\\n",
       "0  0    0.805667\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        8   \\\n",
       "0  0    0.826826\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        9   \\\n",
       "0  0    0.833421\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        10  \\\n",
       "0  0    0.837695\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        11  \\\n",
       "0  0    0.817697\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        12  \n",
       "0  0    0.822552\n",
       "Name: AUC, dtype: float64  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('mean')\n",
    "print(np.mean(train_scores))\n",
    "print(np.mean(test_scores))\n",
    "print(\"std\")\n",
    "print(np.std(train_scores))\n",
    "print(np.std(test_scores))\n",
    "pd.DataFrame(tmp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "03767256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9295183982683983]\n",
      "[0    0.940972\n",
      "Name: AUC, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "print(train_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360d174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b07a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shpae:\n",
      "(643, 4660)\n",
      "range(10, 225, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.7143901\n",
      " 0.7143901  0.71497091 0.71497091 0.71497091        nan        nan\n",
      " 0.5               nan 0.5        0.71448764 0.71448764 0.71269409\n",
      " 0.71288869 0.71283911        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.7410049  0.7410049  0.71928803 0.72452302 0.72069172\n",
      "        nan        nan 0.72603681        nan 0.72980901 0.77485496\n",
      " 0.77485496 0.73512124 0.72827393 0.72121291        nan        nan\n",
      " 0.76355163        nan 0.72094655 0.78226702 0.78226702 0.76229474\n",
      " 0.7282634  0.72160058        nan        nan 0.78163126        nan\n",
      " 0.72194098 0.78337635 0.78337635 0.78181982 0.72840992 0.7217952\n",
      "        nan        nan 0.78313284        nan 0.72184103 0.78327786\n",
      " 0.78322902 0.78332596 0.72879609 0.72169752        nan        nan\n",
      " 0.78318092        nan 0.72174562 0.78327709 0.78327709 0.78322899\n",
      " 0.72850538 0.72169752        nan        nan 0.78332593        nan\n",
      " 0.7217952  0.78327709 0.78327709 0.78327709 0.72855344 0.72155174]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72404662\n",
      " 0.72404662 0.72438469 0.72433585 0.72438393        nan        nan\n",
      " 0.5               nan 0.5        0.72693857 0.72693857 0.72466103\n",
      " 0.72480607 0.7248061         nan        nan 0.75544363        nan\n",
      " 0.75544363 0.75539916 0.75539916 0.73552226 0.73877114 0.735671\n",
      "        nan        nan 0.73097657        nan 0.73520133 0.79135531\n",
      " 0.79135531 0.7484571  0.7411072  0.74152299        nan        nan\n",
      " 0.78985385        nan 0.73712887 0.79798246 0.79798246 0.78495366\n",
      " 0.74066304 0.73967907        nan        nan 0.79767193        nan\n",
      " 0.73997505 0.79815788 0.79815788 0.79650518 0.74052027 0.73938749\n",
      "        nan        nan 0.79771754        nan 0.73938823 0.79776786\n",
      " 0.79776786 0.79776793 0.7405195  0.73914477        nan        nan\n",
      " 0.79781596        nan 0.73928981 0.79771976 0.79767168 0.79776712\n",
      " 0.74037002 0.73919361        nan        nan 0.79771976        nan\n",
      " 0.73914477 0.79771976 0.79771976 0.79771976 0.74027826 0.73914477]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72331987\n",
      " 0.72331987 0.72336945 0.72341755 0.72336943        nan        nan\n",
      " 0.5               nan 0.5        0.72544599 0.72544599 0.72283712\n",
      " 0.72283564 0.7227868         nan        nan 0.75544363        nan\n",
      " 0.75544363 0.74926883 0.74926883 0.73458148 0.73671807 0.73458731\n",
      "        nan        nan 0.73204358        nan 0.73674485 0.77676985\n",
      " 0.77686753 0.74080672 0.73966811 0.73537726        nan        nan\n",
      " 0.77672052        nan 0.73210544 0.78521532 0.78521532 0.76502745\n",
      " 0.7354157  0.73542014        nan        nan 0.78481179        nan\n",
      " 0.73523141 0.785009   0.7849609  0.78224271 0.73502713 0.73551782\n",
      "        nan        nan 0.78539299        nan 0.73542159 0.78476924\n",
      " 0.78476924 0.7842846  0.73478517 0.73542083        nan        nan\n",
      " 0.7848166         nan 0.73561249 0.7846723  0.7846723  0.78452504\n",
      " 0.73468675 0.73561395        nan        nan 0.78467156        nan\n",
      " 0.73546745 0.7846723  0.7846723  0.78462346 0.73497752 0.73561321]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72794032\n",
      " 0.72794032 0.72828135 0.72828209 0.7283775         nan        nan\n",
      " 0.5               nan 0.5        0.73331264 0.7332638  0.73151527\n",
      " 0.73141914 0.73122378        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.76566651 0.76566651 0.74847951 0.75181719 0.74930551\n",
      "        nan        nan 0.73247565        nan 0.7372761  0.80265776\n",
      " 0.80265778 0.75127794 0.74978031 0.74981708        nan        nan\n",
      " 0.79604629        nan 0.74334432 0.82788915 0.82774487 0.7853092\n",
      " 0.74466094 0.74918436        nan        nan 0.82797649        nan\n",
      " 0.74899055 0.83063291 0.83072985 0.82097231 0.74436711 0.74918283\n",
      "        nan        nan 0.83053437        nan 0.74903855 0.83072742\n",
      " 0.8307755  0.82975675 0.74417173 0.74908742        nan        nan\n",
      " 0.83087246        nan 0.7488943  0.83077554 0.83082438 0.83072666\n",
      " 0.74426872 0.74894164        nan        nan 0.83082362        nan\n",
      " 0.74903932 0.83077554 0.83077554 0.83077554 0.7439779  0.74894238]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73285483\n",
      " 0.73285483 0.73333417 0.73333343 0.73333343        nan        nan\n",
      " 0.5               nan 0.5        0.73997216 0.740021   0.73827191\n",
      " 0.73807961 0.73812771        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77333916 0.77333916 0.7544971  0.75730508 0.75503739\n",
      "        nan        nan 0.73232989        nan 0.73708373 0.80877766\n",
      " 0.80867998 0.75879243 0.75447411 0.75287164        nan        nan\n",
      " 0.79927232        nan 0.748104   0.82659674 0.82659674 0.78595839\n",
      " 0.75219026 0.75134787        nan        nan 0.82794298        nan\n",
      " 0.75159204 0.82769962 0.82760344 0.81727132 0.75184831 0.7514914\n",
      "        nan        nan 0.82726597        nan 0.75144178 0.82692625\n",
      " 0.82692625 0.82590602 0.75165443 0.75129678        nan        nan\n",
      " 0.82692625        nan 0.7514418  0.82692703 0.82702395 0.82697513\n",
      " 0.75175285 0.75124646        nan        nan 0.82692701        nan\n",
      " 0.75129604 0.82707205 0.82707205 0.82697511 0.7518491  0.75124794]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73711004\n",
      " 0.73711004 0.73735121 0.73735121 0.73735121        nan        nan\n",
      " 0.5               nan 0.5        0.74445228 0.74445228 0.74324402\n",
      " 0.7432921  0.74309822        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77869383 0.77869383 0.76213691 0.76605762 0.76229858\n",
      "        nan        nan 0.73237873        nan 0.7371799  0.81001503\n",
      " 0.81001503 0.76436057 0.76222784 0.76116996        nan        nan\n",
      " 0.80290457        nan 0.75459094 0.82067363 0.82062553 0.78617131\n",
      " 0.76003256 0.76037946        nan        nan 0.8241373         nan\n",
      " 0.76038115 0.82337015 0.82337015 0.8160351  0.75973947 0.76037876\n",
      "        nan        nan 0.82307993        nan 0.76028185 0.82317599\n",
      " 0.82312715 0.82215817 0.75973947 0.76032992        nan        nan\n",
      " 0.82303097        nan 0.76032918 0.82307905 0.82307905 0.82288596\n",
      " 0.75978831 0.76037728        nan        nan 0.82308055        nan\n",
      " 0.7603795  0.82307905 0.82307981 0.82303171 0.75968913 0.76037802]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73744721\n",
      " 0.73744721 0.73763951 0.73763951 0.73763951        nan        nan\n",
      " 0.5               nan 0.5        0.7433069  0.74325806 0.74151261\n",
      " 0.74156293 0.74146606        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77454046 0.77454046 0.75697895 0.75959677 0.75761014\n",
      "        nan        nan 0.73242755        nan 0.73732497 0.79365361\n",
      " 0.79370245 0.74703995 0.74829754 0.75203096        nan        nan\n",
      " 0.78937715        nan 0.74698316 0.80836777 0.80836777 0.7623341\n",
      " 0.74498145 0.74987725        nan        nan 0.81378871        nan\n",
      " 0.74993    0.81038702 0.81043512 0.79692278 0.74464253 0.74958343\n",
      "        nan        nan 0.81042987        nan 0.74968263 0.81013757\n",
      " 0.81018565 0.80859132 0.74493254 0.74953609        nan        nan\n",
      " 0.81032918        nan 0.74968034 0.81013681 0.81018491 0.81004065\n",
      " 0.74488525 0.74948723        nan        nan 0.81013681        nan\n",
      " 0.74958343 0.81013681 0.81013681 0.81008797 0.74507832 0.74968185]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73633871\n",
      " 0.73633871 0.73653178 0.73648294 0.73653104        nan        nan\n",
      " 0.5               nan 0.5        0.74269416 0.74269416 0.74138156\n",
      " 0.74118694 0.74118842        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.76983163 0.76983163 0.75093999 0.75438573 0.75225268\n",
      "        nan        nan 0.73233133        nan 0.73703486 0.79197839\n",
      " 0.79197839 0.74041255 0.74089036 0.74450725        nan        nan\n",
      " 0.78788249        nan 0.74149915 0.8082046  0.8082046  0.75645829\n",
      " 0.73869427 0.74251288        nan        nan 0.80950031        nan\n",
      " 0.74202374 0.80649448 0.80649448 0.79157322 0.73840343 0.74231969\n",
      "        nan        nan 0.80668741        nan 0.74222204 0.80649348\n",
      " 0.80649348 0.80464598 0.73854847 0.74227088        nan        nan\n",
      " 0.80644309        nan 0.74236629 0.80639647 0.80639573 0.80629734\n",
      " 0.73854844 0.7421251         nan        nan 0.80634837        nan\n",
      " 0.74241518 0.80639795 0.80634911 0.80629953 0.73850037 0.74231898]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73455917\n",
      " 0.73455917 0.73484987 0.73489795 0.73494605        nan        nan\n",
      " 0.5               nan 0.5        0.74051735 0.74051735 0.73814748\n",
      " 0.73819627 0.73814597        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.76511028 0.76511028 0.74661628 0.74918681 0.74671995\n",
      "        nan        nan 0.73223367        nan 0.73708373 0.78852751\n",
      " 0.78852751 0.73414641 0.73123044 0.73643315        nan        nan\n",
      " 0.79255455        nan 0.74362154 0.80724257 0.80724257 0.75228293\n",
      " 0.72774575 0.73449056        nan        nan 0.80923082        nan\n",
      " 0.73487309 0.80568434 0.80563624 0.78920552 0.72750525 0.73395778\n",
      "        nan        nan 0.80313601        nan 0.73410208 0.80173528\n",
      " 0.80168644 0.80234252 0.72731137 0.73405472        nan        nan\n",
      " 0.80120259        nan 0.73419828 0.80110642 0.80110642 0.80115371\n",
      " 0.7274534  0.73400514        nan        nan 0.80110642        nan\n",
      " 0.73400588 0.8012041  0.8012041  0.80115526 0.72740755 0.73400514]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73718016\n",
      " 0.73718016 0.73727779 0.73722895 0.73718085        nan        nan\n",
      " 0.5               nan 0.5        0.74415732 0.74415732 0.74221723\n",
      " 0.74226537 0.74207226        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77151083 0.77151083 0.75319523 0.75615565 0.75397674\n",
      "        nan        nan 0.73233137        nan 0.73703563 0.78276739\n",
      " 0.78276739 0.73917661 0.74043605 0.74438756        nan        nan\n",
      " 0.78151786        nan 0.74428749 0.79365694 0.79365694 0.74432202\n",
      " 0.73635325 0.74360651        nan        nan 0.79741317        nan\n",
      " 0.74268472 0.78800054 0.78800054 0.770008   0.73635101 0.74350656\n",
      "        nan        nan 0.78714274        nan 0.74341113 0.78646705\n",
      " 0.78646705 0.78504734 0.73630441 0.7435576         nan        nan\n",
      " 0.78637161        nan 0.74355614 0.78641969 0.78637159 0.78583592\n",
      " 0.73625483 0.7435073         nan        nan 0.78627465        nan\n",
      " 0.7435073  0.78627541 0.78627541 0.78632275 0.73639985 0.7436057 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73721718\n",
      " 0.73721718 0.73731257 0.73731109 0.73731183        nan        nan\n",
      " 0.5               nan 0.5        0.74519492 0.74519492 0.74287028\n",
      " 0.7428222  0.74267718        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77388311 0.77383501 0.75571926 0.75906434 0.7570319\n",
      "        nan        nan 0.73228327        nan 0.73708447 0.78919881\n",
      " 0.78929649 0.7383738  0.7410354  0.74727659        nan        nan\n",
      " 0.79837396        nan 0.75293924 0.79868238 0.79858547 0.74557385\n",
      " 0.7369505  0.7448486         nan        nan 0.80122729        nan\n",
      " 0.74654637 0.7921285  0.7921285  0.77679277 0.73646587 0.74479823\n",
      "        nan        nan 0.78894117        nan 0.7447983  0.78725173\n",
      " 0.78725173 0.78635735 0.73632157 0.74479747        nan        nan\n",
      " 0.78701044        nan 0.74474865 0.78677068 0.78681804 0.78686099\n",
      " 0.73636817 0.74465174        nan        nan 0.78667224        nan\n",
      " 0.74465176 0.78667298 0.78676916 0.78667224 0.73622241 0.74475016]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73498839\n",
      " 0.73498839 0.73537451 0.73537451 0.73537525        nan        nan\n",
      " 0.5               nan 0.5        0.74191385 0.74196195 0.74016768\n",
      " 0.7402661  0.74036299        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77085727 0.77090534 0.75381292 0.75638253 0.75473862\n",
      "        nan        nan 0.73233063        nan 0.73708373 0.78278367\n",
      " 0.78278367 0.73379183 0.74144238 0.74693156        nan        nan\n",
      " 0.78553675        nan 0.75161732 0.79678687 0.79678687 0.7383492\n",
      " 0.73654082 0.74479567        nan        nan 0.8015851         nan\n",
      " 0.74547291 0.78722798 0.78727682 0.76851005 0.73552036 0.74450415\n",
      "        nan        nan 0.78355297        nan 0.74431259 0.78186822\n",
      " 0.78191632 0.78246776 0.73566989 0.74435985        nan        nan\n",
      " 0.78138281        nan 0.74440719 0.78147748 0.7814294  0.78128291\n",
      " 0.73566912 0.74450487        nan        nan 0.78128362        nan\n",
      " 0.74416523 0.78142714 0.78147598 0.7814775  0.73562105 0.74426296]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73784327\n",
      " 0.73784327 0.73847134 0.7384706  0.73856754        nan        nan\n",
      " 0.5               nan 0.5        0.74743194 0.74743194 0.74569005\n",
      " 0.74564274 0.74569012        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77962244 0.77962244 0.7626641  0.76586647 0.76344024\n",
      "        nan        nan 0.73228179        nan 0.73703563 0.78971182\n",
      " 0.78966298 0.74765061 0.75118777 0.7558488         nan        nan\n",
      " 0.78436332        nan 0.75332094 0.7899935  0.7899935  0.73979204\n",
      " 0.7468031  0.75439466        nan        nan 0.78859021        nan\n",
      " 0.75371177 0.77913378 0.77913378 0.75611042 0.74665508 0.75410307\n",
      "        nan        nan 0.77289331        nan 0.75419923 0.77110017\n",
      " 0.77110017 0.77085519 0.74636276 0.75376341        nan        nan\n",
      " 0.77032685        nan 0.75390919 0.77032685 0.77027873 0.76979409\n",
      " 0.74655664 0.75391144        nan        nan 0.77003605        nan\n",
      " 0.75400764 0.77018179 0.77018179 0.77013371 0.74660624 0.75400764]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73808821\n",
      " 0.73808821 0.73866899 0.73866899 0.73876519        nan        nan\n",
      " 0.5               nan 0.5        0.74564311 0.74564311 0.7441435\n",
      " 0.74424041 0.74419157        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77876228 0.77876228 0.76098621 0.76446891 0.76219748\n",
      "        nan        nan 0.73233063        nan 0.73708373 0.78899101\n",
      " 0.78899101 0.7413675  0.74842731 0.75529299        nan        nan\n",
      " 0.78168824        nan 0.7591277  0.78937373 0.78937373 0.7388036\n",
      " 0.74473228 0.75374269        nan        nan 0.78202258        nan\n",
      " 0.75418766 0.76297335 0.76297335 0.7466749  0.74380728 0.75349849\n",
      "        nan        nan 0.75470994        nan 0.75355032 0.75180572\n",
      " 0.75180572 0.75025777 0.74380578 0.75345194        nan        nan\n",
      " 0.74971605        nan 0.7536473  0.74952221 0.74952221 0.74957186\n",
      " 0.74380578 0.7535496         nan        nan 0.74947337        nan\n",
      " 0.75359772 0.74937791 0.74947411 0.74928097 0.7440004  0.75350152]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.7380381\n",
      " 0.73798926 0.73847236 0.73847236 0.7385212         nan        nan\n",
      " 0.5               nan 0.5        0.74683969 0.74679085 0.74529341\n",
      " 0.74495523 0.74481243        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.78072511 0.78072511 0.7610598  0.76396384 0.76260846\n",
      "        nan        nan 0.73228179        nan 0.73708373 0.78315892\n",
      " 0.78315892 0.73479141 0.74492427 0.7528068         nan        nan\n",
      " 0.78587059        nan 0.75837655 0.77692629 0.77697439 0.72735272\n",
      " 0.73980244 0.75003638        nan        nan 0.78014005        nan\n",
      " 0.7514933  0.76668306 0.76668306 0.7417625  0.73946056 0.74959978\n",
      "        nan        nan 0.7585958         nan 0.74993865 0.75603558\n",
      " 0.75598748 0.75373837 0.73936439 0.74959978        nan        nan\n",
      " 0.75332949        nan 0.74979363 0.75275084 0.75275084 0.75356558\n",
      " 0.73907211 0.74955165        nan        nan 0.75255622        nan\n",
      " 0.74979435 0.75207226 0.75202418 0.75260429 0.73950866 0.74974553]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73851517\n",
      " 0.73851517 0.7388533  0.7388533  0.73890138        nan        nan\n",
      " 0.5               nan 0.5        0.74692245 0.74692245 0.74531984\n",
      " 0.74546486 0.74541752        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.78149452 0.78149452 0.76376563 0.76817162 0.76609624\n",
      "        nan        nan 0.73228253        nan 0.73703563 0.7876887\n",
      " 0.7876887  0.7411569  0.7493864  0.75821609        nan        nan\n",
      " 0.78359844        nan 0.75931041 0.78034442 0.78034442 0.73209404\n",
      " 0.7443698  0.75602472        nan        nan 0.7771926         nan\n",
      " 0.75709934 0.75634528 0.75624833 0.73495155 0.74378365 0.75563698\n",
      "        nan        nan 0.73887351        nan 0.75563994 0.73693619\n",
      " 0.73703313 0.73650907 0.74387908 0.75529882        nan        nan\n",
      " 0.7282363         nan 0.75529732 0.72872322 0.72872322 0.73160254\n",
      " 0.74412254 0.7552485         nan        nan 0.72614062        nan\n",
      " 0.75544382 0.72526668 0.72536288 0.72638635 0.74392642 0.75534618]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73976896\n",
      " 0.73976896 0.74015589 0.74015589 0.74015589        nan        nan\n",
      " 0.5               nan 0.5        0.74764936 0.74764936 0.74571533\n",
      " 0.74561915 0.74586113        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.78338483 0.78338483 0.7662297  0.7698588  0.76662567\n",
      "        nan        nan 0.73228179        nan 0.73708447 0.7926677\n",
      " 0.79261963 0.74658316 0.75286392 0.75859326        nan        nan\n",
      " 0.79052311        nan 0.75925519 0.78464866 0.78464866 0.73790665\n",
      " 0.74926821 0.75708206        nan        nan 0.78341022        nan\n",
      " 0.7567073  0.7586695  0.7586214  0.73752218 0.74902778 0.75698366\n",
      "        nan        nan 0.73975765        nan 0.75674321 0.74111463\n",
      " 0.74111463 0.73689114 0.74878656 0.75683793        nan        nan\n",
      " 0.73293755        nan 0.75708063 0.73206361 0.73201551 0.73414997\n",
      " 0.74883387 0.75693561        nan        nan 0.73197039        nan\n",
      " 0.75698371 0.73234337 0.73263049 0.73230637 0.74897968 0.75698366]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73842546\n",
      " 0.73842546 0.73881313 0.73876429 0.73871545        nan        nan\n",
      " 0.5               nan 0.5        0.74558837 0.74558837 0.74369945\n",
      " 0.74360177 0.74345603        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77907239 0.77907239 0.75916537 0.7627531  0.76042908\n",
      "        nan        nan 0.73233063        nan 0.73703563 0.78272001\n",
      " 0.78267117 0.73560692 0.74299962 0.7507107         nan        nan\n",
      " 0.78239952        nan 0.76167964 0.77579027 0.77579027 0.72209203\n",
      " 0.73916958 0.74856146        nan        nan 0.76699183        nan\n",
      " 0.75055729 0.73947839 0.73947839 0.71250981 0.73921842 0.74807757\n",
      "        nan        nan 0.71677834        nan 0.74846605 0.71862968\n",
      " 0.71862968 0.70875386 0.73897496 0.747931          nan        nan\n",
      " 0.70522461        nan 0.74817298 0.71047712 0.71047712 0.70561832\n",
      " 0.73897642 0.74797987        nan        nan 0.70333694        nan\n",
      " 0.74812639 0.70960537 0.70970303 0.7035693  0.73917032 0.74793251]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73774223\n",
      " 0.73774223 0.73793537 0.73798345 0.7378873         nan        nan\n",
      " 0.5               nan 0.5        0.7468876  0.7468876  0.74456428\n",
      " 0.74485357 0.74475441        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77703875 0.77703875 0.75920547 0.76158358 0.76037243\n",
      "        nan        nan 0.73233063        nan 0.73713183 0.77770512\n",
      " 0.77770512 0.72906771 0.74151393 0.75070816        nan        nan\n",
      " 0.7741012         nan 0.75750629 0.77093566 0.77088758 0.71042541\n",
      " 0.73553939 0.74867026        nan        nan 0.77095301        nan\n",
      " 0.75026571 0.7476316  0.74758276 0.71003318 0.73529593 0.74813677\n",
      "        nan        nan 0.71200598        nan 0.74862216 0.71900639\n",
      " 0.71905449 0.70854622 0.73519973 0.74833139        nan        nan\n",
      " 0.69955503        nan 0.74837947 0.70788092 0.70788094 0.6952821\n",
      " 0.73524855 0.74828329        nan        nan 0.69324153        nan\n",
      " 0.74818485 0.70456527 0.70653712 0.68966887 0.73524783 0.74838023]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73972007\n",
      " 0.73967197 0.74025202 0.74025202 0.74015582        nan        nan\n",
      " 0.5               nan 0.5        0.74847606 0.74847606 0.74746108\n",
      " 0.74736416 0.7472176         nan        nan 0.75544363        nan\n",
      " 0.75544363 0.78295938 0.78295938 0.76644765 0.76901219 0.7665996\n",
      "        nan        nan 0.73228179        nan 0.73703563 0.79015732\n",
      " 0.79015732 0.74730439 0.75479368 0.76185532        nan        nan\n",
      " 0.78528067        nan 0.76479837 0.77261944 0.77261944 0.7239449\n",
      " 0.75236613 0.75991071        nan        nan 0.75984971        nan\n",
      " 0.76113618 0.74541741 0.74551361 0.71625363 0.75231949 0.76010533\n",
      "        nan        nan 0.71683067        nan 0.76020373 0.71965509\n",
      " 0.71965509 0.70421088 0.75203019 0.76005871        nan        nan\n",
      " 0.70503453        nan 0.76005723 0.7200558  0.72005578 0.69719669\n",
      " 0.75197987 0.76000913        nan        nan 0.69748291        nan\n",
      " 0.75995955 0.72116948 0.72092752 0.6998603  0.75203019 0.76000839]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73962322\n",
      " 0.73962322 0.73952779 0.73952779 0.73957663        nan        nan\n",
      " 0.5               nan 0.5        0.7490519  0.7490519  0.74736208\n",
      " 0.74745673 0.74755141        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.78338747 0.78338747 0.76812958 0.77094119 0.76925304\n",
      "        nan        nan 0.73228253        nan 0.73698755 0.78816177\n",
      " 0.78816177 0.74762451 0.75725    0.76202883        nan        nan\n",
      " 0.78071408        nan 0.7621497  0.77208907 0.77204023 0.72339998\n",
      " 0.75424185 0.76013748        nan        nan 0.77010325        nan\n",
      " 0.76158695 0.75017006 0.75017006 0.71083192 0.75423951 0.76018632\n",
      "        nan        nan 0.72055593        nan 0.76067171 0.72501785\n",
      " 0.72487133 0.69945344 0.75399607 0.76028178        nan        nan\n",
      " 0.70575101        nan 0.76028324 0.71853575 0.71843955 0.69508272\n",
      " 0.75414407 0.76023442        nan        nan 0.69440402        nan\n",
      " 0.76018632 0.71665487 0.71670293 0.69334228 0.75414338 0.76028398]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=10\n",
    "                                                   )\n",
    "print(\"train_x.shpae:\")\n",
    "print(train_X.shape)\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(train_X)\n",
    "X_standard = standardScaler.transform(train_X)\n",
    "X_standard_test = standardScaler.transform(test_X)\n",
    "    #calculate max n_components\n",
    "estimator = PCA(n_components=0.95,random_state=10)\n",
    "pca_X_train = estimator.fit_transform(X_standard)\n",
    "\n",
    "n_components=range(10,min(pca_X_train.shape),10)\n",
    "print(n_components)\n",
    "    #n_components=[0.99,0.95,0.90,0.85]\n",
    "best_pca_train_scores=[]\n",
    "best_pca_test_scores=[]\n",
    "for j in n_components:\n",
    "    estimator = PCA(n_components=j,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "    \n",
    "        #scoring = {'AUC': 'roc_auc'}\n",
    "    cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "    gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "    parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "\n",
    "    svc_grid_search=GridSearchCV(estimator=SVC(random_state=10),\n",
    "                                 param_grid=parameters,cv=cvx,scoring=scoring)\n",
    "    svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "    param_grid = {'penalty':['l1', 'l2'],\n",
    "                  \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                  \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "    #               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                  }\n",
    "    LR_grid = LogisticRegression(max_iter=1000, random_state=10)\n",
    "    LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring=scoring,n_jobs=10)\n",
    "    LR_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "    estimators = [\n",
    "        ('lr', LR_grid_search.best_estimator_),\n",
    "        ('svc', svc_grid_search.best_estimator_),\n",
    "    ]\n",
    "    clf = StackingClassifier(estimators=estimators, final_estimator=LinearSVC(C=5, random_state=10),\n",
    "                             n_jobs=10)\n",
    "    clf.fit(pca_X_train, train_y)\n",
    "\n",
    "    estimators = [\n",
    "        ('lr', LR_grid_search.best_estimator_),\n",
    "        ('svc', svc_grid_search.best_estimator_),\n",
    "    ]\n",
    "\n",
    "    param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),\n",
    "                                    LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                    LogisticRegression(C=0.1),LogisticRegression(C=1),\n",
    "                                    LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                    LogisticRegression(C=1000)]}\n",
    "\n",
    "    Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "    Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx,\n",
    "                                        scoring=scoring,n_jobs=10)\n",
    "    Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "    Stacking_grid_search.best_estimator_\n",
    "\n",
    "    train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "\n",
    "    test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "        \n",
    "    best_pca_train_scores.append(train_res1.loc[:,\"AUC\"])\n",
    "    best_pca_test_scores.append(test_res1.loc[:,\"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "969af2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94004329004329\n",
      "0    0.958333\n",
      "Name: AUC, dtype: float64\n",
      "n_components:\n",
      "140\n",
      "[0    0.827624\n",
      "Name: AUC, dtype: float64, 0    0.890611\n",
      "Name: AUC, dtype: float64, 0    0.890611\n",
      "Name: AUC, dtype: float64, 0    0.899702\n",
      "Name: AUC, dtype: float64, 0    0.916126\n",
      "Name: AUC, dtype: float64, 0    0.902733\n",
      "Name: AUC, dtype: float64, 0    0.5\n",
      "Name: AUC, dtype: float64, 0    0.91756\n",
      "Name: AUC, dtype: float64, 0    0.930952\n",
      "Name: AUC, dtype: float64, 0    0.92059\n",
      "Name: AUC, dtype: float64, 0    0.926488\n",
      "Name: AUC, dtype: float64, 0    0.5\n",
      "Name: AUC, dtype: float64, 0    0.911661\n",
      "Name: AUC, dtype: float64, 0    0.940043\n",
      "Name: AUC, dtype: float64, 0    0.895238\n",
      "Name: AUC, dtype: float64, 0    0.5\n",
      "Name: AUC, dtype: float64, 0    0.901299\n",
      "Name: AUC, dtype: float64, 0    0.885038\n",
      "Name: AUC, dtype: float64]\n",
      "[0    0.854167\n",
      "Name: AUC, dtype: float64, 0    0.878472\n",
      "Name: AUC, dtype: float64, 0    0.868056\n",
      "Name: AUC, dtype: float64, 0    0.923611\n",
      "Name: AUC, dtype: float64, 0    0.902778\n",
      "Name: AUC, dtype: float64, 0    0.923611\n",
      "Name: AUC, dtype: float64, 0    0.5\n",
      "Name: AUC, dtype: float64, 0    0.940972\n",
      "Name: AUC, dtype: float64, 0    0.965278\n",
      "Name: AUC, dtype: float64, 0    0.954861\n",
      "Name: AUC, dtype: float64, 0    0.96875\n",
      "Name: AUC, dtype: float64, 0    0.5\n",
      "Name: AUC, dtype: float64, 0    0.965278\n",
      "Name: AUC, dtype: float64, 0    0.958333\n",
      "Name: AUC, dtype: float64, 0    0.961806\n",
      "Name: AUC, dtype: float64, 0    0.5\n",
      "Name: AUC, dtype: float64, 0    0.961806\n",
      "Name: AUC, dtype: float64, 0    0.947917\n",
      "Name: AUC, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "print(np.max(best_pca_train_scores))\n",
    "print(best_pca_test_scores[np.argmax(best_pca_train_scores)])\n",
    "print(\"n_components:\")\n",
    "print(n_components[np.argmax(best_pca_train_scores)])\n",
    "\n",
    "print(best_pca_train_scores)\n",
    "print(best_pca_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067f4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
