{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fbef4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, cross_val_predict\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn import svm  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "# cores = mp.cpu_count()\n",
    "# pool = mp.Pool(processes=20)\n",
    "\n",
    "# min1=min(list(X_standard.shape))\n",
    "# a1=list(range(10,min1,10))\n",
    "# a1[-1]=min1\n",
    "# pcc_top1=pool.map(find_best_pca_lr,a1)  ##（SVM，LR）\n",
    "# pool.terminate()\n",
    "\n",
    "\n",
    "# a1=pd.DataFrame()\n",
    "# for i1 in pcc_top1:\n",
    "#     a1=pd.concat([a1,i1], axis=0)\n",
    "# a1.columns=['tr_TP', 'tr_TN', 'tr_FP', 'tr_FN', 'tr_Sen', 'tr_Spe', 'tr_Acc', 'tr_PPV', 'tr_NPV', 'tr_MCC', 'tr_AUC','TP',\n",
    "#        'TN', 'FP', 'FN', 'Sen', 'Spe', 'Acc', 'PPV', 'NPV', 'MCC', 'AUC','PCA']   \n",
    "\n",
    "# a1=a1.sort_values(['Acc','tr_Acc','PCA'], ascending=[False,False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "64a00ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_csv(input_path,i):\n",
    "\n",
    "    df_chunk=pd.read_csv(input_path,\n",
    "                         chunksize=10000,\n",
    "#                          sep='\\t'\n",
    "                        sep=i\n",
    "                        )\n",
    "    res_chunk=[]\n",
    "    for chunk in df_chunk:\n",
    "        res_chunk.append(chunk)\n",
    "    res_df=pd.concat(res_chunk)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c5d3ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measures_gridloo(label, score):\n",
    "    label = np.array(label)\n",
    "    score = np.array(score)\n",
    "    \n",
    "    N  = len(label)\n",
    "    TP = sum((label == 1) & (score == 1))\n",
    "    TN = sum((label == 0) & (score == 0))\n",
    "    FP = sum((label == 0) & (score == 1))\n",
    "    FN = sum((label == 1) & (score == 0))\n",
    "\n",
    "    # init all measures to nan\n",
    "    measures = {measure: float(\"nan\") for measure in (\"Sen\", \"Spe\", \"Acc\", \"PPV\", \"NPV\", \"MCC\",\"AUC\")}\n",
    "    \n",
    "    measures[\"TP\"] = TP\n",
    "    measures[\"TN\"] = TN\n",
    "    measures[\"FP\"] = FP\n",
    "    measures[\"FN\"] = FN\n",
    "    \n",
    "    S = (TP + FN) / N\n",
    "    P = (TP + FP) / N\n",
    "\n",
    "    if (TP + FN) > 0:\n",
    "        measures[\"Sen\"] = round(TP/(TP+FN), 4)\n",
    "\n",
    "    if (TN + FP) > 0:\n",
    "        measures[\"Spe\"] = round(TN/(TN+FP), 4)\n",
    "\n",
    "    if (TP + FP + FN + TN) > 0:\n",
    "        measures[\"Acc\"] = round((TP+TN)/(TP+FP+FN+TN), 4)\n",
    "\n",
    "    if (TP + FP) > 0:\n",
    "        measures[\"PPV\"] = round(TP/(TP+FP), 4)\n",
    "\n",
    "    if (TN + FN) > 0:\n",
    "        measures[\"NPV\"] = round(TN/(TN+FN), 4)\n",
    "\n",
    "    if (S*P*(1-S)*(1-P)) > 0:\n",
    "        measures[\"MCC\"] = round((TP/N - S*P)/(math.sqrt(S*P*(1-S)*(1-P))), 4)\n",
    "    \n",
    "    \n",
    "    measures[\"AUC\"]= roc_auc_score(label, score)\n",
    "    return pd.DataFrame([measures],\n",
    "                        columns=[\"TP\", \"TN\", \"FP\",\n",
    "                                 \"FN\", \"Sen\", \"Spe\", \"Acc\", \"PPV\", \"NPV\", \"MCC\",\"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9d53b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVM\n",
    "def find_best_pca(i):\n",
    "    n_components=i\n",
    "    estimator = PCA(n_components=n_components,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    \n",
    "    scoring = {'AUC': 'roc_auc'}\n",
    "    cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "    gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "    parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "    \n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "    grid_search=GridSearchCV(estimator=SVC(random_state=10),param_grid=parameters,cv=cvx,scoring='accuracy')\n",
    "    grid_search.fit(pca_X_train, train_y)\n",
    "    \n",
    "    train_pre_y = cross_val_predict(grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "    test_pre_y = grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "    test_res1['PCA']=n_components\n",
    "    \n",
    "    res=pd.concat([train_res1,test_res1], axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7d4e5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_pca_lr(i):\n",
    "    n_components=i\n",
    "    estimator = PCA(n_components=n_components,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    \n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "\n",
    "    param_grid = {'penalty':['l2'],\n",
    "              \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],  \n",
    "              \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\"],\n",
    "#             \"C\":list(np.arange(0,0.1,0.005)),   \n",
    "#               \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\"]\n",
    "            }\n",
    "    LR_grid = LogisticRegression()\n",
    "    grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=9)\n",
    "    grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "\n",
    "    train_pre_y = cross_val_predict(grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "   \n",
    "\n",
    "    test_pre_y = grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "    test_res1['PCA']=n_components\n",
    "    \n",
    "    res=pd.concat([train_res1,test_res1], axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e5f27eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer='BRCA'\n",
    "path='D:\\\\lymph_meta_xmiseq\\\\tcga_data\\\\'\n",
    "# e1=\"./\"+cancer+\"_delta_pcc_wilcox.csv\"\n",
    "# delta_pcc=read_single_csv(e1,',')\n",
    "# delta_pcc=delta_pcc.drop(['Unnamed: 0','pair'],axis=1)\n",
    "# delta_pcc=delta_pcc.dropna(axis=0,how='any')\n",
    "\n",
    "# result=delta_pcc.T\n",
    "# train=result.iloc[:,0:-1].values.astype('float')\n",
    "# target=result.iloc[:,-1].values.astype('float')\n",
    "\n",
    "train=pd.read_csv(path+cancer+\"\\\\admat_final.csv\").iloc[:,2:].T.values\n",
    "target=pd.read_csv(path+cancer+\"\\\\gctm_label.csv\",index_col=0).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "986f9b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.19461937e-04, -8.63151370e-03,  3.10418355e-03, ...,\n",
       "        -1.52881284e-02,  9.97735338e-04, -5.38560918e-03],\n",
       "       [-8.24605516e-04, -1.42506638e-03,  7.95171455e-03, ...,\n",
       "         3.31465816e-04,  2.26944011e-03, -9.78459003e-05],\n",
       "       [-1.16900878e-02, -5.33698509e-03,  6.28624170e-03, ...,\n",
       "         2.71030467e-02, -7.49026964e-03, -2.40547544e-03],\n",
       "       ...,\n",
       "       [ 3.34385978e-02,  2.44368202e-02,  4.33853074e-02, ...,\n",
       "        -4.67998447e-04, -1.14356119e-02, -2.56179085e-03],\n",
       "       [ 4.88828589e-04, -3.34588148e-03, -7.58491028e-03, ...,\n",
       "        -3.99659676e-03, -3.38371248e-03,  4.06080068e-03],\n",
       "       [-5.09754182e-03, -7.55936433e-02, -3.46494864e-02, ...,\n",
       "         3.19405065e-03,  1.86598804e-03,  7.88591094e-04]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a0046d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4d47e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=10\n",
    "                                                   )\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(train_X)\n",
    "X_standard = standardScaler.transform(train_X)\n",
    "X_standard_test = standardScaler.transform(test_X)\n",
    "\n",
    "n_components=0.95\n",
    "estimator = PCA(n_components=n_components,random_state=10)\n",
    "pca_X_train = estimator.fit_transform(X_standard)\n",
    "pca_X_test = estimator.transform(X_standard_test)\n",
    "cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4d3eaf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 2281)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "385399ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.45230769        nan 0.52369231 0.54769231\n",
      " 0.54769231 0.72153846 0.76123077 0.74523077        nan        nan\n",
      " 0.45230769        nan 0.50030769 0.75292308 0.75292308 0.75292308\n",
      " 0.79230769 0.75292308        nan        nan 0.45230769        nan\n",
      " 0.52369231 0.848      0.848      0.82430769 0.864      0.832\n",
      "        nan        nan 0.68246154        nan 0.75292308 0.888\n",
      " 0.888      0.87230769 0.88       0.88              nan        nan\n",
      " 0.92              nan 0.92       0.88061538 0.88061538 0.85661538\n",
      " 0.86461538 0.86461538        nan        nan 0.944             nan\n",
      " 0.936      0.84061538 0.84061538 0.86461538 0.86461538 0.87261538\n",
      "        nan        nan 0.944             nan 0.87261538 0.84861538\n",
      " 0.84861538 0.86461538 0.86461538 0.87261538        nan        nan\n",
      " 0.90430769        nan 0.87261538 0.85661538 0.85661538 0.84861538\n",
      " 0.86461538 0.87261538        nan        nan 0.80892308        nan\n",
      " 0.87261538 0.84861538 0.84861538 0.84061538 0.86461538 0.87261538]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=10, shuffle=True),\n",
       "             estimator=LogisticRegression(max_iter=1000), n_jobs=10,\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                               1000],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm\n",
    "scoring = {'AUC': 'roc_auc'}\n",
    "cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "\n",
    "svc_grid_search=GridSearchCV(estimator=SVC(random_state=10),param_grid=parameters,cv=cvx,scoring='accuracy')\n",
    "svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "#LR\n",
    "param_grid = {'penalty':['l1', 'l2'],\n",
    "              \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "#               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "            }\n",
    "LR_grid = LogisticRegression(max_iter=1000)\n",
    "LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=10)\n",
    "LR_grid_search.fit(pca_X_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c0fc0d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                LogisticRegression(C=1, max_iter=1000,\n",
       "                                                   penalty='l1',\n",
       "                                                   solver='liblinear')),\n",
       "                               ('svc',\n",
       "                                SVC(C=32, gamma=3.0517578125e-05,\n",
       "                                    random_state=10))],\n",
       "                   final_estimator=LinearSVC(C=5), n_jobs=10)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('lr', LR_grid_search.best_estimator_),\n",
    "    ('svc', svc_grid_search.best_estimator_),\n",
    "]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LinearSVC(C=5),n_jobs=10)\n",
    "clf.fit(pca_X_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "aa318404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                LogisticRegression(C=1, max_iter=1000,\n",
       "                                                   penalty='l1',\n",
       "                                                   solver='liblinear')),\n",
       "                               ('svc',\n",
       "                                SVC(C=32, gamma=3.0517578125e-05,\n",
       "                                    random_state=10))],\n",
       "                   final_estimator=LogisticRegression(C=100))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('lr', LR_grid_search.best_estimator_),\n",
    "    ('svc', svc_grid_search.best_estimator_),\n",
    "]\n",
    "\n",
    "param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                 LogisticRegression(C=0.1),LogisticRegression(C=1),LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                 LogisticRegression(C=1000)]}\n",
    "\n",
    "Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=10)\n",
    "Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "Stacking_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a1961530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "\n",
    "test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "test_res1=get_measures_gridloo(test_y,test_pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dfa32e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TP  TN  FP  FN     Sen     Spe     Acc     PPV     NPV     MCC       AUC\n",
      "0  64  50   7   5  0.9275  0.8772  0.9048  0.9014  0.9091  0.8076  0.902365\n",
      "   TP  TN  FP  FN  Sen  Spe  Acc  PPV  NPV  MCC  AUC\n",
      "0  30  24   0   0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_res1)\n",
    "print(test_res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca852392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.75113775\n",
      " 0.75113775 0.75099266 0.75094456 0.75099266        nan        nan\n",
      " 0.5               nan 0.5        0.76054612 0.76054612 0.75899383\n",
      " 0.75909149 0.75885101        nan        nan 0.71155659        nan\n",
      " 0.71155659 0.7898724  0.7898724  0.77735868 0.77870738 0.77696884\n",
      "        nan        nan 0.76196468        nan 0.76461978 0.78720643\n",
      " 0.78720643 0.75664736 0.77557727 0.77929138        nan        nan\n",
      " 0.74885025        nan 0.77659204 0.76060847 0.76060847 0.72502347\n",
      " 0.77146474 0.77963192        nan        nan 0.72060296        nan\n",
      " 0.78002262 0.74239508 0.74239508 0.71255053 0.77141904 0.77953431\n",
      "        nan        nan 0.71089061        nan 0.77938846 0.73759789\n",
      " 0.73754979 0.70796271 0.7713702  0.77953577        nan        nan\n",
      " 0.67686679        nan 0.77948619 0.73532912 0.73518632 0.70092419\n",
      " 0.77132136 0.77943954        nan        nan 0.62796028        nan\n",
      " 0.7795831  0.73373004 0.73392765 0.66645928 0.77146714 0.77943735]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.7522015\n",
      " 0.7522015  0.75249087 0.75253894 0.75253897        nan        nan\n",
      " 0.5               nan 0.5        0.76098048 0.76098048 0.7600127\n",
      " 0.75986914 0.75967674        nan        nan 0.71155659        nan\n",
      " 0.71155659 0.78662192 0.78662192 0.77339221 0.77435844 0.77412109\n",
      "        nan        nan 0.76196468        nan 0.76461978 0.77304892\n",
      " 0.77304892 0.73899994 0.76325284 0.77358535        nan        nan\n",
      " 0.75021372        nan 0.77382592 0.73103753 0.7311337  0.69703533\n",
      " 0.75847305 0.77184281        nan        nan 0.72247778        nan\n",
      " 0.77286251 0.69426613 0.69426613 0.66375643 0.75793884 0.77213439\n",
      "        nan        nan 0.69009248        nan 0.77189096 0.68105066\n",
      " 0.68100256 0.65128147 0.75793961 0.77193975        nan        nan\n",
      " 0.66425172        nan 0.77208553 0.67606796 0.6761168  0.64672242\n",
      " 0.75798847 0.77213363        nan        nan 0.63583891        nan\n",
      " 0.77218321 0.67404646 0.67438395 0.64538172 0.75798919 0.77218321]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.75147961\n",
      " 0.75147961 0.75177045 0.75177045 0.75181929        nan        nan\n",
      " 0.5               nan 0.5        0.75787571 0.75787571 0.75666232\n",
      " 0.75666306 0.7565654         nan        nan 0.71155659        nan\n",
      " 0.71155659 0.78548988 0.78548988 0.77105251 0.77249956 0.77124565\n",
      "        nan        nan 0.76196468        nan 0.76457094 0.78699386\n",
      " 0.78694576 0.75012307 0.76045276 0.76868678        nan        nan\n",
      " 0.77287393        nan 0.77132308 0.77448637 0.77443829 0.74211929\n",
      " 0.75590819 0.76771812        nan        nan 0.77687026        nan\n",
      " 0.76835442 0.75609525 0.75609525 0.74786211 0.75533124 0.76776624\n",
      "        nan        nan 0.74971179        nan 0.76752504 0.74733951\n",
      " 0.74729141 0.74849759 0.75538082 0.76781434        nan        nan\n",
      " 0.74598832        nan 0.76796012 0.74598758 0.74603568 0.74584256\n",
      " 0.75538082 0.7676708         nan        nan 0.74593948        nan\n",
      " 0.7677189  0.74569826 0.74569826 0.7456975  0.75528388 0.76781586]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.7517674\n",
      " 0.7517674  0.7521063  0.7520582  0.7520582         nan        nan\n",
      " 0.5               nan 0.5        0.76088083 0.76088083 0.76001152\n",
      " 0.75972144 0.7596726         nan        nan 0.71155659        nan\n",
      " 0.71155659 0.79609349 0.79609349 0.78179471 0.78402086 0.78087692\n",
      "        nan        nan 0.76196468        nan 0.76461978 0.82852083\n",
      " 0.82852083 0.78856879 0.78596487 0.78185555        nan        nan\n",
      " 0.81196519        nan 0.78570293 0.81991425 0.81996309 0.79116467\n",
      " 0.78548495 0.78128307        nan        nan 0.81423095        nan\n",
      " 0.78176458 0.81243846 0.81243846 0.80442583 0.78485843 0.78123351\n",
      "        nan        nan 0.81113322        nan 0.78123423 0.8100728\n",
      " 0.81012164 0.80967692 0.78490727 0.78123353        nan        nan\n",
      " 0.8101209         nan 0.78118541 0.81002319 0.81002319 0.80982862\n",
      " 0.78510115 0.78118539        nan        nan 0.80987667        nan\n",
      " 0.78123349 0.81002319 0.81002319 0.80997435 0.78485769 0.78128159]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73064637\n",
      " 0.73069444 0.73074405 0.73084025 0.73079215        nan        nan\n",
      " 0.5               nan 0.5        0.74431929 0.74427119 0.74349572\n",
      " 0.74315754 0.74282084        nan        nan 0.69233373        nan\n",
      " 0.69233373 0.78654172 0.78654172 0.77571597 0.77865315 0.77569169\n",
      "        nan        nan 0.75715703        nan 0.76102196 0.8002501\n",
      " 0.8002501  0.77487462 0.77991626 0.77889768        nan        nan\n",
      " 0.73962965        nan 0.76932246 0.77360117 0.77360117 0.74176523\n",
      " 0.7780593  0.77792446        nan        nan 0.7119108         nan\n",
      " 0.7780664  0.74880108 0.74880108 0.71655752 0.77752428 0.77782754\n",
      "        nan        nan 0.69821523        nan 0.77802142 0.73770577\n",
      " 0.73775535 0.70668415 0.77757384 0.77773058        nan        nan\n",
      " 0.67068843        nan 0.77782678 0.73136997 0.73175847 0.68476295\n",
      " 0.77757312 0.77777794        nan        nan 0.63480156        nan\n",
      " 0.77782604 0.72731146 0.7277001  0.6601456  0.77742808 0.77777794]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73272848\n",
      " 0.73272848 0.73282696 0.73282696 0.73282696        nan        nan\n",
      " 0.5               nan 0.5        0.74669203 0.74669203 0.74582031\n",
      " 0.74557685 0.74523798        nan        nan 0.69233373        nan\n",
      " 0.69233373 0.78938069 0.78942879 0.77966871 0.78144201 0.78027146\n",
      "        nan        nan 0.75720587        nan 0.76102122 0.80082492\n",
      " 0.80082492 0.77352467 0.78045852 0.7806102         nan        nan\n",
      " 0.76243125        nan 0.77270697 0.76111636 0.76121251 0.72511986\n",
      " 0.77591473 0.77909905        nan        nan 0.74070046        nan\n",
      " 0.77817551 0.72936242 0.72936242 0.68838358 0.77538122 0.77900213\n",
      "        nan        nan 0.72865787        nan 0.77851817 0.7182724\n",
      " 0.7182243  0.67721168 0.77533018 0.77871138        nan        nan\n",
      " 0.6810295         nan 0.77871207 0.71334094 0.71309822 0.66970146\n",
      " 0.77542784 0.77880904        nan        nan 0.64838971        nan\n",
      " 0.77895329 0.70995652 0.71030215 0.6641662  0.77513852 0.7785678 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72895364\n",
      " 0.72895364 0.72929476 0.72934286 0.72929476        nan        nan\n",
      " 0.5               nan 0.5        0.74186082 0.74186082 0.7411815\n",
      " 0.74113343 0.74089075        nan        nan 0.69233373        nan\n",
      " 0.63947178 0.77340941 0.77345751 0.76050658 0.76532387 0.763816\n",
      "        nan        nan 0.75715703        nan 0.7611655  0.78537051\n",
      " 0.78541859 0.75347675 0.75746774 0.75726366        nan        nan\n",
      " 0.77800947        nan 0.77084233 0.77114263 0.77114263 0.73548509\n",
      " 0.75190735 0.75374947        nan        nan 0.75378654        nan\n",
      " 0.75617477 0.73635619 0.73640503 0.72672189 0.75117625 0.75330914\n",
      "        nan        nan 0.70314073        nan 0.7534068  0.70508852\n",
      " 0.70518544 0.70500449 0.75117473 0.75320996        nan        nan\n",
      " 0.69300625        nan 0.75330912 0.6974087  0.69745754 0.70065303\n",
      " 0.75132199 0.75306342        nan        nan 0.69139689        nan\n",
      " 0.75320922 0.69662948 0.69672716 0.69685687 0.75122359 0.75311302]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72953123\n",
      " 0.72953123 0.73006322 0.73001512 0.73001515        nan        nan\n",
      " 0.5               nan 0.5        0.74165244 0.74165244 0.74126473\n",
      " 0.74102273 0.74097162        nan        nan 0.69233373        nan\n",
      " 0.69233373 0.77726771 0.77726771 0.76517885 0.76797693 0.76617727\n",
      "        nan        nan 0.75715703        nan 0.76126242 0.79486088\n",
      " 0.79490898 0.76340502 0.76908615 0.7654971         nan        nan\n",
      " 0.79290802        nan 0.77627837 0.78683159 0.78688043 0.76418498\n",
      " 0.76142924 0.76315046        nan        nan 0.78508535        nan\n",
      " 0.76436908 0.77680014 0.77680014 0.76912654 0.76006246 0.7630032\n",
      "        nan        nan 0.77359546        nan 0.76324814 0.77272679\n",
      " 0.77267869 0.77224102 0.76025558 0.76285668        nan        nan\n",
      " 0.77229243        nan 0.76295508 0.77195578 0.77195578 0.77200161\n",
      " 0.76011054 0.76285666        nan        nan 0.77180926        nan\n",
      " 0.76285592 0.7718581  0.7718581  0.77190694 0.75981826 0.76285666]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72586471\n",
      " 0.72586471 0.72635235 0.72635235 0.72640119        nan        nan\n",
      " 0.5               nan 0.5        0.73627794 0.73627794 0.7353552\n",
      " 0.73521088 0.73477883        nan        nan 0.64634266        nan\n",
      " 0.64634266 0.77359145 0.77363953 0.7608898  0.76118136 0.7601197\n",
      "        nan        nan 0.71752174        nan 0.71916132 0.78395554\n",
      " 0.78395554 0.75301761 0.76547064 0.76676684        nan        nan\n",
      " 0.72286831        nan 0.75321549 0.75302399 0.75297515 0.72397905\n",
      " 0.76361803 0.76689914        nan        nan 0.7069783         nan\n",
      " 0.7665182  0.73493474 0.73493474 0.70957082 0.76375999 0.76699604\n",
      "        nan        nan 0.68960563        nan 0.76694794 0.72741691\n",
      " 0.72741691 0.70234152 0.76371265 0.76704411        nan        nan\n",
      " 0.67106438        nan 0.76714182 0.72318159 0.72322823 0.68800558\n",
      " 0.76371036 0.76699453        nan        nan 0.65917356        nan\n",
      " 0.76699604 0.72048692 0.72092195 0.67783624 0.76385617 0.76699601]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72692717\n",
      " 0.72692717 0.72726759 0.72721949 0.72721949        nan        nan\n",
      " 0.5               nan 0.5        0.73868634 0.73868634 0.73741869\n",
      " 0.7369851  0.73669425        nan        nan 0.64634266        nan\n",
      " 0.64634266 0.77163011 0.77163011 0.75959677 0.76052022 0.76033538\n",
      "        nan        nan 0.71752174        nan 0.71921016 0.7732986\n",
      " 0.7732986  0.7452201  0.75612124 0.76131921        nan        nan\n",
      " 0.73665721        nan 0.75255643 0.73377791 0.73382599 0.71141248\n",
      " 0.75445742 0.76124623        nan        nan 0.711308          nan\n",
      " 0.76116492 0.70655109 0.70655109 0.68501658 0.7546016  0.76119512\n",
      "        nan        nan 0.69276249        nan 0.76119961 0.70045209\n",
      " 0.70040399 0.67419916 0.75455353 0.7612913         nan        nan\n",
      " 0.67472421        nan 0.76124468 0.69822585 0.69817777 0.67265804\n",
      " 0.75464973 0.76109971        nan        nan 0.66512876        nan\n",
      " 0.76119663 0.69648775 0.69706941 0.67319421 0.75450392 0.76138974]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72368171\n",
      " 0.72372979 0.72421585 0.72416701 0.72421585        nan        nan\n",
      " 0.5               nan 0.5        0.73057008 0.73057008 0.72950011\n",
      " 0.72925965 0.72940694        nan        nan 0.64634266        nan\n",
      " 0.64634266 0.75478607 0.75478607 0.74228024 0.74402207 0.74272075\n",
      "        nan        nan 0.71752174        nan 0.71921016 0.76281593\n",
      " 0.76281593 0.72131931 0.73232106 0.7396803         nan        nan\n",
      " 0.74247997        nan 0.7359894  0.75715583 0.75715583 0.71521374\n",
      " 0.72958967 0.73885432        nan        nan 0.7535163         nan\n",
      " 0.7385194  0.73820136 0.73820136 0.72298828 0.72929661 0.73846584\n",
      "        nan        nan 0.73024297        nan 0.73856278 0.72869954\n",
      " 0.72869954 0.72810997 0.72924851 0.73870634        nan        nan\n",
      " 0.72855307        nan 0.73865898 0.72816459 0.72811649 0.72850642\n",
      " 0.72924703 0.7385132         nan        nan 0.72811577        nan\n",
      " 0.73865898 0.72763121 0.72763121 0.72797004 0.72954    0.73865826]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72606731\n",
      " 0.72606731 0.72640473 0.72635663 0.72640547        nan        nan\n",
      " 0.5               nan 0.5        0.73359    0.73359    0.73305722\n",
      " 0.7328626  0.73266872        nan        nan 0.64634266        nan\n",
      " 0.64634266 0.76575253 0.76575253 0.75193804 0.75431693 0.75252572\n",
      "        nan        nan 0.71752174        nan 0.71916132 0.80341288\n",
      " 0.80341288 0.76355936 0.75975254 0.75613021        nan        nan\n",
      " 0.77523631        nan 0.74678206 0.80426654 0.80421844 0.77732642\n",
      " 0.75822934 0.75694169        nan        nan 0.80062366        nan\n",
      " 0.75574155 0.79877271 0.79877271 0.79749336 0.75813319 0.7566509\n",
      "        nan        nan 0.79751265        nan 0.75660203 0.79678835\n",
      " 0.79683645 0.79716991 0.75813242 0.75689209        nan        nan\n",
      " 0.79673803        nan 0.75679367 0.79678689 0.79673879 0.79673803\n",
      " 0.75832554 0.75679591        nan        nan 0.79673805        nan\n",
      " 0.75679439 0.79673805 0.79673805 0.79673805 0.75818126 0.75684401]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.74136623\n",
      " 0.74136623 0.74165631 0.74165631 0.74165631        nan        nan\n",
      " 0.5               nan 0.5        0.75079629 0.75079629 0.75045434\n",
      " 0.7505994  0.75026203        nan        nan 0.76860508        nan\n",
      " 0.76860508 0.78989004 0.78989004 0.77543813 0.77766266 0.77427369\n",
      "        nan        nan 0.7293695         nan 0.73425154 0.80774395\n",
      " 0.80774395 0.78038993 0.78538635 0.78351651        nan        nan\n",
      " 0.73535619        nan 0.76131588 0.78185317 0.78185317 0.74770912\n",
      " 0.78288866 0.78366656        nan        nan 0.72667788        nan\n",
      " 0.78125086 0.75768495 0.75768495 0.71932667 0.78264733 0.78390855\n",
      "        nan        nan 0.71185863        nan 0.7832804  0.74766005\n",
      " 0.74766005 0.70852925 0.78269543 0.78381161        nan        nan\n",
      " 0.67034482        nan 0.78381237 0.74354546 0.74364235 0.69785904\n",
      " 0.78274422 0.78371392        nan        nan 0.64975911        nan\n",
      " 0.78371466 0.73972451 0.73991747 0.69033221 0.78259923 0.78386047]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.7421867\n",
      " 0.7421867  0.74213941 0.74213941 0.74218825        nan        nan\n",
      " 0.5               nan 0.5        0.7516625  0.7516625  0.75045189\n",
      " 0.75049999 0.7501619         nan        nan 0.76860508        nan\n",
      " 0.72009546 0.78860399 0.78860399 0.77469181 0.7776406  0.77420584\n",
      "        nan        nan 0.7293695         nan 0.73429961 0.80705697\n",
      " 0.80700813 0.77191205 0.77566804 0.77742399        nan        nan\n",
      " 0.7697059         nan 0.76604648 0.79338428 0.79343312 0.76155638\n",
      " 0.77124299 0.77694586        nan        nan 0.76965086        nan\n",
      " 0.77598025 0.75398557 0.75403441 0.7380932  0.7712956  0.77660918\n",
      "        nan        nan 0.73432722        nan 0.77665651 0.73775206\n",
      " 0.73775209 0.7220695  0.77105365 0.77675422        nan        nan\n",
      " 0.71963039        nan 0.77684894 0.73310553 0.73305669 0.71499864\n",
      " 0.77105288 0.77656034        nan        nan 0.72311126        nan\n",
      " 0.7766092  0.73198653 0.73213153 0.71315451 0.77129486 0.77651076]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73991761\n",
      " 0.73991761 0.74016111 0.74016111 0.74016111        nan        nan\n",
      " 0.5               nan 0.5        0.74915233 0.74915233 0.74732018\n",
      " 0.74698131 0.74669206        nan        nan 0.76860508        nan\n",
      " 0.76860508 0.77984435 0.77984435 0.76645461 0.77042381 0.76645174\n",
      "        nan        nan 0.7293695         nan 0.73429961 0.78507775\n",
      " 0.78512659 0.75875659 0.76427302 0.76658582        nan        nan\n",
      " 0.77275962        nan 0.76049335 0.77868775 0.77863965 0.74702996\n",
      " 0.75997644 0.76542173        nan        nan 0.77889467        nan\n",
      " 0.76518373 0.77242343 0.77242343 0.76228762 0.75935049 0.76570952\n",
      "        nan        nan 0.77015841        nan 0.76546981 0.76977428\n",
      " 0.76977428 0.7689997  0.75935051 0.76566369        nan        nan\n",
      " 0.76938726        nan 0.76561635 0.76958111 0.76958111 0.7692415\n",
      " 0.75934975 0.76556751        nan        nan 0.76948343        nan\n",
      " 0.76575987 0.76958185 0.76962993 0.76948417 0.75925357 0.76556749]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73409914\n",
      " 0.73409914 0.73419909 0.73410217 0.73415025        nan        nan\n",
      " 0.5               nan 0.5        0.74052718 0.74052718 0.73868823\n",
      " 0.7387852  0.73864018        nan        nan 0.76860508        nan\n",
      " 0.76860508 0.76236294 0.76236294 0.74704404 0.75038427 0.74714344\n",
      "        nan        nan 0.7293695         nan 0.73429961 0.7851061\n",
      " 0.7851061  0.74804443 0.74585755 0.74556573        nan        nan\n",
      " 0.7745655         nan 0.74703838 0.78812461 0.78812461 0.76343474\n",
      " 0.74366964 0.74474031        nan        nan 0.78513729        nan\n",
      " 0.74454428 0.78594456 0.7859934  0.78169837 0.74342912 0.74425711\n",
      "        nan        nan 0.78527267        nan 0.7444502  0.78517499\n",
      " 0.78522306 0.78440021 0.74299402 0.74440215        nan        nan\n",
      " 0.78502995        nan 0.74440213 0.78507876 0.78512686 0.78502995\n",
      " 0.7431398  0.74425637        nan        nan 0.78512686        nan\n",
      " 0.74430445 0.78507876 0.78507876 0.78507876 0.74337951 0.7444502 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72680128\n",
      " 0.72680128 0.72723857 0.72723857 0.72728667        nan        nan\n",
      " 0.5               nan 0.5        0.72527655 0.72527655 0.72315139\n",
      " 0.72295679 0.72271333        nan        nan 0.70322007        nan\n",
      " 0.70322007 0.75416845 0.75416845 0.73407574 0.73867674 0.73659449\n",
      "        nan        nan 0.71785404        nan 0.72425489 0.74281411\n",
      " 0.74281411 0.70189221 0.72115651 0.72975957        nan        nan\n",
      " 0.71020042        nan 0.72257992 0.68942465 0.68947275 0.64040642\n",
      " 0.71345523 0.72724105        nan        nan 0.64268454        nan\n",
      " 0.72757157 0.66108875 0.66108875 0.61750807 0.71273227 0.72695323\n",
      "        nan        nan 0.618191          nan 0.72690213 0.65116959\n",
      " 0.65112075 0.60932486 0.71292691 0.72709825        nan        nan\n",
      " 0.5759392         nan 0.72705017 0.64496214 0.64505985 0.60162541\n",
      " 0.71278261 0.72695328        nan        nan 0.56657782        nan\n",
      " 0.72700214 0.64089105 0.64035682 0.59447675 0.71287805 0.72714711]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################random seed loop#################\n",
    "train_scores=[]\n",
    "test_scores=[]\n",
    "loopn=20\n",
    "scoring='roc_auc'\n",
    "np.random.seed(42)\n",
    "random_states=np.random.randint(1,101,loopn)\n",
    "for i in range(loopn):\n",
    "    train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=random_states[i]\n",
    "                                                   )\n",
    "\n",
    "    standardScaler = StandardScaler()\n",
    "    standardScaler.fit(train_X)\n",
    "    X_standard = standardScaler.transform(train_X)\n",
    "    X_standard_test = standardScaler.transform(test_X)\n",
    "\n",
    "    #n_components=0.95\n",
    "    #n_components=range(10,min(train_X.shape),10)\n",
    "    n_components=[0.99,0.95,0.90,0.85]\n",
    "    best_pca_train_scores=[]\n",
    "    best_pca_test_scores=[]\n",
    "    for j in n_components:\n",
    "        estimator = PCA(n_components=j,random_state=random_states[i])\n",
    "        pca_X_train = estimator.fit_transform(X_standard)\n",
    "        pca_X_test = estimator.transform(X_standard_test)\n",
    "        cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_states[i]) \n",
    "    \n",
    "        #scoring = {'AUC': 'roc_auc'}\n",
    "        cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "        gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "        parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "        cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_states[i]) \n",
    "\n",
    "        svc_grid_search=GridSearchCV(estimator=SVC(random_state=random_states[i]),param_grid=parameters,cv=cvx,scoring='accuracy')\n",
    "        svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "        param_grid = {'penalty':['l1', 'l2'],\n",
    "                      \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                      \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "    #               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                    }\n",
    "        LR_grid = LogisticRegression(max_iter=1000)\n",
    "        LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring=scoring,n_jobs=10)\n",
    "        LR_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "        estimators = [\n",
    "            ('lr', LR_grid_search.best_estimator_),\n",
    "            ('svc', svc_grid_search.best_estimator_),\n",
    "        ]\n",
    "        clf = StackingClassifier(estimators=estimators, final_estimator=LinearSVC(C=5),n_jobs=10)\n",
    "        clf.fit(pca_X_train, train_y)\n",
    "\n",
    "        estimators = [\n",
    "            ('lr', LR_grid_search.best_estimator_),\n",
    "            ('svc', svc_grid_search.best_estimator_),\n",
    "        ]\n",
    "\n",
    "        param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                         LogisticRegression(C=0.1),LogisticRegression(C=1),LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                         LogisticRegression(C=1000)]}\n",
    "\n",
    "        Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "        Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx ,scoring=scoring,n_jobs=10)\n",
    "        Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "        Stacking_grid_search.best_estimator_\n",
    "\n",
    "        train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "        train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "\n",
    "        test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "        test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "        \n",
    "        best_pca_train_scores.append(train_res1.loc[:,\"AUC\"])\n",
    "        best_pca_test_scores.append(test_res1.loc[:,\"AUC\"])\n",
    "    \n",
    "    train_scores.append(np.max(best_pca_train_scores))\n",
    "    test_scores.append(best_pca_test_scores[np.argmax(best_pca_train_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "89e38686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7559758835597881\n",
      "0    0.750783\n",
      "Name: AUC, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('mean')\n",
    "print(np.mean(train_scores))\n",
    "print(np.mean(test_scores))\n",
    "print(\"std\")\n",
    "print(np.std(train_scores))\n",
    "print(np.std(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "03767256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7823665466651183, 0.7603211009174312, 0.7589517284093988, 0.7508806565246003, 0.7323723531916541, 0.7714502767777649, 0.7680195873495143, 0.7460805945883173, 0.7417595710912398, 0.7417595710912398, 0.7823133201718732, 0.7586323694499284, 0.7669695738009522, 0.7325320326713893, 0.739964386637247, 0.7520371230596524, 0.7461338210815622, 0.7823133201718732, 0.7476096465760849, 0.7570500909689156]\n",
      "[0    0.714706\n",
      "Name: AUC, dtype: float64, 0    0.763655\n",
      "Name: AUC, dtype: float64, 0    0.763971\n",
      "Name: AUC, dtype: float64, 0    0.764811\n",
      "Name: AUC, dtype: float64, 0    0.792752\n",
      "Name: AUC, dtype: float64, 0    0.72479\n",
      "Name: AUC, dtype: float64, 0    0.771744\n",
      "Name: AUC, dtype: float64, 0    0.738866\n",
      "Name: AUC, dtype: float64, 0    0.75042\n",
      "Name: AUC, dtype: float64, 0    0.75042\n",
      "Name: AUC, dtype: float64, 0    0.739601\n",
      "Name: AUC, dtype: float64, 0    0.749475\n",
      "Name: AUC, dtype: float64, 0    0.746429\n",
      "Name: AUC, dtype: float64, 0    0.801155\n",
      "Name: AUC, dtype: float64, 0    0.753782\n",
      "Name: AUC, dtype: float64, 0    0.713235\n",
      "Name: AUC, dtype: float64, 0    0.754202\n",
      "Name: AUC, dtype: float64, 0    0.739601\n",
      "Name: AUC, dtype: float64, 0    0.728361\n",
      "Name: AUC, dtype: float64, 0    0.753676\n",
      "Name: AUC, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "print(train_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add85de3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
