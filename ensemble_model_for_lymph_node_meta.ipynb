{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbef4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, cross_val_predict\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn import svm  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import math\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "# cores = mp.cpu_count()\n",
    "# pool = mp.Pool(processes=20)\n",
    "\n",
    "# min1=min(list(X_standard.shape))\n",
    "# a1=list(range(10,min1,10))\n",
    "# a1[-1]=min1\n",
    "# pcc_top1=pool.map(find_best_pca_lr,a1)  ##（SVM，LR）\n",
    "# pool.terminate()\n",
    "\n",
    "\n",
    "# a1=pd.DataFrame()\n",
    "# for i1 in pcc_top1:\n",
    "#     a1=pd.concat([a1,i1], axis=0)\n",
    "# a1.columns=['tr_TP', 'tr_TN', 'tr_FP', 'tr_FN', 'tr_Sen', 'tr_Spe', 'tr_Acc', 'tr_PPV', 'tr_NPV', 'tr_MCC', 'tr_AUC','TP',\n",
    "#        'TN', 'FP', 'FN', 'Sen', 'Spe', 'Acc', 'PPV', 'NPV', 'MCC', 'AUC','PCA']   \n",
    "\n",
    "# a1=a1.sort_values(['Acc','tr_Acc','PCA'], ascending=[False,False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a00ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_csv(input_path,i):\n",
    "\n",
    "    df_chunk=pd.read_csv(input_path,\n",
    "                         chunksize=10000,\n",
    "#                          sep='\\t'\n",
    "                        sep=i\n",
    "                        )\n",
    "    res_chunk=[]\n",
    "    for chunk in df_chunk:\n",
    "        res_chunk.append(chunk)\n",
    "    res_df=pd.concat(res_chunk)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d3ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measures_gridloo(label, score):\n",
    "    label = np.array(label)\n",
    "    score = np.array(score)\n",
    "    \n",
    "    N  = len(label)\n",
    "    TP = sum((label == 1) & (score == 1))\n",
    "    TN = sum((label == 0) & (score == 0))\n",
    "    FP = sum((label == 0) & (score == 1))\n",
    "    FN = sum((label == 1) & (score == 0))\n",
    "\n",
    "    # init all measures to nan\n",
    "    measures = {measure: float(\"nan\") for measure in (\"Sen\", \"Spe\", \"Acc\", \"PPV\", \"NPV\", \"MCC\",\"AUC\")}\n",
    "    \n",
    "    measures[\"TP\"] = TP\n",
    "    measures[\"TN\"] = TN\n",
    "    measures[\"FP\"] = FP\n",
    "    measures[\"FN\"] = FN\n",
    "    \n",
    "    S = (TP + FN) / N\n",
    "    P = (TP + FP) / N\n",
    "\n",
    "    if (TP + FN) > 0:\n",
    "        measures[\"Sen\"] = round(TP/(TP+FN), 4)\n",
    "\n",
    "    if (TN + FP) > 0:\n",
    "        measures[\"Spe\"] = round(TN/(TN+FP), 4)\n",
    "\n",
    "    if (TP + FP + FN + TN) > 0:\n",
    "        measures[\"Acc\"] = round((TP+TN)/(TP+FP+FN+TN), 4)\n",
    "\n",
    "    if (TP + FP) > 0:\n",
    "        measures[\"PPV\"] = round(TP/(TP+FP), 4)\n",
    "\n",
    "    if (TN + FN) > 0:\n",
    "        measures[\"NPV\"] = round(TN/(TN+FN), 4)\n",
    "\n",
    "    if (S*P*(1-S)*(1-P)) > 0:\n",
    "        measures[\"MCC\"] = round((TP/N - S*P)/(math.sqrt(S*P*(1-S)*(1-P))), 4)\n",
    "    \n",
    "    \n",
    "    measures[\"AUC\"]= roc_auc_score(label, score)\n",
    "    return pd.DataFrame([measures],\n",
    "                        columns=[\"TP\", \"TN\", \"FP\",\n",
    "                                 \"FN\", \"Sen\", \"Spe\", \"Acc\", \"PPV\", \"NPV\", \"MCC\",\"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d53b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVM\n",
    "def find_best_pca(i):\n",
    "    n_components=i\n",
    "    estimator = PCA(n_components=n_components,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    \n",
    "    scoring = {'AUC': 'roc_auc'}\n",
    "    cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "    gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "    parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "    \n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "    grid_search=GridSearchCV(estimator=SVC(random_state=10),param_grid=parameters,cv=cvx,scoring='accuracy')\n",
    "    grid_search.fit(pca_X_train, train_y)\n",
    "    \n",
    "    train_pre_y = cross_val_predict(grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "    test_pre_y = grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "    test_res1['PCA']=n_components\n",
    "    \n",
    "    res=pd.concat([train_res1,test_res1], axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4e5c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_pca_lr(i):\n",
    "    n_components=i\n",
    "    estimator = PCA(n_components=n_components,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    \n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "\n",
    "    param_grid = {'penalty':['l2'],\n",
    "              \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],  \n",
    "              \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\"],\n",
    "#             \"C\":list(np.arange(0,0.1,0.005)),   \n",
    "#               \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\"]\n",
    "            }\n",
    "    LR_grid = LogisticRegression()\n",
    "    grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=9)\n",
    "    grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "\n",
    "    train_pre_y = cross_val_predict(grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "   \n",
    "\n",
    "    test_pre_y = grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "    test_res1['PCA']=n_components\n",
    "    \n",
    "    res=pd.concat([train_res1,test_res1], axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e5f27eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer='BRCA'\n",
    "path='D:\\\\lymph_meta_xmiseq\\\\tcga_data\\\\'\n",
    "# e1=\"./\"+cancer+\"_delta_pcc_wilcox.csv\"\n",
    "# delta_pcc=read_single_csv(e1,',')\n",
    "# delta_pcc=delta_pcc.drop(['Unnamed: 0','pair'],axis=1)\n",
    "# delta_pcc=delta_pcc.dropna(axis=0,how='any')\n",
    "\n",
    "# result=delta_pcc.T\n",
    "# train=result.iloc[:,0:-1].values.astype('float')\n",
    "# target=result.iloc[:,-1].values.astype('float')\n",
    "\n",
    "train=pd.read_csv(path+cancer+\"\\\\admat_final.csv\").iloc[:,2:].T.values\n",
    "target=pd.read_csv(path+cancer+\"\\\\gctm_label.csv\",index_col=0).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "986f9b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00874834, -0.00736022, -0.01710605, ...,  0.0059139 ,\n",
       "         0.00585509,  0.01760065],\n",
       "       [-0.06756009, -0.03635654, -0.06104614, ...,  0.00184041,\n",
       "         0.01073223, -0.00660949],\n",
       "       [ 0.05017487, -0.03385318, -0.05728117, ..., -0.01067972,\n",
       "         0.01398897,  0.01295414],\n",
       "       ...,\n",
       "       [-0.00012984,  0.00158047,  0.00504004, ...,  0.00526114,\n",
       "        -0.00421565, -0.0168382 ],\n",
       "       [-0.0120549 ,  0.0223974 , -0.02588812, ..., -0.03524445,\n",
       "         0.00812885,  0.01039054],\n",
       "       [ 0.00757404,  0.00548185,  0.02304116, ...,  0.00104388,\n",
       "         0.00138618, -0.0349668 ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a0046d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4d47e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=10\n",
    "                                                   )\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(train_X)\n",
    "X_standard = standardScaler.transform(train_X)\n",
    "X_standard_test = standardScaler.transform(test_X)\n",
    "\n",
    "n_components=0.95\n",
    "estimator = PCA(n_components=n_components,random_state=10)\n",
    "pca_X_train = estimator.fit_transform(X_standard)\n",
    "pca_X_test = estimator.transform(X_standard_test)\n",
    "cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4d3eaf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 2281)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "385399ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.45230769        nan 0.52369231 0.54769231\n",
      " 0.54769231 0.72153846 0.76123077 0.74523077        nan        nan\n",
      " 0.45230769        nan 0.50030769 0.75292308 0.75292308 0.75292308\n",
      " 0.79230769 0.75292308        nan        nan 0.45230769        nan\n",
      " 0.52369231 0.848      0.848      0.82430769 0.864      0.832\n",
      "        nan        nan 0.68246154        nan 0.75292308 0.888\n",
      " 0.888      0.87230769 0.88       0.88              nan        nan\n",
      " 0.92              nan 0.92       0.88061538 0.88061538 0.85661538\n",
      " 0.86461538 0.86461538        nan        nan 0.944             nan\n",
      " 0.936      0.84061538 0.84061538 0.86461538 0.86461538 0.87261538\n",
      "        nan        nan 0.944             nan 0.87261538 0.84861538\n",
      " 0.84861538 0.86461538 0.86461538 0.87261538        nan        nan\n",
      " 0.90430769        nan 0.87261538 0.85661538 0.85661538 0.84861538\n",
      " 0.86461538 0.87261538        nan        nan 0.80892308        nan\n",
      " 0.87261538 0.84861538 0.84861538 0.84061538 0.86461538 0.87261538]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=10, shuffle=True),\n",
       "             estimator=LogisticRegression(max_iter=1000), n_jobs=10,\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                               1000],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm\n",
    "scoring = {'AUC': 'roc_auc'}\n",
    "cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "\n",
    "svc_grid_search=GridSearchCV(estimator=SVC(random_state=10),param_grid=parameters,cv=cvx,scoring='accuracy')\n",
    "svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "#LR\n",
    "param_grid = {'penalty':['l1', 'l2'],\n",
    "              \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "#               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "            }\n",
    "LR_grid = LogisticRegression(max_iter=1000)\n",
    "LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=10)\n",
    "LR_grid_search.fit(pca_X_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c0fc0d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                LogisticRegression(C=1, max_iter=1000,\n",
       "                                                   penalty='l1',\n",
       "                                                   solver='liblinear')),\n",
       "                               ('svc',\n",
       "                                SVC(C=32, gamma=3.0517578125e-05,\n",
       "                                    random_state=10))],\n",
       "                   final_estimator=LinearSVC(C=5), n_jobs=10)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('lr', LR_grid_search.best_estimator_),\n",
    "    ('svc', svc_grid_search.best_estimator_),\n",
    "]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LinearSVC(C=5),n_jobs=10)\n",
    "clf.fit(pca_X_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "aa318404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('lr',\n",
       "                                LogisticRegression(C=1, max_iter=1000,\n",
       "                                                   penalty='l1',\n",
       "                                                   solver='liblinear')),\n",
       "                               ('svc',\n",
       "                                SVC(C=32, gamma=3.0517578125e-05,\n",
       "                                    random_state=10))],\n",
       "                   final_estimator=LogisticRegression(C=100))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('lr', LR_grid_search.best_estimator_),\n",
    "    ('svc', svc_grid_search.best_estimator_),\n",
    "]\n",
    "\n",
    "param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                 LogisticRegression(C=0.1),LogisticRegression(C=1),LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                 LogisticRegression(C=1000)]}\n",
    "\n",
    "Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx ,scoring='accuracy',n_jobs=10)\n",
    "Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "Stacking_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a1961530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "#     train_res1['PCA']=n_components\n",
    "\n",
    "test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "test_res1=get_measures_gridloo(test_y,test_pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dfa32e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TP  TN  FP  FN     Sen     Spe     Acc     PPV     NPV     MCC       AUC\n",
      "0  64  50   7   5  0.9275  0.8772  0.9048  0.9014  0.9091  0.8076  0.902365\n",
      "   TP  TN  FP  FN  Sen  Spe  Acc  PPV  NPV  MCC  AUC\n",
      "0  30  24   0   0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "print(train_res1)\n",
    "print(test_res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ac3da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shpae:\n",
      "(195, 13022)\n",
      "range(10, 132, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.79777778\n",
      " 0.79777778 0.79778056 0.79778056 0.79778056        nan        nan\n",
      " 0.5               nan 0.5        0.80732387 0.80732387 0.80944027\n",
      " 0.80944027 0.80944027        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.80894737 0.80894737 0.81001392 0.80948482 0.80948482\n",
      "        nan        nan 0.80202172        nan 0.80202172 0.81582568\n",
      " 0.81582568 0.81529936 0.81529936 0.81477304        nan        nan\n",
      " 0.81265664        nan 0.81370927 0.8121359  0.8121359  0.81319131\n",
      " 0.8121359  0.812665          nan        nan 0.81477304        nan\n",
      " 0.81318853 0.8131941  0.8131941  0.8131941  0.812665   0.812665\n",
      "        nan        nan 0.8131941         nan 0.812665   0.8137232\n",
      " 0.8137232  0.8137232  0.8131941  0.812665          nan        nan\n",
      " 0.8131941         nan 0.812665   0.8137232  0.8137232  0.8137232\n",
      " 0.8131941  0.812665          nan        nan 0.8131941         nan\n",
      " 0.812665   0.8137232  0.8137232  0.8137232  0.8131941  0.812665  ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.80939293\n",
      " 0.80939293 0.80939293 0.80939293 0.80939293        nan        nan\n",
      " 0.5               nan 0.5        0.832665   0.832665   0.83161793\n",
      " 0.83161793 0.83161793        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.83691172 0.83691172 0.83637984 0.83637984 0.83637984\n",
      "        nan        nan 0.81314119        nan 0.81314119 0.85644946\n",
      " 0.85644946 0.85644946 0.85750487 0.85644946        nan        nan\n",
      " 0.84642439        nan 0.84695071 0.87281259 0.87281259 0.86912838\n",
      " 0.86595934 0.86226399        nan        nan 0.87335004        nan\n",
      " 0.86120579 0.87756057 0.87756057 0.8802005  0.86965748 0.86331941\n",
      "        nan        nan 0.87755778        nan 0.86331941 0.87755778\n",
      " 0.87755778 0.8780841  0.87018658 0.86331941        nan        nan\n",
      " 0.87755778        nan 0.86331941 0.87755778 0.87755778 0.87755778\n",
      " 0.87018658 0.86331941        nan        nan 0.87755778        nan\n",
      " 0.86331941 0.87755778 0.87755778 0.87755778 0.87018658 0.86331941]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81468672\n",
      " 0.81468672 0.8141604  0.8141604  0.8141604         nan        nan\n",
      " 0.5               nan 0.5        0.84112782 0.84112782 0.84218881\n",
      " 0.84218881 0.84218881        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.86174882 0.86174882 0.85964355 0.85964355 0.85964355\n",
      "        nan        nan 0.81208299        nan 0.81208299 0.88811473\n",
      " 0.88811473 0.88599276 0.88704818 0.88493734        nan        nan\n",
      " 0.8654386         nan 0.86385408 0.89019215 0.89019215 0.88864383\n",
      " 0.89180451 0.88599833        nan        nan 0.88915065        nan\n",
      " 0.88758563 0.88753551 0.88753551 0.89232804 0.89022556 0.88546923\n",
      "        nan        nan 0.88595656        nan 0.88494291 0.88542746\n",
      " 0.88489836 0.89176831 0.88917293 0.88494291        nan        nan\n",
      " 0.88436926        nan 0.88546923 0.88436926 0.88436926 0.88595377\n",
      " 0.8886494  0.88546923        nan        nan 0.88436926        nan\n",
      " 0.88494291 0.88436926 0.88436926 0.88436926 0.88864662 0.88546923]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81996658\n",
      " 0.81996658 0.81997215 0.81997215 0.81997215        nan        nan\n",
      " 0.5               nan 0.5        0.85328599 0.85328599 0.85381509\n",
      " 0.85381509 0.85381509        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88443331 0.88443331 0.88392091 0.88392091 0.88392091\n",
      "        nan        nan 0.81950153        nan 0.81897243 0.90602896\n",
      " 0.90602896 0.91183793 0.91236703 0.91236703        nan        nan\n",
      " 0.89128098        nan 0.89021442 0.89387914 0.89387914 0.90918129\n",
      " 0.90918964 0.91025063        nan        nan 0.90757728        nan\n",
      " 0.90919243 0.89598719 0.89598719 0.90811752 0.9112949  0.90866889\n",
      "        nan        nan 0.90810916        nan 0.91024784 0.89494013\n",
      " 0.89494013 0.90705931 0.91129212 0.90866889        nan        nan\n",
      " 0.90863548        nan 0.90866889 0.89546644 0.89546644 0.90811473\n",
      " 0.91129212 0.90866889        nan        nan 0.90547201        nan\n",
      " 0.90866889 0.89441381 0.89441381 0.91022278 0.91023949 0.90866889]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.82049568\n",
      " 0.82049568 0.81944305 0.81944305 0.81944305        nan        nan\n",
      " 0.5               nan 0.5        0.85327764 0.85327764 0.85169312\n",
      " 0.85169312 0.85221944        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88708716 0.88708716 0.88657477 0.88657199 0.88657199\n",
      "        nan        nan 0.80573656        nan 0.80573656 0.89076859\n",
      " 0.89076859 0.8912949  0.89288221 0.89235589        nan        nan\n",
      " 0.88495127        nan 0.88336118 0.88338067 0.88338067 0.87863548\n",
      " 0.8823169  0.88600111        nan        nan 0.87018379        nan\n",
      " 0.88653578 0.88970482 0.88970482 0.87758563 0.88336953 0.88652743\n",
      "        nan        nan 0.86491785        nan 0.88652743 0.88917572\n",
      " 0.88917572 0.87652186 0.88284043 0.88758563        nan        nan\n",
      " 0.87229184        nan 0.88705653 0.88390699 0.88390699 0.87494013\n",
      " 0.88389585 0.88758563        nan        nan 0.88019493        nan\n",
      " 0.88705653 0.88180173 0.88127541 0.87441103 0.88336953 0.88652743]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81890281\n",
      " 0.81890281 0.8189056  0.8189056  0.8189056         nan        nan\n",
      " 0.5               nan 0.5        0.84904205 0.84904205 0.85168198\n",
      " 0.85168198 0.85221108        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.89235867 0.89235867 0.89500696 0.89500696 0.89500696\n",
      "        nan        nan 0.80838207        nan 0.80785297 0.90976608\n",
      " 0.90976608 0.91242551 0.91347536 0.91347536        nan        nan\n",
      " 0.90240602        nan 0.90292398 0.90449735 0.90449735 0.89289613\n",
      " 0.90081314 0.90767196        nan        nan 0.89920356        nan\n",
      " 0.90872737 0.89500696 0.89500696 0.8807296  0.90344472 0.90767474\n",
      "        nan        nan 0.89443052        nan 0.90767474 0.89394598\n",
      " 0.89394598 0.8807296  0.90239209 0.90767474        nan        nan\n",
      " 0.88492063        nan 0.90767474 0.891824   0.891824   0.88019215\n",
      " 0.90238931 0.90767474        nan        nan 0.86219716        nan\n",
      " 0.90767474 0.8907658  0.88971317 0.87966583 0.90239209 0.90767474]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.8183765\n",
      " 0.8183765  0.8183765  0.8183765  0.8183765         nan        nan\n",
      " 0.5               nan 0.5        0.85062935 0.85062935 0.85116124\n",
      " 0.85116124 0.85168755        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88390977 0.88390977 0.88813422 0.88866332 0.88866332\n",
      "        nan        nan 0.80785297        nan 0.80679476 0.90397661\n",
      " 0.90397661 0.90399053 0.90557226 0.90451685        nan        nan\n",
      " 0.87653857        nan 0.88234754 0.89500139 0.89500139 0.88972988\n",
      " 0.89079087 0.89976608        nan        nan 0.87811473        nan\n",
      " 0.90188527 0.88971596 0.88971596 0.88340295 0.89184907 0.89924255\n",
      "        nan        nan 0.87496519        nan 0.89924534 0.88602896\n",
      " 0.88550265 0.87759955 0.89184907 0.89924255        nan        nan\n",
      " 0.87018379        nan 0.89871345 0.88549986 0.88602896 0.87654135\n",
      " 0.89290448 0.89765803        nan        nan 0.85009468        nan\n",
      " 0.89765803 0.88338903 0.88550265 0.87179337 0.89237817 0.89765803]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.82048454\n",
      " 0.82048454 0.81995823 0.81995823 0.81995823        nan        nan\n",
      " 0.5               nan 0.5        0.8511501  0.8511501  0.85590922\n",
      " 0.85538012 0.85538012        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.8955472  0.8955472  0.90029518 0.89976887 0.89976887\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.90927597\n",
      " 0.90927597 0.91246449 0.91246449 0.91141186        nan        nan\n",
      " 0.88976051        nan 0.89451406 0.89818435 0.89818435 0.89715957\n",
      " 0.90138123 0.90612921        nan        nan 0.89026455        nan\n",
      " 0.90770816 0.89292398 0.89292398 0.88818435 0.90243665 0.90665553\n",
      "        nan        nan 0.88184071        nan 0.90612643 0.88659705\n",
      " 0.88659705 0.88343637 0.90296575 0.90665553        nan        nan\n",
      " 0.86176831        nan 0.90665553 0.88396547 0.8850181  0.87869674\n",
      " 0.90296575 0.90665553        nan        nan 0.83483988        nan\n",
      " 0.90665553 0.88344194 0.88344194 0.87975494 0.90349485 0.90612643]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81784461\n",
      " 0.81784461 0.8178474  0.8178474  0.8178474         nan        nan\n",
      " 0.5               nan 0.5        0.8516792  0.8516792  0.85326371\n",
      " 0.85326371 0.85326371        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.89290727 0.89290727 0.8981927  0.8971345  0.8971345\n",
      "        nan        nan 0.80732387        nan 0.80679476 0.91352827\n",
      " 0.91352827 0.91564467 0.91564467 0.91617098        nan        nan\n",
      " 0.87658034        nan 0.88028126 0.90666388 0.90666388 0.90878307\n",
      " 0.91406572 0.91406015        nan        nan 0.88236981        nan\n",
      " 0.91299916 0.89928989 0.89928989 0.89875522 0.91406572 0.91353105\n",
      "        nan        nan 0.87289056        nan 0.91353105 0.89453356\n",
      " 0.89453356 0.89612086 0.91406572 0.91406015        nan        nan\n",
      " 0.86281537        nan 0.91353105 0.89137009 0.89084378 0.88769702\n",
      " 0.91353383 0.91406015        nan        nan 0.82426901        nan\n",
      " 0.91353105 0.88662211 0.89401281 0.88769424 0.91406294 0.91353105]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81731551\n",
      " 0.81731551 0.81784461 0.81784461 0.81784461        nan        nan\n",
      " 0.5               nan 0.5        0.85221108 0.85221108 0.85274018\n",
      " 0.85274018 0.85274018        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.89186578 0.89186578 0.89451128 0.89398218 0.89398218\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.91616541\n",
      " 0.91616541 0.91142022 0.9108939  0.91194653        nan        nan\n",
      " 0.88240323        nan 0.88556391 0.90667502 0.90667502 0.90455026\n",
      " 0.90350599 0.91036202        nan        nan 0.88819827        nan\n",
      " 0.9093066  0.90719577 0.90719577 0.90297132 0.90350599 0.9098357\n",
      "        nan        nan 0.87604288        nan 0.9087775  0.90666945\n",
      " 0.90666945 0.90457254 0.90350599 0.9098357         nan        nan\n",
      " 0.84537455        nan 0.9098357  0.90244222 0.90244222 0.89615706\n",
      " 0.9040323  0.9108939         nan        nan 0.82526873        nan\n",
      " 0.9103648  0.902445   0.90562796 0.89247006 0.90297689 0.91036202]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81783904\n",
      " 0.81783904 0.81784183 0.81784183 0.81784183        nan        nan\n",
      " 0.5               nan 0.5        0.8516792  0.8516792  0.85485102\n",
      " 0.85485102 0.8543247         nan        nan 0.78772765        nan\n",
      " 0.78772765 0.89608187 0.89608187 0.89873851 0.89873851 0.89873851\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.91351991\n",
      " 0.91351991 0.91247006 0.91246728 0.91299638        nan        nan\n",
      " 0.87817878        nan 0.88663047 0.90823726 0.90823726 0.90348649\n",
      " 0.90665274 0.90982735        nan        nan 0.86019493        nan\n",
      " 0.90455305 0.90612086 0.90612086 0.89978279 0.90665274 0.90982456\n",
      "        nan        nan 0.86178502        nan 0.90876915 0.90875522\n",
      " 0.90875522 0.89926483 0.90612364 0.90929546        nan        nan\n",
      " 0.85696463        nan 0.90929546 0.90770259 0.90770259 0.89344751\n",
      " 0.90612364 0.90982456        nan        nan 0.80358674        nan\n",
      " 0.90982456 0.90454191 0.90294625 0.89450014 0.90717906 0.90876636]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81837093\n",
      " 0.81837093 0.8173183  0.8173183  0.8173183         nan        nan\n",
      " 0.5               nan 0.5        0.85168755 0.85168755 0.85380117\n",
      " 0.85380117 0.85380117        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88816486 0.88816486 0.88974659 0.88974659 0.88922027\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.89449457\n",
      " 0.89502367 0.89713729 0.89713729 0.8971345         nan        nan\n",
      " 0.86601504        nan 0.86865776 0.88761348 0.88761348 0.88867446\n",
      " 0.89079087 0.89132554        nan        nan 0.85228627        nan\n",
      " 0.89186299 0.8828655  0.8828655  0.88392927 0.89079087 0.89185185\n",
      "        nan        nan 0.84858535        nan 0.89185185 0.88549986\n",
      " 0.88549986 0.87126706 0.89237538 0.89132554        nan        nan\n",
      " 0.81783904        nan 0.89132554 0.88338903 0.88444723 0.86493177\n",
      " 0.89184907 0.89185185        nan        nan 0.77718184        nan\n",
      " 0.89079644 0.88076023 0.88234754 0.86123642 0.89131997 0.89026734]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.81836814\n",
      " 0.81836814 0.81784461 0.81784461 0.81784461        nan        nan\n",
      " 0.5               nan 0.5        0.8522083  0.8522083  0.85432749\n",
      " 0.85432749 0.85379838        nan        nan 0.78772765        nan\n",
      " 0.78772765 0.88499025 0.88499025 0.88711779 0.88711779 0.88711779\n",
      "        nan        nan 0.80679476        nan 0.80679476 0.89238931\n",
      " 0.89238931 0.89239488 0.89239488 0.89239209        nan        nan\n",
      " 0.8591061         nan 0.87549986 0.88552214 0.88552214 0.8897633\n",
      " 0.89028683 0.89345586        nan        nan 0.86018658        nan\n",
      " 0.89028683 0.88235032 0.88235032 0.88553885 0.89028126 0.89292398\n",
      "        nan        nan 0.85120301        nan 0.89397939 0.87971039\n",
      " 0.87971039 0.87602896 0.88975494 0.89292676        nan        nan\n",
      " 0.83211083        nan 0.89292398 0.87812865 0.87760234 0.86018936\n",
      " 0.89028126 0.89239766        nan        nan 0.73969925        nan\n",
      " 0.89292398 0.87549708 0.87655528 0.85753829 0.88975216 0.89345308]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components:\n",
      "110\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################random seed loop#################\n",
    "train_scores=[]\n",
    "test_scores=[]\n",
    "loopn=1\n",
    "scoring='roc_auc'\n",
    "#np.random.seed(42)\n",
    "random_states=np.random.choice(range(101), loopn, replace=False)\n",
    "\n",
    "tmp_train=[]\n",
    "tmp_test=[]\n",
    "#print(random_states)\n",
    "for i in range(loopn):\n",
    "    train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=10\n",
    "                                                   )\n",
    "    print(\"train_x.shpae:\")\n",
    "    print(train_X.shape)\n",
    "\n",
    "    standardScaler = StandardScaler()\n",
    "    standardScaler.fit(train_X)\n",
    "    X_standard = standardScaler.transform(train_X)\n",
    "    X_standard_test = standardScaler.transform(test_X)\n",
    "    #calculate max n_components\n",
    "    estimator = PCA(n_components=0.95,random_state=10)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "\n",
    "    n_components=range(10,min(pca_X_train.shape),10)\n",
    "    print(n_components)\n",
    "    #n_components=[0.99,0.95,0.90,0.85]\n",
    "    best_pca_train_scores=[]\n",
    "    best_pca_test_scores=[]\n",
    "    for j in n_components:\n",
    "        estimator = PCA(n_components=j,random_state=10)\n",
    "        pca_X_train = estimator.fit_transform(X_standard)\n",
    "        pca_X_test = estimator.transform(X_standard_test)\n",
    "        cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=10) \n",
    "    \n",
    "        #scoring = {'AUC': 'roc_auc'}\n",
    "        cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "        gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "        parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "\n",
    "        svc_grid_search=GridSearchCV(estimator=SVC(random_state=10),\n",
    "                                     param_grid=parameters,cv=cvx,scoring=scoring)\n",
    "        svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "        param_grid = {'penalty':['l1', 'l2'],\n",
    "                      \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                      \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "    #               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                    }\n",
    "        LR_grid = LogisticRegression(max_iter=1000, random_state=10)\n",
    "        LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring=scoring,n_jobs=10)\n",
    "        LR_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "        estimators = [\n",
    "            ('lr', LR_grid_search.best_estimator_),\n",
    "            ('svc', svc_grid_search.best_estimator_),\n",
    "        ]\n",
    "        clf = StackingClassifier(estimators=estimators, final_estimator=LinearSVC(C=5, random_state=10),\n",
    "                                 n_jobs=10)\n",
    "        clf.fit(pca_X_train, train_y)\n",
    "\n",
    "        estimators = [\n",
    "            ('lr', LR_grid_search.best_estimator_),\n",
    "            ('svc', svc_grid_search.best_estimator_),\n",
    "        ]\n",
    "\n",
    "        param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),\n",
    "                                         LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                         LogisticRegression(C=0.1),LogisticRegression(C=1),\n",
    "                                         LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                         LogisticRegression(C=1000)]}\n",
    "\n",
    "        Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "        Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx,\n",
    "                                            scoring=scoring,n_jobs=10)\n",
    "        Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "        Stacking_grid_search.best_estimator_\n",
    "\n",
    "        train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "        train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "\n",
    "        test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "        test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "        \n",
    "        best_pca_train_scores.append(train_res1.loc[:,\"AUC\"])\n",
    "        best_pca_test_scores.append(test_res1.loc[:,\"AUC\"])\n",
    "    \n",
    "    train_scores.append(np.max(best_pca_train_scores))\n",
    "    test_scores.append(best_pca_test_scores[np.argmax(best_pca_train_scores)])\n",
    "    print(\"n_components:\")\n",
    "    print(n_components[np.argmax(best_pca_train_scores)])\n",
    "    \n",
    "    tmp_train.append(best_pca_train_scores)\n",
    "    tmp_test.append(best_pca_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "89e38686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "0.8376952300548755\n",
      "0.7829059829059828\n",
      "std\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0    0.754221\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.809941\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.805087\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.827406\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.797119\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.811102\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.795958\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.805667\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.826826\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.833421\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.837695\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.817697\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.822552\n",
       "Name: AUC, dtype: float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0    0.754221\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.809941\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.805087\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.827406\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.797119\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.811102\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.795958\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.805667\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.826826\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.833421\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.837695\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.817697\n",
       "Name: AUC, dtype: float64</td>\n",
       "      <td>0    0.827986\n",
       "Name: AUC, dtype: float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0   \\\n",
       "0  0    0.754221\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.754221\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        1   \\\n",
       "0  0    0.809941\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.809941\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        2   \\\n",
       "0  0    0.805087\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.805087\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        3   \\\n",
       "0  0    0.827406\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.827406\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        4   \\\n",
       "0  0    0.797119\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.797119\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        5   \\\n",
       "0  0    0.811102\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.811102\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        6   \\\n",
       "0  0    0.795958\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.795958\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        7   \\\n",
       "0  0    0.805667\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.805667\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        8   \\\n",
       "0  0    0.826826\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.826826\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        9   \\\n",
       "0  0    0.833421\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.833421\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        10  \\\n",
       "0  0    0.837695\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.837695\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        11  \\\n",
       "0  0    0.817697\n",
       "Name: AUC, dtype: float64   \n",
       "1  0    0.817697\n",
       "Name: AUC, dtype: float64   \n",
       "\n",
       "                                        12  \n",
       "0  0    0.822552\n",
       "Name: AUC, dtype: float64  \n",
       "1  0    0.827986\n",
       "Name: AUC, dtype: float64  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('mean')\n",
    "print(np.mean(train_scores))\n",
    "print(np.mean(test_scores))\n",
    "print(\"std\")\n",
    "print(np.std(train_scores))\n",
    "print(np.std(test_scores))\n",
    "pd.DataFrame(tmp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "03767256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9295183982683983]\n",
      "[0    0.940972\n",
      "Name: AUC, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "print(train_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360d174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66359025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shpae:\n",
      "(643, 4660)\n",
      "range(10, 463, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.7143901\n",
      " 0.7143901  0.71497091 0.71497091 0.71497091        nan        nan\n",
      " 0.5               nan 0.5        0.71448764 0.71448764 0.71269409\n",
      " 0.71288869 0.71283985        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.7410049  0.7410049  0.71928803 0.72452302 0.72074056\n",
      "        nan        nan 0.72603681        nan 0.72980901 0.77485496\n",
      " 0.77485496 0.73512124 0.72803268 0.72116555        nan        nan\n",
      " 0.76355163        nan 0.72089623 0.78226702 0.78226702 0.76229474\n",
      " 0.72811836 0.72164791        nan        nan 0.78163126        nan\n",
      " 0.72198905 0.78337635 0.78337635 0.78181982 0.7286038  0.72184327\n",
      "        nan        nan 0.78313284        nan 0.72184327 0.78327786\n",
      " 0.78322902 0.78332596 0.72865188 0.72184327        nan        nan\n",
      " 0.78318092        nan 0.72184327 0.78327709 0.78327709 0.78322899\n",
      " 0.72865188 0.72184327        nan        nan 0.78327709        nan\n",
      " 0.72184327 0.78327709 0.78327709 0.78327709 0.72865188 0.72184327]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72404662\n",
      " 0.72404662 0.72438469 0.72438393 0.724432          nan        nan\n",
      " 0.5               nan 0.5        0.72693857 0.72693857 0.72466103\n",
      " 0.72480607 0.72475726        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.75539916 0.75539916 0.73552226 0.73877114 0.7357191\n",
      "        nan        nan 0.73102541        nan 0.73525017 0.79135531\n",
      " 0.79135531 0.7484571  0.7410591  0.74123069        nan        nan\n",
      " 0.78985385        nan 0.73708003 0.79798246 0.79798246 0.78495366\n",
      " 0.74095307 0.73972867        nan        nan 0.79767193        nan\n",
      " 0.73992621 0.79815788 0.79815788 0.79650518 0.74042259 0.73924171\n",
      "        nan        nan 0.79771754        nan 0.7393882  0.79776786\n",
      " 0.79776786 0.79776793 0.74051876 0.73914477        nan        nan\n",
      " 0.79771976        nan 0.73919287 0.79771976 0.79767168 0.79776712\n",
      " 0.74051876 0.73914477        nan        nan 0.79771976        nan\n",
      " 0.73914477 0.79771976 0.79771976 0.79771976 0.74051876 0.73914477]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72331987\n",
      " 0.72331987 0.72336945 0.72336945 0.72336943        nan        nan\n",
      " 0.5               nan 0.5        0.72544599 0.72544599 0.72283712\n",
      " 0.72283564 0.7227868         nan        nan 0.75544363        nan\n",
      " 0.75544363 0.74926883 0.74926883 0.73458148 0.73666923 0.73477971\n",
      "        nan        nan 0.73204358        nan 0.73674485 0.77676985\n",
      " 0.77686753 0.74080672 0.73961927 0.7353765         nan        nan\n",
      " 0.77672052        nan 0.73215426 0.78521532 0.78521532 0.76502745\n",
      " 0.73522105 0.73561325        nan        nan 0.78476295        nan\n",
      " 0.73532761 0.785009   0.7849609  0.78224271 0.73507523 0.73551703\n",
      "        nan        nan 0.78534489        nan 0.73561395 0.78476924\n",
      " 0.78476924 0.7842846  0.73502715 0.73551703        nan        nan\n",
      " 0.7848166         nan 0.73551703 0.7846723  0.7846723  0.78452504\n",
      " 0.73502715 0.73551703        nan        nan 0.78467156        nan\n",
      " 0.73551703 0.7846723  0.7846723  0.78462346 0.73502715 0.73546819]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.72794032\n",
      " 0.72794032 0.72828135 0.72823325 0.7283775         nan        nan\n",
      " 0.5               nan 0.5        0.73331264 0.7332638  0.73151527\n",
      " 0.73141914 0.73127262        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.76566651 0.76566651 0.74847951 0.75181719 0.74925741\n",
      "        nan        nan 0.73247565        nan 0.73722803 0.80265776\n",
      " 0.80265778 0.75127794 0.74973147 0.74976898        nan        nan\n",
      " 0.79599819        nan 0.74334131 0.82788915 0.82774487 0.7853092\n",
      " 0.7446121  0.74908737        nan        nan 0.82797649        nan\n",
      " 0.74899129 0.83063291 0.83072985 0.82097231 0.74441447 0.7488943\n",
      "        nan        nan 0.8304863         nan 0.74898971 0.83072742\n",
      " 0.8307755  0.82975675 0.74441447 0.7488943         nan        nan\n",
      " 0.83077554        nan 0.74894238 0.83077554 0.83082438 0.83072666\n",
      " 0.74441447 0.7488943         nan        nan 0.83077554        nan\n",
      " 0.7488943  0.83077554 0.83077554 0.83077554 0.74441447 0.7488943 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73285483\n",
      " 0.73285483 0.73333417 0.73333417 0.73333417        nan        nan\n",
      " 0.5               nan 0.5        0.73997216 0.740021   0.73827191\n",
      " 0.73822386 0.73812771        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77333916 0.77333916 0.7544971  0.75730508 0.75518315\n",
      "        nan        nan 0.73232989        nan 0.7371799  0.80877766\n",
      " 0.80867998 0.75879243 0.75422917 0.7528228         nan        nan\n",
      " 0.79927232        nan 0.74815136 0.82659674 0.82659674 0.78595839\n",
      " 0.7521895  0.7516379         nan        nan 0.82794298        nan\n",
      " 0.75139973 0.82769962 0.82760344 0.81727132 0.75165594 0.75124794\n",
      "        nan        nan 0.82726597        nan 0.75139368 0.82692625\n",
      " 0.82692625 0.82590602 0.75175211 0.7511991         nan        nan\n",
      " 0.82692622        nan 0.75124794 0.82692703 0.82702395 0.82697513\n",
      " 0.75175211 0.7511991         nan        nan 0.82702393        nan\n",
      " 0.7511991  0.82707205 0.82707205 0.82697511 0.75175211 0.7511991 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73711004\n",
      " 0.73711004 0.73735121 0.73740005 0.73735121        nan        nan\n",
      " 0.5               nan 0.5        0.74445228 0.74445228 0.74324402\n",
      " 0.7432921  0.74309822        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77869383 0.77869383 0.76213691 0.76605762 0.76234666\n",
      "        nan        nan 0.73237873        nan 0.73708373 0.81001503\n",
      " 0.81001503 0.76436057 0.76213164 0.76121804        nan        nan\n",
      " 0.80295341        nan 0.75449252 0.82067363 0.82062553 0.78617131\n",
      " 0.76008064 0.76033136        nan        nan 0.82404036        nan\n",
      " 0.76042992 0.82337015 0.82337015 0.8160351  0.75959369 0.7604742\n",
      "        nan        nan 0.82307993        nan 0.76028108 0.82317599\n",
      " 0.82312715 0.82215817 0.75954411 0.76037652        nan        nan\n",
      " 0.82303097        nan 0.76037726 0.82307905 0.82307905 0.82288596\n",
      " 0.75954411 0.76032842        nan        nan 0.82312865        nan\n",
      " 0.76032842 0.82307905 0.82307981 0.82303171 0.75954411 0.76037726]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73744721\n",
      " 0.73744721 0.73763951 0.73759067 0.73763951        nan        nan\n",
      " 0.5               nan 0.5        0.7433069  0.74325806 0.74151261\n",
      " 0.74151485 0.74146606        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77454046 0.77454046 0.75697895 0.75959675 0.75765824\n",
      "        nan        nan 0.73247565        nan 0.73732497 0.79365361\n",
      " 0.79370245 0.74703995 0.74815328 0.75193254        nan        nan\n",
      " 0.78937715        nan 0.74717775 0.80836777 0.80836777 0.7623341\n",
      " 0.74517607 0.75002303        nan        nan 0.81383681        nan\n",
      " 0.74993    0.81038702 0.81043512 0.79692278 0.74493402 0.74972847\n",
      "        nan        nan 0.81042987        nan 0.74963456 0.81013757\n",
      " 0.81018565 0.80859132 0.74493402 0.7496796         nan        nan\n",
      " 0.81023301        nan 0.74963153 0.81013681 0.81018491 0.81004065\n",
      " 0.74493402 0.7496796         nan        nan 0.81013681        nan\n",
      " 0.7496796  0.81013681 0.81013681 0.81008797 0.74493402 0.7496796 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73633871\n",
      " 0.73633871 0.73653178 0.73653104 0.73653104        nan        nan\n",
      " 0.5               nan 0.5        0.74269416 0.74269416 0.74138156\n",
      " 0.74118694 0.74113958        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.76983163 0.76983163 0.75093999 0.75438573 0.75225268\n",
      "        nan        nan 0.73228325        nan 0.73698679 0.79197839\n",
      " 0.79197839 0.74041255 0.74103688 0.74431337        nan        nan\n",
      " 0.78788249        nan 0.74149991 0.8082046  0.8082046  0.75645829\n",
      " 0.73864691 0.74246402        nan        nan 0.80935527        nan\n",
      " 0.74217026 0.80649448 0.80649448 0.79157322 0.73854918 0.7421251\n",
      "        nan        nan 0.80668741        nan 0.74236557 0.80649348\n",
      " 0.80649348 0.80464598 0.7384515  0.7421732         nan        nan\n",
      " 0.80644309        nan 0.7421251  0.80639647 0.80639573 0.80629734\n",
      " 0.7384515  0.7421732         nan        nan 0.80644457        nan\n",
      " 0.7421732  0.80639795 0.80634911 0.80629953 0.7384515  0.7421732 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73455917\n",
      " 0.73455917 0.73484987 0.73494605 0.73489797        nan        nan\n",
      " 0.5               nan 0.5        0.74051735 0.74051735 0.73814748\n",
      " 0.73824437 0.73809787        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.76511028 0.76511028 0.74661628 0.74913871 0.74671995\n",
      "        nan        nan 0.73223367        nan 0.73708373 0.78852751\n",
      " 0.78852751 0.73414641 0.73137548 0.7362408         nan        nan\n",
      " 0.79255381        nan 0.74362006 0.80724257 0.80724257 0.75228293\n",
      " 0.72774651 0.73444246        nan        nan 0.80913462        nan\n",
      " 0.73497001 0.80568434 0.80563624 0.78920552 0.72764874 0.73400662\n",
      "        nan        nan 0.80313601        nan 0.73410208 0.80173528\n",
      " 0.80168644 0.80234252 0.7275999  0.73400588        nan        nan\n",
      " 0.80120259        nan 0.73400662 0.80110642 0.80110642 0.80115371\n",
      " 0.7275999  0.73400588        nan        nan 0.80120257        nan\n",
      " 0.73400588 0.8012041  0.8012041  0.80115526 0.7275999  0.73400588]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73718016\n",
      " 0.73718016 0.73727779 0.73727779 0.73727779        nan        nan\n",
      " 0.5               nan 0.5        0.74415732 0.74415732 0.74221723\n",
      " 0.74221656 0.7422173         nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77151083 0.77151083 0.75319523 0.75615565 0.75397674\n",
      "        nan        nan 0.73237947        nan 0.73703486 0.78276739\n",
      " 0.78276739 0.73917661 0.74048412 0.74448447        nan        nan\n",
      " 0.78146902        nan 0.74443251 0.79365694 0.79365694 0.74432202\n",
      " 0.73654491 0.74379891        nan        nan 0.79736433        nan\n",
      " 0.74282902 0.78800054 0.78800054 0.770008   0.73625335 0.74350878\n",
      "        nan        nan 0.78714274        nan 0.74355765 0.78646705\n",
      " 0.78646705 0.78504734 0.73620599 0.7436057         nan        nan\n",
      " 0.78646929        nan 0.74355762 0.78641969 0.78637159 0.78583592\n",
      " 0.73620599 0.7435576         nan        nan 0.78627465        nan\n",
      " 0.7436057  0.78627541 0.78627541 0.78632275 0.73620599 0.7435576 ]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73721718\n",
      " 0.73721718 0.73731257 0.73731183 0.73736067        nan        nan\n",
      " 0.5               nan 0.5        0.74519492 0.74519492 0.74287028\n",
      " 0.7428222  0.74267718        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77388311 0.77383501 0.75571926 0.75906434 0.75707998\n",
      "        nan        nan 0.73228327        nan 0.73703563 0.78919881\n",
      " 0.78929649 0.7383738  0.74093996 0.747372          nan        nan\n",
      " 0.79837396        nan 0.75303544 0.79868238 0.79858547 0.74557385\n",
      " 0.73675662 0.7449433         nan        nan 0.80122729        nan\n",
      " 0.74664329 0.7921285  0.7921285  0.77679277 0.736562   0.74469981\n",
      "        nan        nan 0.78903811        nan 0.74499061 0.78725173\n",
      " 0.78725173 0.78635735 0.7365139  0.74474789        nan        nan\n",
      " 0.7870578         nan 0.74469905 0.78677068 0.78681804 0.78686099\n",
      " 0.7365139  0.74474789        nan        nan 0.78672039        nan\n",
      " 0.74474789 0.78667298 0.78676916 0.78667224 0.7365139  0.74474789]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73498839\n",
      " 0.73498839 0.73537451 0.73542335 0.73542335        nan        nan\n",
      " 0.5               nan 0.5        0.74191385 0.74196195 0.74016768\n",
      " 0.74021726 0.74026682        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77085727 0.77090534 0.75381292 0.75638253 0.75478669\n",
      "        nan        nan 0.73228253        nan 0.73703563 0.78278367\n",
      " 0.78278367 0.73379183 0.74149048 0.74702774        nan        nan\n",
      " 0.78553675        nan 0.75142422 0.79678687 0.79678687 0.7383492\n",
      " 0.73605691 0.74460408        nan        nan 0.80153552        nan\n",
      " 0.74537525 0.78722798 0.78727682 0.76851005 0.73557218 0.74440793\n",
      "        nan        nan 0.7837957         nan 0.7444576  0.78186822\n",
      " 0.78191632 0.78246776 0.73557218 0.74435909        nan        nan\n",
      " 0.78138281        nan 0.74435909 0.78147748 0.7814294  0.78128291\n",
      " 0.73557218 0.74435909        nan        nan 0.78152482        nan\n",
      " 0.74435909 0.78142714 0.78147598 0.7814775  0.73557218 0.74435909]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73784327\n",
      " 0.73784327 0.73847134 0.73847134 0.73851944        nan        nan\n",
      " 0.5               nan 0.5        0.74743194 0.74743194 0.74569005\n",
      " 0.74564274 0.74573822        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77962244 0.77962244 0.7626641  0.76586647 0.7633914\n",
      "        nan        nan 0.73223369        nan 0.7370837  0.78971182\n",
      " 0.78966298 0.74765061 0.75123587 0.7558488         nan        nan\n",
      " 0.78436332        nan 0.75293396 0.7899935  0.7899935  0.73979204\n",
      " 0.74670466 0.75415265        nan        nan 0.78854213        nan\n",
      " 0.75371175 0.77913378 0.77913378 0.75611042 0.74641088 0.75385961\n",
      "        nan        nan 0.77279487        nan 0.75385961 0.77110017\n",
      " 0.77110017 0.77085519 0.74636204 0.75385961        nan        nan\n",
      " 0.77027801        nan 0.75390771 0.77032685 0.77027873 0.76979409\n",
      " 0.74636204 0.75385961        nan        nan 0.77018253        nan\n",
      " 0.75385961 0.77018179 0.77018179 0.77013371 0.74636204 0.75385961]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73808821\n",
      " 0.73808821 0.73866899 0.73871783 0.73866899        nan        nan\n",
      " 0.5               nan 0.5        0.74564311 0.74564311 0.7441435\n",
      " 0.74424041 0.74423967        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.77876228 0.77876228 0.76098621 0.76446891 0.76214864\n",
      "        nan        nan 0.73233063        nan 0.73708373 0.78899101\n",
      " 0.78899101 0.7413675  0.74847613 0.75538843        nan        nan\n",
      " 0.78168824        nan 0.7591758  0.78937373 0.78937373 0.7388036\n",
      " 0.74463534 0.75369464        nan        nan 0.78202332        nan\n",
      " 0.75404336 0.76297335 0.76297335 0.7466749  0.74385314 0.75364427\n",
      "        nan        nan 0.75466184        nan 0.7533557  0.75180572\n",
      " 0.75180572 0.75025777 0.74390198 0.75374195        nan        nan\n",
      " 0.74976415        nan 0.75369311 0.74952221 0.74952221 0.74957186\n",
      " 0.74390198 0.75374195        nan        nan 0.74937791        nan\n",
      " 0.75374195 0.74937791 0.74947411 0.74928097 0.74390198 0.75374195]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.7380381\n",
      " 0.73798926 0.73847236 0.73847236 0.73852046        nan        nan\n",
      " 0.5               nan 0.5        0.74683969 0.74679085 0.74529341\n",
      " 0.74495521 0.74481241        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.78072511 0.78072511 0.7610598  0.76401268 0.76256038\n",
      "        nan        nan 0.73228179        nan 0.7370837  0.78315892\n",
      " 0.78315892 0.73479141 0.74497012 0.75275875        nan        nan\n",
      " 0.78587059        nan 0.75842463 0.77692629 0.77697439 0.72735272\n",
      " 0.73960706 0.74998751        nan        nan 0.78014005        nan\n",
      " 0.7513483  0.76668306 0.76668306 0.7417625  0.73916829 0.74974479\n",
      "        nan        nan 0.75879042        nan 0.74989057 0.75603558\n",
      " 0.75598748 0.75373837 0.73916829 0.74974479        nan        nan\n",
      " 0.75332949        nan 0.74974479 0.75275084 0.75275084 0.75356558\n",
      " 0.73916829 0.74974479        nan        nan 0.75245854        nan\n",
      " 0.74974479 0.75207226 0.75202418 0.75260429 0.73916829 0.74974479]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5               nan 0.5        0.73851517\n",
      " 0.73851517 0.7388533  0.7389014  0.73890138        nan        nan\n",
      " 0.5               nan 0.5        0.74692245 0.74692245 0.74531984\n",
      " 0.74546486 0.74536945        nan        nan 0.75544363        nan\n",
      " 0.75544363 0.78149452 0.78149452 0.76376563 0.76817238 0.7660955\n",
      "        nan        nan 0.73228253        nan 0.7370837  0.7876887\n",
      " 0.7876887  0.7411569  0.74923988 0.75831303        nan        nan\n",
      " 0.78364654        nan 0.75931041 0.78034442 0.78034442 0.73209404\n",
      " 0.7441271  0.75587894        nan        nan 0.77719258        nan\n",
      " 0.75680852 0.75634528 0.75624833 0.73495155 0.74373557 0.75554078\n",
      "        nan        nan 0.73911769        nan 0.75544456 0.73693619\n",
      " 0.73703313 0.73650907 0.74383175 0.75544384        nan        nan\n",
      " 0.7282844         nan 0.75544384 0.72872322 0.72872322 0.73160254\n",
      " 0.74383175 0.75544384        nan        nan 0.72599636        nan\n",
      " 0.75549268 0.72526668 0.72536288 0.72638635 0.74383175 0.75544384]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "random_stat=10\n",
    "train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   stratify=target,\n",
    "                                                   random_state=random_stat\n",
    "                                                   )\n",
    "print(\"train_x.shpae:\")\n",
    "print(train_X.shape)\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(train_X)\n",
    "X_standard = standardScaler.transform(train_X)\n",
    "X_standard_test = standardScaler.transform(test_X)\n",
    "    #calculate max n_components\n",
    "estimator = PCA(n_components=0.99,random_state=random_stat)\n",
    "pca_X_train = estimator.fit_transform(X_standard)\n",
    "\n",
    "n_components=range(10,min(pca_X_train.shape),10)\n",
    "print(n_components)\n",
    "    #n_components=[0.99,0.95,0.90,0.85]\n",
    "best_pca_train_scores=[]\n",
    "best_pca_test_scores=[]\n",
    "for j in n_components:\n",
    "    estimator = PCA(n_components=j,random_state=random_stat)\n",
    "    pca_X_train = estimator.fit_transform(X_standard)\n",
    "    pca_X_test = estimator.transform(X_standard_test)\n",
    "    cvx = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_stat) \n",
    "    \n",
    "        #scoring = {'AUC': 'roc_auc'}\n",
    "    cost = [-5, -3, -1, 1, 3, 5, 7, 9, 11, 13, 15]\n",
    "    gam = [3, 1, -1, -3, -5, -7, -9, -11, -13, -15]\n",
    "    parameters =[{'kernel': ['rbf'], 'C': [2**x for x in cost],'gamma':[2**x for x in gam]}]\n",
    "\n",
    "    svc_grid_search=GridSearchCV(estimator=SVC(random_state=random_stat),\n",
    "                                 param_grid=parameters,cv=cvx,scoring=scoring)\n",
    "    svc_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "    param_grid = {'penalty':['l1', 'l2'],\n",
    "                  \"C\":[0.00001,0.0001,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                  \"solver\":[\"newton-cg\", \"lbfgs\",\"liblinear\",\"sag\",\"saga\"]\n",
    "    #               \"algorithm\":['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "                  }\n",
    "    LR_grid = LogisticRegression(max_iter=1000, random_state=random_stat)\n",
    "    LR_grid_search = GridSearchCV(LR_grid, param_grid=param_grid, cv=cvx ,scoring=scoring,n_jobs=10)\n",
    "    LR_grid_search.fit(pca_X_train, train_y)\n",
    "\n",
    "    estimators = [\n",
    "        ('lr', LR_grid_search.best_estimator_),\n",
    "        ('svc', svc_grid_search.best_estimator_),\n",
    "    ]\n",
    "    clf = StackingClassifier(estimators=estimators, \n",
    "                             final_estimator=LinearSVC(C=5, random_state=random_stat),n_jobs=10)\n",
    "    clf.fit(pca_X_train, train_y)\n",
    "\n",
    "    estimators = [\n",
    "        ('lr', LR_grid_search.best_estimator_),\n",
    "        ('svc', svc_grid_search.best_estimator_),\n",
    "    ]\n",
    "\n",
    "    param_grid = {'final_estimator':[LogisticRegression(C=0.00001),LogisticRegression(C=0.0001),\n",
    "                                    LogisticRegression(C=0.001),LogisticRegression(C=0.01),\n",
    "                                    LogisticRegression(C=0.1),LogisticRegression(C=1),\n",
    "                                    LogisticRegression(C=10),LogisticRegression(C=100),\n",
    "                                    LogisticRegression(C=1000)]}\n",
    "\n",
    "    Stacking_grid =StackingClassifier(estimators=estimators,)\n",
    "    Stacking_grid_search = GridSearchCV(Stacking_grid, param_grid=param_grid, cv=cvx,\n",
    "                                        scoring=scoring,n_jobs=10)\n",
    "    Stacking_grid_search.fit(pca_X_train, train_y)\n",
    "    Stacking_grid_search.best_estimator_\n",
    "\n",
    "    train_pre_y = cross_val_predict(Stacking_grid_search.best_estimator_, pca_X_train,train_y, cv=cvx)\n",
    "    train_res1=get_measures_gridloo(train_y,train_pre_y)\n",
    "\n",
    "    test_pre_y = Stacking_grid_search.predict(pca_X_test)\n",
    "    test_res1=get_measures_gridloo(test_y,test_pre_y)\n",
    "        \n",
    "    best_pca_train_scores.append(train_res1.loc[:,\"AUC\"])\n",
    "    best_pca_test_scores.append(test_res1.loc[:,\"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "915736c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9489718614718614\n",
      "0    0.958333\n",
      "Name: AUC, dtype: float64\n",
      "n_components:\n",
      "140\n",
      "[0    0.827624\n",
      "Name: AUC, dtype: float64, 0    0.890611\n",
      "Name: AUC, dtype: float64, 0    0.890611\n",
      "Name: AUC, dtype: float64, 0    0.899702\n",
      "Name: AUC, dtype: float64, 0    0.916126\n",
      "Name: AUC, dtype: float64, 0    0.902733\n",
      "Name: AUC, dtype: float64, 0    0.5\n",
      "Name: AUC, dtype: float64, 0    0.5\n",
      "Name: AUC, dtype: float64, 0    0.923458\n",
      "Name: AUC, dtype: float64, 0    0.92059\n",
      "Name: AUC, dtype: float64, 0    0.922024\n",
      "Name: AUC, dtype: float64, 0    0.889177\n",
      "Name: AUC, dtype: float64, 0    0.911661\n",
      "Name: AUC, dtype: float64, 0    0.948972\n",
      "Name: AUC, dtype: float64, 0    0.895238\n",
      "Name: AUC, dtype: float64, 0    0.5\n",
      "Name: AUC, dtype: float64, 0    0.901299\n",
      "Name: AUC, dtype: float64, 0    0.885038\n",
      "Name: AUC, dtype: float64, 0    0.899702\n",
      "Name: AUC, dtype: float64, 0    0.883279\n",
      "Name: AUC, dtype: float64, 0    0.898268\n",
      "Name: AUC, dtype: float64, 0    0.910227\n",
      "Name: AUC, dtype: float64, 0    0.907197\n",
      "Name: AUC, dtype: float64, 0    0.910227\n",
      "Name: AUC, dtype: float64]\n",
      "[0    0.854167\n",
      "Name: AUC, dtype: float64, 0    0.878472\n",
      "Name: AUC, dtype: float64, 0    0.868056\n",
      "Name: AUC, dtype: float64, 0    0.923611\n",
      "Name: AUC, dtype: float64, 0    0.909722\n",
      "Name: AUC, dtype: float64, 0    0.923611\n",
      "Name: AUC, dtype: float64, 0    0.5\n",
      "Name: AUC, dtype: float64, 0    0.5\n",
      "Name: AUC, dtype: float64, 0    0.954861\n",
      "Name: AUC, dtype: float64, 0    0.954861\n",
      "Name: AUC, dtype: float64, 0    0.965278\n",
      "Name: AUC, dtype: float64, 0    0.965278\n",
      "Name: AUC, dtype: float64, 0    0.965278\n",
      "Name: AUC, dtype: float64, 0    0.958333\n",
      "Name: AUC, dtype: float64, 0    0.961806\n",
      "Name: AUC, dtype: float64, 0    0.5\n",
      "Name: AUC, dtype: float64, 0    0.961806\n",
      "Name: AUC, dtype: float64, 0    0.947917\n",
      "Name: AUC, dtype: float64, 0    0.972222\n",
      "Name: AUC, dtype: float64, 0    0.972222\n",
      "Name: AUC, dtype: float64, 0    0.982639\n",
      "Name: AUC, dtype: float64, 0    0.961806\n",
      "Name: AUC, dtype: float64, 0    0.96875\n",
      "Name: AUC, dtype: float64, 0    0.975694\n",
      "Name: AUC, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "print(np.max(best_pca_train_scores))\n",
    "print(best_pca_test_scores[np.argmax(best_pca_train_scores)])\n",
    "print(\"n_components:\")\n",
    "print(n_components[np.argmax(best_pca_train_scores)])\n",
    "\n",
    "print(best_pca_train_scores)\n",
    "print(best_pca_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1d2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
